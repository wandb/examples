{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98b0e02d",
   "metadata": {},
   "source": [
    "[![Open In Studio Lab](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/tcapelle/aws_smsl_demo/blob/main/01_data_processing.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d20ae56-6ea6-414e-9ae9-a465821bb739",
   "metadata": {},
   "source": [
    "# The CamVid Dataset\n",
    "\n",
    "In this notebooks we will pull the Cambridge-driving Labeled Video Database or `CamVid` to train our model. It contains a collection of videos with object class semantic labels, complete with metadata. The database provides ground truth labels that associate each pixel with one of 32 semantic classes.\n",
    "\n",
    "We will upload the full dataset to Weights and Biases as an `wandb.Artifact` first, and then compute some information of what classes are present on each image, and upload the processed dataset as a `wandb.Table`. Doing so enables the user to use the `wandb` UI to visualize and filter images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a854bbf5-b089-4f8d-8bc0-a956c2f057bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/studio-lab-user/.conda/envs/fastai/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/studio-lab-user/.conda/envs/fastai/lib/python3.9/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /opt/conda/conda-bld/pytorch_1607370151529/work/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7f7a33d-f84e-4cb4-b805-3ab9124cd4f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# log to wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a1fe00-4f87-49c6-a93f-2c67ed4a1fa0",
   "metadata": {},
   "source": [
    "## Log the raw dataset\n",
    "We will grab a copy of `CamVid` using `fastai`'s `untar_data` method, afterwards we can use the `Artifact.add_dir()` method, and upload the full folder to our wandb workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41d8bc4b-fbad-4d44-9154-095540469967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='598917120' class='' max='598913237' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [598917120/598913237 00:12<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = untar_data(URLs.CAMVID)\n",
    "codes = np.loadtxt(path/'codes.txt', dtype=str)\n",
    "fnames = get_image_files(path/\"images\")\n",
    "class_labels = {k: v for k, v in enumerate(codes)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99540b8a-5de7-4105-8e09-1380ca77134b",
   "metadata": {},
   "source": [
    "- we create a project under `user/project`\n",
    "- If you are working on a team, you can pass the team name to `Entity`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "636021ef-51af-4354-a119-94d575e10070",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT=\"sagemaker_camvid_demo\"\n",
    "ENTITY=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be5f0760-cce7-4cfc-96ce-7bc64f2a5614",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcapecape\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/studio-lab-user/aws_smsl_demo/wandb/run-20220309_144638-mdx25b1v</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/capecape/sagemaker_camvid_demo/runs/mdx25b1v\" target=\"_blank\">upload_camvid</a></strong> to <a href=\"https://wandb.ai/capecape/sagemaker_camvid_demo\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/studio-lab-user/.fastai/data/camvid)... Done. 4.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">upload_camvid</strong>: <a href=\"https://wandb.ai/capecape/sagemaker_camvid_demo/runs/mdx25b1v\" target=\"_blank\">https://wandb.ai/capecape/sagemaker_camvid_demo/runs/mdx25b1v</a><br/>Synced 6 W&B file(s), 0 media file(s), 1405 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220309_144638-mdx25b1v/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with wandb.init(\n",
    "    project=PROJECT,\n",
    "    name=\"upload_camvid\",\n",
    "    entity=ENTITY,\n",
    "    job_type=\"upload\",\n",
    "):\n",
    "    artifact = wandb.Artifact(\n",
    "        'camvid-dataset',\n",
    "        type='dataset',\n",
    "        metadata={\n",
    "            \"url\": URLs.CAMVID,\n",
    "            \"class_labels\": class_labels\n",
    "        },\n",
    "        description=\"The Cambridge-driving Labeled Video Database (CamVid) is the first collection of videos with object class semantic labels, complete with metadata. The database provides ground truth labels that associate each pixel with one of 32 semantic classes.\"\n",
    "    )\n",
    "    artifact.add_dir(path)\n",
    "    wandb.log_artifact(artifact)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37f692a-7b0e-402b-bc71-770102ec1bd9",
   "metadata": {},
   "source": [
    "## Log a `wandb.Table`\n",
    "Let's log a `wandb.Table` with the frequency distribution of each class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff15c66-8265-4928-b906-03556c2c0462",
   "metadata": {},
   "source": [
    "![](images/camvid_table.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5433c202-f483-423c-8bb4-f139244a54f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_func(fn):\n",
    "    return fn.parent.parent/\"labels\"/f\"{fn.stem}_P{fn.suffix}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ac2a270-17bd-48fe-a054-bfa13a34fa71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frequency_distribution(mask_data):\n",
    "    (unique, counts) = np.unique(mask_data, return_counts=True)\n",
    "    unique = list(unique)\n",
    "    counts = list(counts)\n",
    "    frequency_dict = {}\n",
    "    for _class in class_labels.keys():\n",
    "        if _class in unique:\n",
    "            frequency_dict[class_labels[_class]] = counts[unique.index(_class)]\n",
    "        else:\n",
    "            frequency_dict[class_labels[_class]] = 0\n",
    "    return frequency_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecbc6c9d-f0a0-494f-94ba-ad27dfb774d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ARTIFACT_ID = 'capecape/sagemaker_camvid_demo/camvid-dataset:latest'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d65adc34-9a16-4bf0-8628-4faac9f55c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_dataset():\n",
    "    with wandb.init(\n",
    "        project=PROJECT,\n",
    "        name=\"visualize_camvid\",\n",
    "        entity=ENTITY,\n",
    "        job_type=\"data_viz\"\n",
    "    ):\n",
    "        artifact = wandb.use_artifact(ARTIFACT_ID, type='dataset')\n",
    "        artifact_dir = artifact.download()\n",
    "        \n",
    "        table_data = []\n",
    "        image_files = get_image_files(Path(artifact_dir)/\"images\")\n",
    "        labels = [str(class_labels[_lab]) for _lab in list(class_labels)]\n",
    "        \n",
    "        print(\"Creating Table...\")\n",
    "        for image_file in progress_bar(image_files):\n",
    "            image = np.array(Image.open(image_file))\n",
    "            mask_data = np.array(Image.open(label_func(image_file)))\n",
    "            frequency_distribution = get_frequency_distribution(mask_data)\n",
    "            table_data.append(\n",
    "                [\n",
    "                    str(image_file.name),\n",
    "                    wandb.Image(image),\n",
    "                    wandb.Image(image, masks={\n",
    "                        \"predictions\": {\n",
    "                            \"mask_data\": mask_data,\n",
    "                            \"class_labels\": class_labels\n",
    "                        }\n",
    "                    })\n",
    "                ] + [\n",
    "                    frequency_distribution[_lab] for _lab in labels\n",
    "                ]\n",
    "            )\n",
    "        wandb.log({\n",
    "            \"CamVid_Dataset\": wandb.Table(\n",
    "                data=table_data,\n",
    "                columns=[\"File_Name\", \"Images\", \"Segmentation_Masks\"] + labels\n",
    "            )\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a96e61ad-dd9a-4f8c-93fb-469966f68c77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/studio-lab-user/aws_smsl_demo/wandb/run-20220309_144913-2i6pp0rf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/capecape/sagemaker_camvid_demo/runs/2i6pp0rf\" target=\"_blank\">visualize_camvid</a></strong> to <a href=\"https://wandb.ai/capecape/sagemaker_camvid_demo\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Downloading large artifact camvid-dataset:latest, 572.51MB. 1405 files... Done. 0:0:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Table...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='701' class='' max='701' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [701/701 06:33<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">visualize_camvid</strong>: <a href=\"https://wandb.ai/capecape/sagemaker_camvid_demo/runs/2i6pp0rf\" target=\"_blank\">https://wandb.ai/capecape/sagemaker_camvid_demo/runs/2i6pp0rf</a><br/>Synced 6 W&B file(s), 1 media file(s), 1404 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220309_144913-2i6pp0rf/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "log_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13467edf-1e60-4799-ba1b-82446803becf",
   "metadata": {},
   "source": [
    "## View the dataset in Weights and Biases workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed533f12-c528-40f6-81dc-c4473105f745",
   "metadata": {},
   "source": [
    "We get a nice UI to view our images\n",
    "\n",
    "![](images/camvid_mask.gif)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai:Python",
   "language": "python",
   "name": "conda-env-fastai-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
