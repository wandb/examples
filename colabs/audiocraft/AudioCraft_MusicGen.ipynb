{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EZU3hg4B1om6"
      },
      "outputs": [],
      "source": [
        "!pip install -q -U audiocraft wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RerQaiZt14r8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "from tempfile import TemporaryDirectory\n",
        "\n",
        "from scipy import signal\n",
        "from scipy.io import wavfile\n",
        "\n",
        "from audiocraft.models import MusicGen\n",
        "from audiocraft.data.audio import audio_write\n",
        "\n",
        "import wandb\n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3MTX8GoE7AzN"
      },
      "outputs": [],
      "source": [
        "# @title ## MusicGen Configs\n",
        "\n",
        "# @markdown WandB Project Name\n",
        "project_name = \"audiocraft\" # @param {type:\"string\"}\n",
        "\n",
        "wandb.init(project=project_name, job_type=\"musicgen/inference\")\n",
        "\n",
        "config = wandb.config\n",
        "\n",
        "# @markdown Select the MusicGen variant\n",
        "config.model_name = \"small\" # @param [\"small\", \"medium\", \"large\", \"melody\"]\n",
        "\n",
        "# @markdown ---\n",
        "# @markdown ## Conditional Generation Configs\n",
        "\n",
        "# @markdown The prompt for generating audio. You can give multiple prompts separated by `|` in the input. You can also leave it blank for unconditional generation.\n",
        "config.prompts = \"happy rock | energetic EDM | sad jazz\" # @param {type:\"string\"}\n",
        "\n",
        "descriptions = [prompt.strip() for prompt in config.prompts.split(\"|\")]\n",
        "config.is_unconditional = config.prompts.strip() == \"\"\n",
        "\n",
        "# @markdown Number of audio samples generated, this is relevant only for unconditional generation, i.e, if `config.prompts` is left blank.\n",
        "config.num_samples = 4 # @param {type:\"slider\", min:1, max:10, step:1}\n",
        "\n",
        "# @markdown Specify the random seed\n",
        "seed = None # @param {type:\"raw\"}\n",
        "\n",
        "max_seed = int(1024 * 1024 * 1024)\n",
        "if not isinstance(seed, int):\n",
        "    seed = random.randint(1, max_seed)\n",
        "if seed < 0:\n",
        "    seed = - seed\n",
        "seed = seed % max_seed\n",
        "config.seed = seed\n",
        "\n",
        "# @markdown ---\n",
        "# @markdown ## Generation Parameters\n",
        "# @markdown Use sampling if True, else do argmax decoding\n",
        "config.use_sampling = True # @param {type:\"boolean\"}\n",
        "\n",
        "# @markdown `top_k` used for sampling; limits us to `k` number of  of the top tokens to consider.\n",
        "config.top_k = 250 # @param {type:\"slider\", min:0, max:1000, step:1}\n",
        "\n",
        "# @markdown `top_p` used for sampling; limits us to the top tokens within a probability mass `p`\n",
        "config.top_p = 0.0 # @param {type:\"slider\", min:0, max:1.0, step:0.01}\n",
        "\n",
        "# @markdown Softmax temperature parameter\n",
        "config.temperature = 1.0 # @param {type:\"slider\", min:0, max:1.0, step:0.01}\n",
        "\n",
        "# @markdown Duration of the generated waveform\n",
        "config.duration = 10 # @param {type:\"slider\", min:1, max:30, step:1}\n",
        "\n",
        "# @markdown Coefficient used for classifier free guidance\n",
        "config.cfg_coef = 3 # @param {type:\"slider\", min:1, max:100, step:1}\n",
        "\n",
        "# @markdown Whether to perform 2 forward for Classifier Free Guidance instead of batching together the two. This has some impact on how things are padded but seems to have little impact in practice.\n",
        "config.two_step_cfg = False # @param {type:\"boolean\"}\n",
        "\n",
        "# @markdown When doing extended generation (i.e. more than 30 seconds), by how much should we extend the audio each time. Larger values will mean less context is preserved, and shorter value will require extra computations.\n",
        "config.extend_stride = 18 # @param {type:\"slider\", min:1, max:30, step:1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SfM8rhVX7ES9"
      },
      "outputs": [],
      "source": [
        "model = MusicGen.get_pretrained(config.model_name)\n",
        "model.set_generation_params(\n",
        "    use_sampling=config.use_sampling,\n",
        "    top_k=config.top_k,\n",
        "    top_p=config.top_p,\n",
        "    temperature=config.temperature,\n",
        "    duration=config.duration,\n",
        "    cfg_coef=config.cfg_coef,\n",
        "    two_step_cfg=config.two_step_cfg,\n",
        "    extend_stride=config.extend_stride\n",
        ")\n",
        "\n",
        "generated_wav = None\n",
        "if config.is_unconditional:\n",
        "    generated_wav = model.generate_unconditional(\n",
        "        num_samples=config.num_samples, progress=True\n",
        "    )\n",
        "else:\n",
        "    generated_wav = model.generate(descriptions, progress=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_n-1RthFVPYN"
      },
      "outputs": [],
      "source": [
        "def get_spectrogram(audio_file, output_file):\n",
        "    sample_rate, samples = wavfile.read(audio_file)\n",
        "    frequencies, times, Sxx = signal.spectrogram(samples, sample_rate)\n",
        "\n",
        "    log_Sxx = 10 * np.log10(Sxx + 1e-10)\n",
        "    vmin = np.percentile(log_Sxx, 5)\n",
        "    vmax = np.percentile(log_Sxx, 95)\n",
        "\n",
        "    mean_spectrum = np.mean(log_Sxx, axis=1)\n",
        "    threshold_low = np.percentile(mean_spectrum, 5)\n",
        "    threshold_high = np.percentile(mean_spectrum, 95)\n",
        "\n",
        "    freq_indices = np.where(mean_spectrum > threshold_low)\n",
        "    freq_min = 20\n",
        "    freq_max = frequencies[freq_indices].max()\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    cmap = plt.get_cmap(\"magma\")\n",
        "\n",
        "    ax.pcolormesh(times, frequencies, log_Sxx, shading=\"gouraud\", cmap=cmap, vmin=vmin, vmax=vmax)\n",
        "    ax.axis(\"off\")\n",
        "    ax.set_ylim([freq_min, freq_max])\n",
        "\n",
        "    plt.subplots_adjust(left=0, right=1, top=1, bottom=0)\n",
        "    plt.savefig(output_file, format=\"png\", bbox_inches=\"tight\", pad_inches=0)\n",
        "    plt.close()\n",
        "\n",
        "    return wandb.Image(output_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4fcOpiYx7Fqf"
      },
      "outputs": [],
      "source": [
        "temp_dir = TemporaryDirectory()\n",
        "wandb_table = wandb.Table(columns=[\"Prompt\", \"Audio\", \"Spectrogram\", \"Seed\"])\n",
        "\n",
        "for idx, wav in enumerate(generated_wav):\n",
        "    file_name = os.path.join(temp_dir.name, str(idx))\n",
        "    audio_write(\n",
        "        file_name,\n",
        "        wav.cpu(),\n",
        "        model.sample_rate,\n",
        "        strategy=\"loudness\",\n",
        "        loudness_compressor=True,\n",
        "    )\n",
        "    wandb_audio = wandb.Audio(file_name +  \".wav\")\n",
        "    wandb.log({\"Generated-Audio\": wandb_audio})\n",
        "    desc = descriptions[idx] if len(descriptions) > 1 else config.prompts\n",
        "    wandb_table.add_data(\n",
        "        desc,\n",
        "        wandb_audio,\n",
        "        get_spectrogram(\n",
        "            audio_file=file_name +  \".wav\",\n",
        "            output_file=os.path.join(temp_dir.name, str(idx) + \".png\")\n",
        "        ),\n",
        "        config.seed\n",
        "    )\n",
        "\n",
        "wandb.log({\"Generated-Audio-Table\": wandb_table})\n",
        "\n",
        "wandb.finish()\n",
        "temp_dir.cleanup()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7tYIL-auPawL"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}