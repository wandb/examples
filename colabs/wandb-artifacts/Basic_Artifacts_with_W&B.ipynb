{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/wandb/examples/blob/master/colabs/wandb-artifacts/Basic_Artifacts_with_W&B.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "<!--- @wandbcode{artifacts-basics} -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# W&B Artifacts Quickstart\n",
    "\n",
    "<!--- @wandbcode{artifacts-basics} -->\n",
    "\n",
    "This tutorial shows how to get started with W&B Artifacts very quickly. I finetune a convnet in Keras to identify 10 types of living things in photos: plants, animals, insects, etc. \n",
    "[Check out the companion report on W&B](https://wandb.ai/wandb/arttest/reports/Artifacts-Quickstart--VmlldzozNTAzMDM) \n",
    "\n",
    "In this example we're using Google Colab as a convenient hosted environment, but you can run your own training scripts from anywhere and visualize metrics with W&B's experiment tracking tool.\n",
    "\n",
    "## Sign up or login\n",
    "\n",
    "[Sign up or login](https://wandb.ai/login) to W&B to see and interact with your experiments in the browser.\n",
    "\n",
    "### Note on Artifacts storage space and deletion\n",
    "\n",
    "Running this colab end-to-end will create at least 7GB of artifacts in your wandb account (more if you try different experiments, increase the number of epochs or examples, etc). If you'd like to free up this space later, you can\n",
    "* delete the whole project (top right menu at wandb.ai / USERNAME / PROJECT_NAME /overview), or\n",
    "* delete individual artifacts (hover on the three vertical dots to the right of the artifact name in the sidebar), or\n",
    "* delete specific artifact versions through the storage explorer at wandb.ai / storage / USERNAME /PROJECT_NAME."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download sample data: Nature photos\n",
    "\n",
    "Note: **this stage might take a few minutes (~3.6GB of data)**. If you end up needing to rerun this cell, comment out the first capture line (change ```%%capture``` to ```#%%capture``` ) so you can respond to the prompt about re-downloading the dataset (and see the progress bar).\n",
    "\n",
    "Download subsampled data: 10,000 training images and 2,000 validation images from the [iNaturalist dataset](https://github.com/visipedia/inat_comp), evenly distributed across 10 classes of living things like birds, insects, plants, and mammals (names given in Latin—so Aves, Insecta, Plantae, etc :). We will fine-tune a convolutional neural network already trained on ImageNet on this task: given a photo of a living thing, correctly classify it into one of the 10 classes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!curl -SL https://storage.googleapis.com/wandb_datasets/nature_12K.zip > nature_12K.zip\n",
    "!unzip nature_12K.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start out by installing the experiment tracking library and setting up your free W&B account:\n",
    "\n",
    "\n",
    "*   **pip install wandb** – Install the W&B library\n",
    "*   **import wandb** – Import the wandb library\n",
    "*   **wandb login** – Login to your W&B account so you can log all your metrics in one place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wandb -qq\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from random import shuffle\n",
    "\n",
    "# source directory for all raw data (technically a subset of only 10K images)\n",
    "SRC = \"inaturalist_12K/train\"\n",
    "\n",
    "# number of images per class label\n",
    "# The total number of images is\n",
    "# 10 classes * 1000 images = 10,000 images in SRC\n",
    "NUM_IMAGES = 1000 # per class label, set this lower for faster results/fewer files\n",
    "PROJECT_NAME = \"artifacts_demo\"\n",
    "PREFIX = \"inat\" # convenient for tracking local data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Upload raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DATA_AT = \"_\".join([PREFIX, \"raw_data_10K\"])\n",
    "run = wandb.init(project=PROJECT_NAME, job_type=\"upload\")\n",
    "\n",
    "# create an artifact for all the raw data\n",
    "raw_data_at = wandb.Artifact(RAW_DATA_AT, type=\"raw_data\")\n",
    "\n",
    "# SRC_DIR contains 10 folders, one for each of 10 class labels\n",
    "# each folder contains images of the corresponding class\n",
    "labels = os.listdir(SRC)\n",
    "for l in labels:\n",
    "  imgs_per_label = os.path.join(SRC, l)\n",
    "  if os.path.isdir(imgs_per_label):\n",
    "    imgs = os.listdir(imgs_per_label)\n",
    "    # randomize the order\n",
    "    shuffle(imgs)\n",
    "    img_file_ids = imgs[:NUM_IMAGES]\n",
    "    for f in img_file_ids:\n",
    "      file_path = os.path.join(SRC, l, f)\n",
    "      # add file to artifact by full path\n",
    "      raw_data_at.add_file(file_path, name=l + \"/\" + f)\n",
    "\n",
    "# save artifact to W&B\n",
    "run.log_artifact(raw_data_at)\n",
    "wandb.run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Split raw data to prepare for training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DATA_AT = \"inat_raw_data_10K\"\n",
    "run = wandb.init(project=PROJECT_NAME, job_type=\"data_split\")\n",
    "\n",
    "# find the most recent (\"latest\") version of the full raw data\n",
    "# you can of course pass around programmatic aliases and not string literals\n",
    "data_at = run.use_artifact(RAW_DATA_AT + \":latest\")\n",
    "# download it locally (for illustration purposes/across hardware; you can\n",
    "# also sync/version artifacts by reference)\n",
    "data_dir = data_at.download()\n",
    "\n",
    "# create balanced train, val, test splits\n",
    "# each count is the number of images per label\n",
    "DATA_SPLITS = {\"train\" : 800, \"val\" : 100, \"test\": 100}\n",
    "\n",
    "ats = {}\n",
    "# wrap artifacts in dictionary for convenience\n",
    "for split, count in DATA_SPLITS.items():\n",
    "  ats[split] = wandb.Artifact(\"_\".join([PREFIX, split, \"data\", str(count*10)]), \n",
    "                              \"_\".join([split, \"data\"]))\n",
    "\n",
    "labels = os.listdir(data_dir)\n",
    "for l in labels:\n",
    "  if l.startswith(\".\"): # skip non-label file\n",
    "    continue\n",
    "  imgs_per_label = os.listdir(os.path.join(data_dir, l))\n",
    "  shuffle(imgs_per_label)\n",
    "  start_id = 0\n",
    "  for split, count in DATA_SPLITS.items():\n",
    "    # take a subset\n",
    "    split_imgs = imgs_per_label[start_id:start_id+count]\n",
    "    for img_file in split_imgs:\n",
    "      full_path = os.path.join(data_dir, l, img_file)\n",
    "      # add file to artifact by full path\n",
    "      # note: pass the label to the name parameter to retain it in\n",
    "      # the data structure \n",
    "      ats[split].add_file(full_path, name = os.path.join(l, img_file))\n",
    "    start_id += count\n",
    "\n",
    "# save all three artifacts to W&B\n",
    "# note: yes, in this example, we are cheating and have labels for the \"test\" data ;)\n",
    "for split, artifact in ats.items():\n",
    "  run.log_artifact(artifact)\n",
    "\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Train with artifacts and save model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPERIMENT CONFIG\n",
    "#---------------------------\n",
    "# number of training and validation examples\n",
    "# set these lower for fewer files/faster results\n",
    "# if you set these higher, make sure the total count is less than or equal to\n",
    "# the number of files uploaded for that split in the train/val data artifact\n",
    "NUM_TRAIN = 8000 # try 500, 1000, 2000, or max 10000\n",
    "NUM_VAL = 1000 \n",
    "NUM_EPOCHS = 1 # set low for demo purposes; try 3, 5, or as many as you like\n",
    "\n",
    "# model name\n",
    "# if you want to train a sufficiently different model, give this a new name\n",
    "# to start a new lineage for the model, instead of just incrementing the\n",
    "# version of the old model\n",
    "MODEL_NAME = \"iv3_trained\"\n",
    "\n",
    "# folder in which to save initial, untrained model\n",
    "INIT_MODEL_DIR = \"init_model_keras_iv3\"\n",
    "\n",
    "# folder in which to save the final, trained model\n",
    "# if you want to train a sufficiently different model, give this a new name\n",
    "# to start a new lineage for the model, instead of just incrementing the\n",
    "# version of the old model\n",
    "FINAL_MODEL_DIR = \"trained_keras_model_iv3\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "\n",
    "# experiment configuration saved to W&B\n",
    "config_defaults = {\n",
    "  \"num_train\" : NUM_TRAIN,\n",
    "  \"num_val\" : NUM_VAL,\n",
    "  \"num_classes\" : 10,\n",
    "  \"fc_size\" : 1024,\n",
    "\n",
    "  # inceptionV3 settings\n",
    "  \"img_width\" : 299,\n",
    "  \"img_height\": 299,\n",
    "  \"batch_size\" : 32,\n",
    "\n",
    "  \"epochs\" : NUM_EPOCHS,\n",
    "}\n",
    "\n",
    "def finetune_inception_model(fc_size, num_classes):\n",
    "  \"\"\"Load InceptionV3 with ImageNet weights, freeze it,\n",
    "  and attach a finetuning top for this classification task\"\"\"\n",
    "  # load InceptionV3 as base\n",
    "  base = InceptionV3(weights=\"imagenet\", include_top=\"False\")\n",
    "  # freeze base layers\n",
    "  for layer in base.layers:\n",
    "    layer.trainable = False\n",
    "  x = base.get_layer('mixed10').output \n",
    "\n",
    "  # attach a fine-tuning layer\n",
    "  x = GlobalAveragePooling2D()(x)\n",
    "  x = Dense(fc_size, activation='relu')(x)\n",
    "  guesses = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "  model = Model(inputs=base.input, outputs=guesses)\n",
    "  model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "  return model\n",
    "\n",
    "def train():\n",
    "  \"\"\" Main training loop. This is called pretrain because it freezes\n",
    "  the InceptionV3 layers of the model and only trains the new top layers\n",
    "  on the new data.   subsequent training phase would unfreeze all the layers\n",
    "  and finetune the whole model on the new data\"\"\" \n",
    "  # track this experiment with wandb: all runs will be sent\n",
    "  # to the given project name\n",
    "  run = wandb.init(project=PROJECT_NAME, job_type=\"train\", config=config_defaults)\n",
    "  cfg = wandb.config\n",
    "\n",
    "  # artifact names\n",
    "  train_at = os.path.join(PROJECT_NAME, PREFIX + \"_train_data_8000\") + \":latest\"\n",
    "  val_at = os.path.join(PROJECT_NAME, PREFIX + \"_val_data_1000\") + \":latest\"\n",
    "\n",
    "  train_data = run.use_artifact(train_at, type='train_data')\n",
    "  train_dir = train_data.download()\n",
    "  val_data = run.use_artifact(val_at, type='val_data')\n",
    "  val_dir = val_data.download()\n",
    "\n",
    "  # create train and validation data generators\n",
    "  train_datagen = ImageDataGenerator(\n",
    "      rescale=1. / 255,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True)\n",
    "  val_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "  train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(cfg.img_width, cfg.img_height),\n",
    "    batch_size=cfg.batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "  val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(cfg.img_width, cfg.img_height),\n",
    "    batch_size=cfg.batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "  # instantiate model and callbacks\n",
    "  model = finetune_inception_model(cfg.fc_size, cfg.num_classes)\n",
    "\n",
    "  # log model\n",
    "  model_artifact = wandb.Artifact(\n",
    "            \"iv3\", type=\"model\",\n",
    "            description=\"unmodified inception v3\",\n",
    "            metadata=dict(cfg))\n",
    "\n",
    "  model.save(INIT_MODEL_DIR)\n",
    "  model_artifact.add_dir(INIT_MODEL_DIR)\n",
    "  run.log_artifact(model_artifact)\n",
    "  callbacks = [WandbCallback()]\n",
    "\n",
    "  # train!\n",
    "  model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch = cfg.num_train // cfg.batch_size,\n",
    "    epochs=cfg.epochs,\n",
    "    validation_data=val_generator,\n",
    "    callbacks = callbacks,\n",
    "    validation_steps=cfg.num_val // cfg.batch_size)\n",
    "\n",
    "  # save trained model as artifact\n",
    "  trained_model_artifact = wandb.Artifact(\n",
    "            MODEL_NAME, type=\"model\",\n",
    "            description=\"trained inception v3\",\n",
    "            metadata=dict(cfg))\n",
    "\n",
    "  model.save(FINAL_MODEL_DIR)\n",
    "  trained_model_artifact.add_dir(FINAL_MODEL_DIR)\n",
    "  run.log_artifact(trained_model_artifact)\n",
    "  wandb.run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Load model for inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "import os\n",
    "run = wandb.init(project=PROJECT_NAME, job_type=\"inference\")\n",
    "# use the latest version of the model\n",
    "model_at = run.use_artifact(MODEL_NAME + \":latest\")\n",
    "# download the directory in which the model is saved\n",
    "model_dir= model_at.download()\n",
    "print(\"model: \", model_dir)\n",
    "model = keras.models.load_model(model_dir)\n",
    "\n",
    "test_data_at = run.use_artifact(\"inat_test_data_1000:latest\")\n",
    "test_dir = test_data_at.download()\n",
    "\n",
    "imgs = []\n",
    "class_labels = os.listdir(test_dir)\n",
    "for l in class_labels:\n",
    "  if l.startswith(\".\"):\n",
    "    continue\n",
    "  imgs_per_class = os.listdir(os.path.join(test_dir, l))\n",
    "  for img in imgs_per_class:\n",
    "    img_path = os.path.join(test_dir, l, img)\n",
    "    img = image.load_img(img_path, target_size=(299, 299))\n",
    "    img = image.img_to_array(img)\n",
    "    # don't forget to rescale test images to match the range of inputs\n",
    "    # to the network\n",
    "    img = np.expand_dims(img/255.0, axis=0)\n",
    "    imgs.append(img)\n",
    "\n",
    "preds = {}\n",
    "imgs = np.vstack(imgs)\n",
    "classes = model.predict(imgs, batch_size=32)\n",
    "for c in classes:\n",
    "  class_id = np.argmax(c)\n",
    "  if class_id in preds:\n",
    "    preds[class_id] += 1\n",
    "  else:\n",
    "    preds[class_id] = 1\n",
    "\n",
    "print(preds)\n",
    "wandb.run.finish()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More about Weights & Biases\n",
    "We're always free for academics and open source projects. Email carey@wandb.com with any questions or feature suggestions. Here are some more resources:\n",
    "\n",
    "1. [Documentation](http://docs.wandb.com) - Python docs\n",
    "2. [Gallery](https://app.wandb.ai/gallery) - example reports in W&B\n",
    "3. [Articles](https://www.wandb.com/articles) - blog posts and tutorials\n",
    "4. [Community](wandb.me/slack) - join our Slack community forum"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
