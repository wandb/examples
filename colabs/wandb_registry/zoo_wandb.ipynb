{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "822e8bc6",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/wandb/examples/blob/master/colabs/wandb_registry/zoo_wandb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "<!--- @wandbcode{zoo-wandb} -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75eb97c",
   "metadata": {},
   "source": [
    "<img src=\"http://wandb.me/logo-im-png\" width=\"400\" alt=\"Weights & Biases\" />\n",
    "\n",
    "<!--- @wandbcode{zoo-wandb} -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7e5952",
   "metadata": {},
   "source": [
    "# Weights & Biases Registry Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507ab87f",
   "metadata": {},
   "source": [
    "The goal of this notebook is to demonstrate how you and other members of your organization can use W&B Registry to track, share, and use dataset and model artifacts in your machine learning workflows. By the end of this notebook, you will know how to use W&B to:\n",
    "\n",
    "1. Create [collections](https://docs.wandb.ai/guides/registry/create_collection) within [W&B Registry](https://docs.wandb.ai/guides/registry)\n",
    "2. Make dataset and model artifacts available to other members of your organization, and\n",
    "3. Download your trained model and dataset artifacts from the registry for inference\n",
    "\n",
    "To achieve this, we will train a neural network to identify animal classes (mammal, amphibian, reptile, and so forth) based on features such as weather or not they ahve feathers, fins, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88f92cd-90ff-41cc-a656-2502799a1989",
   "metadata": {},
   "source": [
    "## Install and import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87ee0c6-4e88-4c77-9cf5-dde109bb7ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wandb torch ucimlrepo scikit-learn pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41c6701-7375-4bb0-a70f-3fdc5bff1693",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "import wandb\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fecd29-8146-41e2-86fb-0bb4e3e3350a",
   "metadata": {},
   "source": [
    "## Retrieve and process dataset\n",
    "We will use the open source [Zoo dataset](https://archive.ics.uci.edu/dataset/111/zoo) from the UCI Machine Learning Repository.\n",
    "\n",
    "### Retrieve dataset\n",
    "We can either manually download the dataset or use the [`ucimlrepo` package](https://github.com/uci-ml-repo/ucimlrepo) to import the dataset directly into our notebook. For this example, we will import the dataset directly into this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda1fc39-c06f-468c-82ad-736ca764e105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch dataset \n",
    "zoo = fetch_ucirepo(id=111) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = zoo.data.features \n",
    "y = zoo.data.targets "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9137a521-ced5-4e35-88d0-b6245527cb90",
   "metadata": {},
   "source": [
    "### Explore the data\n",
    "\n",
    "Let's take a quick look at the shape and data type of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edb34ad-02df-4256-b5de-6058c2826305",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"features: \", X.shape, \"type: \", type(X))\n",
    "print(\"labels: \", y.shape, \"type: \", type(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde2f7c4-7db7-4d09-9850-e7c6121ab775",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22eb4df0-120b-4915-8f88-c9d36637cbfc",
   "metadata": {},
   "source": [
    "### Process data\n",
    "\n",
    "For training let's convert our dataset from a [pandas `DataFrame`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html) to [a tensor with PyTorch](https://pytorch.org/docs/stable/generated/torch.tensor.html#torch.tensor), convert the data type of our input tensor(float64 to float32) to match the data type of the `nn.Linear module`, and convert our label tensor to index from 0-6:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff90527-d818-4678-bf01-3efe4c8c58a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data type of the data must match the data type of the model, the default dtype for nn.Linear is torch.float32\n",
    "dataset = torch.tensor(X.values).type(torch.float32) \n",
    "\n",
    "# Convert to tensor and format labels from 0 - 6 for indexing\n",
    "labels = torch.tensor(y.values)  - 1\n",
    "\n",
    "print(\"dataset: \", dataset.shape, \"dtype: \",dataset.dtype)\n",
    "print(\"labels: \", labels.shape, \"dtype: \",labels.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ce3c7c-193c-4c5a-90e6-ad278ff17154",
   "metadata": {},
   "source": [
    "Save processed dataset locally using [`torch.save`](https://pytorch.org/docs/stable/generated/torch.save.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46dacfb7-7493-4d36-8167-212f8b51af7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(dataset, \"zoo_dataset.pt\")\n",
    "torch.save(labels, \"zoo_labels.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c2b1fb-a1af-4311-aae9-86497d00ffda",
   "metadata": {},
   "source": [
    "## Track and publish dataset \n",
    "\n",
    "Within the Dataset registry we will create a collection called \"zoo-dataset-tensors\". A collection is a set of linked artifact versions in a registry.  \n",
    "\n",
    "To create a collection we need to do two things:\n",
    "1. Specify the collection and registry we want to link our artifact version to. To do this, we specify a \"target path\" for our artifact version.\n",
    "2. Use the `run.link_artifact` method and pass our artifact object and the target path.\n",
    "\n",
    "#### Define target path of the collection\n",
    "\n",
    "The target path of a collection consists of three parts:\n",
    "* The name of your W&B Organization\n",
    "* The name of the registry\n",
    "* The name of the collection within the registry\n",
    "\n",
    "If you know these three fields, you can create the full name yourself with string concatanation, f-strings, and so forth:\n",
    "```python\n",
    "target_path = f\"{ORG_NAME}/wandb-registry-{REGISTRY_NAME}/{COLLECTION_NAME}\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2217d9-39df-4e9a-a715-7067e9e5c731",
   "metadata": {},
   "source": [
    "### Publish dataset to registry\n",
    "\n",
    "Let's publish our dataset to the Dataset registry in a collection called \"zoo-dataset-tensors\". To do this, we will \n",
    "\n",
    "1. Get or create the target path. For this notebook we will programmatically create the target path\n",
    "1. Initialize a run\n",
    "1. Create an Artifact object\n",
    "2. Add each split dataset as individual files to the artifact object\n",
    "3. Link the artifact object to the collection with `run.link_artifact()`. Here we specify the target path and the artifact we want to link.\n",
    "\n",
    "First, let's create the target path. In the following code cell, replace the values specified in `<>` with the name of your organization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfe847c-9229-4428-873b-bde5d0c654e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ORG_NAME = \"<INSERT-YOUR-ORG-NAME>\"\n",
    "REGISTRY_NAME = \"Dataset\"\n",
    "COLLECTION_NAME = \"zoo-dataset-tensors\"\n",
    "\n",
    "# Path to link the artifact to a collection\n",
    "dataset_target_path = f\"{ORG_NAME}/wandb-registry-{REGISTRY_NAME}/{COLLECTION_NAME}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d03210-1de4-44a4-9773-67b4f5d71dfc",
   "metadata": {},
   "source": [
    "Now that we have the target path, let's publish the dataset to the \"Dataset\" registry. In the following code cell, ensure to replace the values enclosed in `<>` with your team's entity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742c237c-1e8d-4c2e-8ac4-8221146d876e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEAM_ENTITY = \"<TEAM_A>\"\n",
    "PROJECT = \"zoo_experiment\"\n",
    "\n",
    "run = wandb.init(\n",
    "    entity=TEAM_ENTITY,\n",
    "    project=PROJECT,\n",
    "    job_type=\"publish_dataset\"\n",
    ")\n",
    "\n",
    "artifact = wandb.Artifact(\n",
    "    name=\"zoo_dataset\",\n",
    "    type=\"dataset\",  \n",
    "    description=\"Processed dataset and labels.\"\n",
    ")\n",
    "\n",
    "artifact.add_file(local_path=\"zoo_dataset.pt\", name=\"zoo_dataset\")\n",
    "artifact.add_file(local_path=\"zoo_labels.pt\", name=\"zoo_labels\")\n",
    "\n",
    "run.link_artifact(artifact=artifact, target_path=dataset_target_path)\n",
    "\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383bc963-55f9-498c-b42d-a2a0bf86f3b7",
   "metadata": {},
   "source": [
    "### Split data and publish split dataset to registry\n",
    "Split the data into a training and test set. Splitting the dataset and tracking them as separate files will make it easier for a different user to use the same datasets for future reproducibility, testing, and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6432936b-31bf-477b-a4aa-a3a85345e5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decsribe how we split the training dataset for future reference, reproducibility.\n",
    "config = {\n",
    "    \"random_state\" : 42,\n",
    "    \"test_size\" : 0.25,\n",
    "    \"shuffle\" : True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5243bcd0-c3bc-4958-bb62-4ac129cbaed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    dataset,labels, \n",
    "    random_state=config[\"random_state\"],\n",
    "    test_size=config[\"test_size\"], \n",
    "    shuffle=config[\"shuffle\"]\n",
    ")\n",
    "\n",
    "# Save the files locally\n",
    "torch.save(X_train, \"zoo_dataset_X_train.pt\")\n",
    "torch.save(y_train, \"zoo_labels_y_train.pt\")\n",
    "\n",
    "torch.save(X_test, \"zoo_dataset_X_test.pt\")\n",
    "torch.save(y_test, \"zoo_labels_y_test.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028d0992-15a9-4687-8c3b-4218bf70adb9",
   "metadata": {},
   "source": [
    "Next, let's publish this dataset into a different collection within the Dataset registry called \"zoo-dataset-tensors-split\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64bacb4-5ca7-4a74-abc8-e890c655fe17",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wandb.init(\n",
    "    entity=TEAM_ENTITY,\n",
    "    project=PROJECT,\n",
    "    job_type=\"publish_split_dataset\", \n",
    "    config=config\n",
    ")\n",
    "\n",
    "# Let's add a description to let others know which file to use in future experiments\n",
    "artifact = wandb.Artifact(\n",
    "    name=\"split_zoo_dataset\",\n",
    "    type=\"dataset\", \n",
    "    description=\"Artifact contains `zoo_dataset` split into 4 datasets. \\\n",
    "                For training, use `zoo_dataset_X_train` and `zoo_labels_y_train`. \\\n",
    "                For testing, use `zoo_dataset_X_test` and `zoo_labels_y_test`.\"\n",
    ")\n",
    "\n",
    "artifact.add_file(local_path=\"zoo_dataset_X_train.pt\", name=\"zoo_dataset_X_train\")\n",
    "artifact.add_file(local_path=\"zoo_labels_y_train.pt\", name=\"zoo_labels_y_train\")\n",
    "artifact.add_file(local_path=\"zoo_dataset_X_test.pt\", name=\"zoo_dataset_X_test\")\n",
    "artifact.add_file(local_path=\"zoo_labels_y_test.pt\", name=\"zoo_labels_y_test\")\n",
    "\n",
    "REGISTRY_NAME = \"Dataset\"\n",
    "COLLECTION_NAME = \"zoo-dataset-tensors-split\"\n",
    "target_dataset_path=f\"{ORG_NAME}/wandb-registry-{REGISTRY_NAME}/{COLLECTION_NAME}\"\n",
    "\n",
    "run.link_artifact(artifact=artifact, target_path=target_dataset_path)\n",
    "\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e971ed7f-f1d3-4d62-b2ff-26135f45045f",
   "metadata": {},
   "source": [
    "We can verify we correctly linked our artifact to our desired collection and registry with W&B App UI: \n",
    "\n",
    "1. Navigate to the Registry App\n",
    "2. Select on the Dataset registry\n",
    "3. Click **View details** \"zoo-dataset-tensors-split\" collection\n",
    "4. Click the **View** button next to the artifact version\n",
    "5. Select the **Files** tab\n",
    "\n",
    "You should see four files: \"zoo_dataset_X_test\", \"zoo_dataset_X_train\", \"zoo_labels_y_test\", and \"zoo_labels_y_train\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3492dc4-f465-4843-b573-0b2ca752b0ac",
   "metadata": {},
   "source": [
    "## Define a model\n",
    "\n",
    "The following cells show how to create a simple neural network classifier with PyTorch. There is nothing unique about this model, so we'll gloss over this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c28053a-73c5-4ef4-a308-0c255c25595c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_stack = nn.Sequential(\n",
    "            nn.Linear(in_features=16 , out_features=16),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(in_features=16, out_features=7)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.linear_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c289cfc-eec8-49dc-8d93-9bd188c40545",
   "metadata": {},
   "source": [
    "### Define hyperparameters, loss function, and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def6486b-8d3a-43c6-b97e-66308b64e746",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter_config = {\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"epochs\": 1000,\n",
    "    \"model_type\": \"Multivariate_neural_network_classifier\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e485e9d4-01db-40b2-ae3d-1c7c7d1c45ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=hyperparameter_config[\"learning_rate\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052f6942-e8e9-4429-9f26-e00fbdf8b338",
   "metadata": {},
   "source": [
    "## Train model\n",
    "\n",
    "Next, let's train, save, and model artifacts to W&B.\n",
    "\n",
    "We'll train the model using the training data we published to the Dataset registry. To use the an artifact from a registry, we need to provide the name of the artifact. The name of the artifact looks similar to a filepath. In fact, this filepath is almost identical to the target path we used in a previous step to publish our artifact, except that we must specify the specific artifact version we want to use following the name of the collection: \n",
    "\n",
    "```python\n",
    "# Target path for publishing an artifact version to a registry\n",
    "f\"{ORG_NAME}/wandb-registry-{REGISTRY_NAME}/{COLLECTION_NAME}\"\n",
    "\n",
    "```\n",
    "\n",
    "```python\n",
    "# Artifact name/filepath for downloading and using artifact publsihed in a registry\n",
    "f\"{ORG_NAME}/wandb-registry-{REGISTRY_NAME}/{COLLECTION_NAME}:v{VERSION}\"\n",
    "```\n",
    "\n",
    "Since we only linked on artifact version, the version we'll use is `v0`. (W&B uses 0 indexing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1042375b-c2c8-4503-9888-a406bc9c5df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wandb.init(entity = TEAM_ENTITY, project = PROJECT, job_type = \"training\", config = hyperparameter_config)\n",
    "\n",
    "# Get dataset artifacts from registry\n",
    "VERSION = 0\n",
    "artifact_name = f\"{ORG_NAME}/wandb-registry-{REGISTRY_NAME.lower()}/{COLLECTION_NAME}:v{VERSION}\"\n",
    "dataset_artifact = run.use_artifact(artifact_or_name=artifact_name)\n",
    "\n",
    "# Download only the training data\n",
    "X_train_path = dataset_artifact.download(path_prefix=\"zoo_dataset_X_train\")\n",
    "y_train_path = dataset_artifact.download(path_prefix=\"zoo_labels_y_train\")\n",
    "\n",
    "# Load data as tensors \n",
    "X_train = torch.load(f=X_train_path+\"/zoo_dataset_X_train\")\n",
    "y_train = torch.load(f=y_train_path+\"/zoo_labels_y_train\")\n",
    "\n",
    "# Set initial dummy loss value to compare to in training loop\n",
    "prev_best_loss = 1e10 \n",
    "\n",
    "# Training loop\n",
    "for e in range(hyperparameter_config[\"epochs\"] + 1):\n",
    "    pred = model(X_train)\n",
    "    loss = loss_fn(pred, y_train.squeeze(1))\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    wandb.log({\n",
    "            \"train/epoch_ndx\": e,\n",
    "            \"train/train_loss\": loss\n",
    "        })\n",
    "\n",
    "    # Checkpoint/save model if loss improves\n",
    "    if (e % 100 == 0) and (loss <= prev_best_loss):\n",
    "        print(\"epoch: \", e, \"loss:\", loss.item())\n",
    "    \n",
    "        PATH = 'zoo_wandb.pth' \n",
    "        torch.save(model.state_dict(), PATH)\n",
    "\n",
    "        model_artifact_name = f\"zoo-{wandb.run.id}\"\n",
    "        artifact = wandb.Artifact(\n",
    "            name=model_artifact_name,\n",
    "            type=\"model\",\n",
    "            metadata={\n",
    "                \"num_classes\": 7,\n",
    "                \"model_type\": wandb.config[\"model_type\"]\n",
    "            }\n",
    "        )\n",
    "\n",
    "\n",
    "        # Store new best loss\n",
    "        prev_best_loss = loss\n",
    "\n",
    "print(f'Saving model artifact {model_artifact_name}')\n",
    "\n",
    "# Add saved model to artifact\n",
    "artifact.add_file(PATH)\n",
    "artifact.save()\n",
    "\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2666d37e-1232-4609-8e2c-78af670585ab",
   "metadata": {},
   "source": [
    "The preceeding cell might look intimidating. Let's break it down:\n",
    "\n",
    "* First, we download the dataset from the Dataset registry and load it as a tensor\n",
    "* Next, we create a simple training loop\n",
    "  * Within the training loop we log the loss for each step\n",
    "  * We checkpoint(save) the model every time the remainder of the epoch divided by 100 is 0 and the loss is lower than the previously recorded loss.\n",
    "  * We then add the saved PyTorch model to the Artifact. \n",
    "\n",
    "A couple of things to note:\n",
    "1. The preceeding code cell adds a single artifact version to W&B. You can confirm this by navigating to your project workspace, select **Artifacts** in the left navigation, and under **models** click the name of the artifact (starts with `zoo-{run.id}`). You will see a single model with version `v0`.\n",
    "2. At this point, we have only tracked the model artifact within our team's project. Anyone outside of our team does not have access to the model we created. To make this model accessible to members outside of our team, we will  need to publish our model to the registry. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05223ca1-3879-4f51-b843-76f1c25cf1f7",
   "metadata": {},
   "source": [
    "## Publish model to registry\n",
    "Let's make this model artifact available to other users in our organization. To do this, we will create a collection within the Model registry.\n",
    "\n",
    "To create a collection within a registry, we need to know the full name of the artifact. The full name of the artifact consists of the name we provided to it when we created the Artifact object and its location within our team's project.\n",
    "\n",
    "There are two ways to get the full name of an artifact, interatively with the W&B App UI or programmatically with the W&B Python SDK. In this example, we'll programmatically create the name of the artifact since we have these values loaded into memory.\n",
    "\n",
    "### Programmatically create name of artifact\n",
    "\n",
    "The full name of an artifact consists of four components:\n",
    "* Team entity\n",
    "* Project name\n",
    "* The name of the artifact (the string you passed when you created the artifact object with `wandb.Artifact()`)\n",
    "* The artifact version\n",
    "\n",
    "Putting this together, the full name of an artifact is:\n",
    "```python\n",
    "# Full name of an artifact in a team project\n",
    "artifact_name = f'{TEAM_ENTITY}/{PROJECT}/{ARTIFACT_NAME}:v{VERSION}'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc31ddfa-53e0-4b00-b010-253eef47066b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Artifact name specifies the specific artifact version within our team's project\n",
    "artifact_name = f'{TEAM_ENTITY}/{PROJECT}/{model_artifact_name}:v0'\n",
    "print(\"Artifact name: \", artifact_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aaa9221-f6ac-454b-9a48-47597f47a572",
   "metadata": {},
   "source": [
    "Now that we have the full name of our model artifact. Let's publish it to the model registry.\n",
    "\n",
    "Similar to how we created a target path when we published our dataset artifact to the Dataset registry, let's create the target path for our model artifact. The target path tells W&B the collection and registry (Model registry) to link our artifact version to. \n",
    "\n",
    "As a reminder, the target path to link an artifact to a registry consists of:\n",
    "\n",
    "```python\n",
    "# Target path used to link artifact to registry\n",
    "target_path = f\"{ORG_NAME}/wandb-registry-{REGISTRY_NAME}/{COLLECTION_NAME}\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e734592-7ab1-4baa-af04-71956a92f9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "REGISTRY_NAME = \"Model\"\n",
    "COLLECTION_NAME = \"Zoo_Classifier_Models\"\n",
    "\n",
    "target_path = f\"{ORG_NAME}/wandb-registry-{REGISTRY_NAME}/{COLLECTION_NAME}\"\n",
    "print(\"Target path: \", target_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0401783-dd12-4d2a-83e8-36bf9343e5a1",
   "metadata": {},
   "source": [
    "Putting this all together, we specify our artifact name in `run.use_artifact()` and the target path for `run.link_artifact()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4ed37c-f488-4cd8-8797-fdeb6002148e",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wandb.init(entity=TEAM_ENTITY, project=PROJECT)\n",
    "model_artifact = run.use_artifact(artifact_or_name=artifact_name, type=\"model\")\n",
    "run.link_artifact(artifact=model_artifact, target_path=target_path)\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903ac676-cf6c-4ef5-9a9f-85e1e9ee446f",
   "metadata": {},
   "source": [
    "The preceding code block links our model artifact version to a collection called \"Zoo_Classifier_Models\" within the model registry."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4e0ae2be-6cd1-41b6-9acc-a02158fb26bb",
   "metadata": {},
   "source": [
    "### View lineage map of registered model\n",
    "\n",
    "Let's say that you did not know exactly which model version to use. You can check the lineage of all artifact versions on the W&B App UI. The lineage shows which artifacts were used as input to a run and which artifacts were the output of a given run.\n",
    "\n",
    "For example, the image below shows the Zoo_Classifier_Models collection within the model registry. Highlighted in yellow is the current model artifact version that is linked to the registry.\n",
    "\n",
    "From left to right we see that the run \"trim-rain-2\" was responible for creating the \"split_zoo_dataset\" artifact. (Recall that this is the dataset artifact that contains the test and training data).\n",
    "\n",
    "We then see that the \"golden-sunset-3\" run used the \"split_zoo_dataset\" artifact for training. Within this run, we created a model artifact. The speciic artifact version we linked to Zoo_Classifier_Models is called `zoo-wyhak4o0:v10`.\n",
    "\n",
    "![](./images/dag_model_registry.png)\n",
    "\n",
    "To view the lineage map of an artifact in a registry:\n",
    "\n",
    "1. Navigate to the Registry app at https://wandb.ai/registry\n",
    "2. Click on a registry\n",
    "3. Select an artifact version \n",
    "3. Select the **Lineage** tab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8da2c69-dc5d-451b-b709-fe2822a9811c",
   "metadata": {},
   "source": [
    "---\n",
    "## Download artifacts from registry for inference\n",
    "\n",
    "For this last section, suppose you are a different user in a different team within the same organization. You and your team want to download the model and test dataset that was published to your organization's registry by a different team. You and your team will use the model and test dataset for inference and store those findings in a project called \"Check_Zoo_Model\".\n",
    "\n",
    "Note: The team member that wants do use and download published artifacts has [member role permissions](https://docs.wandb.ai/guides/registry/configure_registry#registry-roles-permissions).  This means they can view and download artifacts from the registry.\n",
    "\n",
    "How can you retrieve the artifacts version that were published by another team? Simple:\n",
    "\n",
    "1. Get the full name of the artifact version programmatically or interactively with the W&B App UI\n",
    "2. Use the W&B Python SDK to download the artifacts\n",
    "\n",
    "#### Interactively get full name of model and dataset artifacts from registry\n",
    "1. Go to the W&B Registry app at https://wandb.ai/registry/.\n",
    "2. Select the registry that your artifact is linked to.\n",
    "3. Click the **View details** button next to the name of the collection with your linked artifact. \n",
    "4. Click on the **View** button next to the artifact version. \n",
    "5. Within the **Version** tab, copy path listed next to **Full Name**.\n",
    "6. Paste the full name of the registry for the `artifact_or_name` field in `run.use_artifact()`.\n",
    "\n",
    "Note: In this example, we happen to know these values, so we'll programmatically create the full name of our model and dataset artifacts published in the registry."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bc7cfe-eef0-478d-9898-95067e37d572",
   "metadata": {},
   "source": [
    "### Get trained model from model registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0828dd-4986-4077-b469-54a60b2db2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model artifact name\n",
    "REGISTRY_NAME = \"model\"\n",
    "COLLECTION_NAME = \"Zoo_Classifier_Models\"\n",
    "VERSION = 0\n",
    "\n",
    "model_artifact_name = f\"{ORG_NAME}/wandb-registry-{REGISTRY_NAME}/{COLLECTION_NAME}:v{VERSION}\"\n",
    "print(f\"Model artifact name: {model_artifact_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6953db2-aad2-484f-8dfa-f88180288682",
   "metadata": {},
   "source": [
    "In the following code cell, ensure to replace the values enclosed in `<>` with the entity of a different team in your organization than the one you specified earlier in this notebook.\n",
    "\n",
    "Note: If you do not have another team entity, you can re-use the entity you specified earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483d258c-ed08-47f0-afca-8a2a50bb0408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter information about your team and your team's project\n",
    "DIFFERENT_TEAM_ENTITY = \"<TEAM_B>\"\n",
    "DIFFERENT_PROJECT = \"Check_Zoo_Model\"\n",
    "\n",
    "run = wandb.init(entity=DIFFERENT_TEAM_ENTITY, project=DIFFERENT_PROJECT)\n",
    "registry_model = run.use_artifact(artifact_or_name=model_artifact_name)\n",
    "local_model_path = registry_model.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca43394e-d596-4b97-947f-0314649ac0cb",
   "metadata": {},
   "source": [
    "For PyTorch models, we need to redefine our model architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6a3118-747d-4a44-a906-3d3eff41df9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_stack = nn.Sequential(\n",
    "            nn.Linear(in_features=16 , out_features=16),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(in_features=16, out_features=7)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.linear_stack(x)\n",
    "        return logits\n",
    "\n",
    "loaded_model = NeuralNetwork()\n",
    "loaded_model.load_state_dict(torch.load(f=local_model_path + \"/zoo_wandb.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93895213-e75e-46e6-b3a8-8017ccaff9e2",
   "metadata": {},
   "source": [
    "### Get test dataset from Dataset registry\n",
    "\n",
    "Let's get the test dataset from our registry. Similar to the above code block, we will specify the full name of the artifact version we want from our Dataset registry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f3fa24-4865-480f-9f56-c1dde25b0141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset artifact name\n",
    "REGISTRY_NAME = \"dataset\"\n",
    "COLLECTION_NAME = \"zoo-dataset-tensors-split\"\n",
    "VERSION = 0\n",
    "\n",
    "data_artifact_name = f\"{ORG_NAME}/wandb-registry-{REGISTRY_NAME}/{COLLECTION_NAME}:v{VERSION}\"\n",
    "print(f\"Dataset artifact name: {data_artifact_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bcfe28-b952-44a5-bc8e-868480bd1b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wandb.init(entity=DIFFERENT_TEAM_ENTITY, project=DIFFERENT_PROJECT)\n",
    "dataset_artifact = run.use_artifact(artifact_or_name=data_artifact_name, type=\"dataset\")\n",
    "local_dataset_path = dataset_artifact.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77089d70-5248-4946-be78-ce4a87bb58ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data and label filenames\n",
    "test_data_filename = \"zoo_dataset_X_test\"\n",
    "test_labels_filename = \"zoo_labels_y_test\" \n",
    "\n",
    "# Load dataset and labels into notebook\n",
    "loaded_data = torch.load(f\"{local_dataset_path}/{test_data_filename}\")\n",
    "loaded_labels = torch.load(f\"{local_dataset_path}/{test_labels_filename}\")\n",
    "\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e522de6d-9a30-4534-a85d-6d0faf56a2f0",
   "metadata": {},
   "source": [
    "### Make predictions with loaded model\n",
    "\n",
    "How does our model perform? Recall that the goal of the neural network is to predict the animall class based on features of that animal. \n",
    "\n",
    "For each prediction, our model returns an integer that refers the class. Let's create a dictionary so we can map the integer to the class name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55c9556-726a-4c65-859d-91ebf7933e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = {\n",
    "    0: \"Aves\",\n",
    "    1: \"Mammalia\",\n",
    "    2: \"Reptilia\",\n",
    "    3: \"Actinopterygii\",\n",
    "    4: \"Amphibia\",\n",
    "    5: \"Insecta\",\n",
    "    6: \"Crustacea\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548ec0e1-4be6-44b9-a6da-ad2735a8a7e6",
   "metadata": {},
   "source": [
    "Let's feed our model some data to make predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d264c840-5e69-4a2e-960b-46f09ef878ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = loaded_model(loaded_data)\n",
    "__, predicted = torch.max(outputs, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb6e86b-eafc-45b9-80d7-01a7a36ce793",
   "metadata": {},
   "source": [
    "These integers don't mean much, let's convert them to return the animal class and store this into a pandas DataFrame for us to compare the predicted vs the true values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1173dc84-0395-4b23-be84-d43a0cacd38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = list(map(lambda x: class_labels.get(x), predicted.numpy()))\n",
    "true_values = list(map(lambda x: class_labels.get(x), loaded_labels.squeeze().numpy()))\n",
    "\n",
    "# Create pandas DataFrame\n",
    "df = pd.DataFrame(\n",
    "    {\n",
    "        'Predicted': results,\n",
    "        'True values': true_values\n",
    "    }\n",
    ")\n",
    "\n",
    "# Create new column where we compare the predicted vs true\n",
    "df[\"Predicted correctly\"] = df[\"Predicted\"] == df[\"True values\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30818967-2a5a-4302-8de9-7c4ac61377bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73834173-4029-4e57-b3ae-a7d37cdd5790",
   "metadata": {},
   "source": [
    "Let's see how many it predicted corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f2e9a5-3513-4aa8-bc38-58da3f031d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count how many predictions were wrong\n",
    "df['Predicted correctly'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a489f597-adef-4a0c-999b-9d72befc1847",
   "metadata": {},
   "source": [
    "Let's view these as percentages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89019ab-be07-4854-b91b-4e7c6c37a48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get percentage \n",
    "df['Predicted correctly'].value_counts(normalize=True).mul(100).astype(str)+'%'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4326c839-f77c-48fd-b220-2255a277ad53",
   "metadata": {},
   "source": [
    "The percentage the model predicted correct might vary. As of writing this notebook, our the model correctly predicted ~88% of the time: "
   ]
  },
  {
   "cell_type": "raw",
   "id": "42d119b0-4fe3-4c6e-9b21-a9c59a7407bf",
   "metadata": {},
   "source": [
    "Predicted correctly\n",
    "True      88.46153846153845%\n",
    "False    11.538461538461538%\n",
    "Name: proportion, dtype: object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9fd561-76a8-4139-ab99-f2ac74c194dc",
   "metadata": {},
   "source": [
    "As a next step, you could dig into the examples that were incorrectly predicted and try to figure out why it predicted incorrectly. You could also try feature engineering to extract more features to train with. \n",
    "\n",
    "## Summary\n",
    "In this notebook completed each major step in a typical machine learning workflow, from downloading a dataset, processing the dataset, defining a model, training that model on processed data, checking/saving the best model, and checking how the model performed by making predictions with that model on a dataset it had not seen before.\n",
    "\n",
    "\n",
    "Throughout the process you learned how to use W&B Registry to:\n",
    "\n",
    "* Track and publish multiple datasets\n",
    "* Track and publish a model \n",
    "* Mimic how someone else in your organization (with correct permission) can download and use model and datasets published in the W&B Registry for further analysis.\n",
    "\n",
    "\n",
    "## Next steps:\n",
    "\n",
    "As the number of machine learning experiments increases, so does the complexity of keeping track of saved models and datasets. For each model version, we recommend that you document key aspects of your model such as a brief summary of the model, information about the architecture of the model, how someone can deserialize a saved model, and so forth. You can provide all of this information, and more, within the **Description** field of the model version."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "example_notebooks",
   "language": "python",
   "name": "example_notebooks"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
