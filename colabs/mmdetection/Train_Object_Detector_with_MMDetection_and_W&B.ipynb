{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/wandb/examples/blob/master/colabs/mmdetection/Train_Object_Detector_with_MMDetection_and_W&B.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "<!--- @wandbcode{mmdetection-wandb-colab} -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://wandb.me/logo-im-png\" width=\"400\" alt=\"Weights & Biases\"/> <br>\n",
    "\n",
    "<!--- @wandbcode{mmdetection-wandb-colab, v=1} -->\n",
    "\n",
    "<img src=\"http://wandb.me/mini-diagram\" width=\"600\" alt=\"Weights & Biases\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üí° Train an Object Detector with MMDetection and Weights and Biases\n",
    "\n",
    "In this colab, we will train an object detector using [MMDetection](https://mmdetection.readthedocs.io/en/latest/1_exist_data_model.html) on a tiny [Kitti](https://paperswithcode.com/dataset/kitti) dataset. Through this colab you will learn to:\n",
    "\n",
    "* use MMDetection to train an object detector on a custom dataset,\n",
    "* use [Weights and Biases](https://wandb.ai/site) to log training and validation metrics, visualize model predictions, version raw validation dataset, and more.\n",
    "\n",
    "This colab in particular, will showcase a dedicated `MMDetWandbHook` for MMDetection that can be used to:\n",
    "\n",
    "‚úÖ Log training and evaluation metrics. <br>\n",
    "‚úÖ Log versioned model checkpoints. <br>\n",
    "‚úÖ Log versioned validation dataset with ground truth bounding boxes. <br>\n",
    "‚úÖ Log and visualize model predictions.\n",
    "\n",
    "But before we continue, here's a quick summary of MMDetection and W&B if you are not familiar with them.\n",
    "\n",
    "### üì∏ MMDetection\n",
    "\n",
    "MMDetection is an open source object detection toolbox based on PyTorch. It provides composable components that are easy to customize and has out-of-box support for single and multi GPU training/inference. It also has hundreds of pretrained detection models in Model Zoo, and supports multiple standard datasets. Check out the GitHub repository [here](https://github.com/open-mmlab/mmdetection).\n",
    "\n",
    "### üì∏ Weights and Biases\n",
    "\n",
    "Consider **[Weights and Biases](https://wandb.ai/site)** (W&B) to be the GitHub for machine learning. Use W&B for machine learning experiment tracking, dataset and model versioning, project collaboration, hyperparameter optimization, dataset exploration, model evaluation and so much more. If you are new to W&B, check out this [intro colab](https://wandb.me/intro)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ‚öΩÔ∏è Imports and Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1Ô∏è‚É£ Install MMDetection\n",
    "\n",
    "MMDetection is heavily dependent on the [MMCV](https://mmcv.readthedocs.io/en/latest/#installation) library. We will have to install the version of MMCV that is compatible with the given PyTorch version. Check out the [Installation documentation](https://mmdetection.readthedocs.io/en/latest/get_started.html#installation) for more details. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install dependencies: (use cu111 because colab has CUDA 11.1)\n",
    "!pip install -qq torch==1.9.0+cu111 torchvision==0.10.0+cu111 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "\n",
    "# install mmcv-full thus we could use CUDA operators\n",
    "!pip install -qq mmcv-full -f https://download.openmmlab.com/mmcv/dist/cu111/torch1.9.0/index.html\n",
    "\n",
    "# Install mmdetection\n",
    "!rm -rf mmdetection\n",
    "!git clone -b wandb2 https://github.com/ayulockin/mmdetection/\n",
    "%cd mmdetection\n",
    "\n",
    "!pip install -e ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2Ô∏è‚É£ Install Weights and Biases\n",
    "\n",
    "Install the latest version of W&B. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qU wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3Ô∏è‚É£ General Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "\n",
    "# MMDetection\n",
    "import mmdet\n",
    "print(mmdet.__version__)\n",
    "from mmdet.datasets import build_dataset\n",
    "from mmdet.models import build_detector\n",
    "from mmdet.apis import train_detector\n",
    "from mmdet.datasets.builder import DATASETS\n",
    "from mmdet.datasets.custom import CustomDataset\n",
    "from mmdet.apis import set_random_seed\n",
    "\n",
    "# MMCV\n",
    "import mmcv\n",
    "from mmcv import Config\n",
    "\n",
    "# Weights and Biases\n",
    "import wandb\n",
    "print(wandb.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4Ô∏è‚É£ Login with you W&B account\n",
    "\n",
    "Create a free W&B account (it's free for personal and academic usage). Visit wandb.ai/authorize to get your unique authentication token. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üèÄ Dataset\n",
    "\n",
    "We will be using a tiny KITTI dataset for this colab notebook. \n",
    "\n",
    "Even though KITTI is a standard dataset for object detection, tiny KITTI can be considered as a custom dataset (lesser number of classes). MMDetection, recommends to convert the data into COCO or PASCAL VOC formats or the middle format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1Ô∏è‚É£ Download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ../\n",
    "!wget https://download.openmmlab.com/mmdetection/data/kitti_tiny.zip\n",
    "!unzip -q kitti_tiny.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls kitti_tiny"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: The `training` folder contains both training and validation data samples. This split is determined by the `train.txt` and `val.txt` files. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2Ô∏è‚É£ Build Custom Dataloader\n",
    "\n",
    "To support a new data format, it's recommended to convert the annotations to COCO format or PASCAL VOC format. You can also convert them the \"middle format\". \n",
    "\n",
    "If you are converting annotations to COCO format, do so offline and use the `CocoDataset` class. If you are converting it to the PASCAL format, use the `VOCDataset` class.\n",
    "\n",
    "In the example below, we are converting it to the middle format. The `KittiTinyDataset` class will thus inherit the `CustomDataset` class and override the `load_annotations` method. \n",
    "\n",
    "You can find more details about customizing the dataset [here](https://mmdetection.readthedocs.io/en/latest/tutorials/customize_dataset.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@DATASETS.register_module()\n",
    "class KittiTinyDataset(CustomDataset):\n",
    "\n",
    "    CLASSES = ('Car', 'Pedestrian', 'Cyclist')\n",
    "\n",
    "    def load_annotations(self, ann_file):\n",
    "        cat2label = {k: i for i, k in enumerate(self.CLASSES)}\n",
    "        # load image list from file\n",
    "        image_list = mmcv.list_from_file(self.ann_file)\n",
    "    \n",
    "        data_infos = []\n",
    "        # convert annotations to middle format\n",
    "        for image_id in image_list:\n",
    "            filename = f'{self.img_prefix}/{image_id}.jpeg'\n",
    "            image = mmcv.imread(filename)\n",
    "            height, width = image.shape[:2]\n",
    "    \n",
    "            data_info = dict(filename=f'{image_id}.jpeg', width=width, height=height)\n",
    "    \n",
    "            # load annotations\n",
    "            label_prefix = self.img_prefix.replace('image_2', 'label_2')\n",
    "            lines = mmcv.list_from_file(os.path.join(label_prefix, f'{image_id}.txt'))\n",
    "    \n",
    "            content = [line.strip().split(' ') for line in lines]\n",
    "            bbox_names = [x[0] for x in content]\n",
    "            bboxes = [[float(info) for info in x[4:8]] for x in content]\n",
    "    \n",
    "            gt_bboxes = []\n",
    "            gt_labels = []\n",
    "            gt_bboxes_ignore = []\n",
    "            gt_labels_ignore = []\n",
    "    \n",
    "            # filter 'DontCare'\n",
    "            for bbox_name, bbox in zip(bbox_names, bboxes):\n",
    "                if bbox_name in cat2label:\n",
    "                    gt_labels.append(cat2label[bbox_name])\n",
    "                    gt_bboxes.append(bbox)\n",
    "                else:\n",
    "                    gt_labels_ignore.append(-1)\n",
    "                    gt_bboxes_ignore.append(bbox)\n",
    "\n",
    "            data_anno = dict(\n",
    "                bboxes=np.array(gt_bboxes, dtype=np.float32).reshape(-1, 4),\n",
    "                labels=np.array(gt_labels, dtype=np.long),\n",
    "                bboxes_ignore=np.array(gt_bboxes_ignore,\n",
    "                                       dtype=np.float32).reshape(-1, 4),\n",
    "                labels_ignore=np.array(gt_labels_ignore, dtype=np.long))\n",
    "\n",
    "            data_info.update(ann=data_anno)\n",
    "            data_infos.append(data_info)\n",
    "\n",
    "        return data_infos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üèà Model\n",
    "\n",
    "There are over hundred pre-trained object detectors provided by MMDetection via Model Zoo. Check out the Model Zoo [documentation](https://mmdetection.readthedocs.io/en/v2.21.0/model_zoo.html) page.\n",
    "\n",
    "You can also customize the model's backbone, neck, head, ROI, and loss. More on customizing the model [here](https://mmdetection.readthedocs.io/en/latest/tutorials/customize_models.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1Ô∏è‚É£ Download the model\n",
    "\n",
    "We will be using a pretrained model checkpoint to fine tune on our custom dataset. Let's download the model in the `checkpoints` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir checkpoints\n",
    "!wget -c https://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_caffe_fpn_mstrain_3x_coco/faster_rcnn_r50_caffe_fpn_mstrain_3x_coco_20210526_095054-1f77628b.pth \\\n",
    "      -O checkpoints/faster_rcnn_r50_caffe_fpn_mstrain_3x_coco_20210526_095054-1f77628b.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ‚öæÔ∏è Configuration\n",
    "\n",
    "MMDetection relies heavily on a config system. In the cell below, we will be loading a config file and modify few of the methods as per the need of this notebook.\n",
    "\n",
    "Note that both train and test dataloaders will use the same training samples. This is not a recommended practice but for the sake of a simplified notebook, let's use it. \n",
    "\n",
    "Learn more about the MMDetection Config system [here](https://mmdetection.readthedocs.io/en/latest/tutorials/config.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1Ô∏è‚É£ Load the config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = Config.fromfile('mmdetection/configs/faster_rcnn/faster_rcnn_r50_caffe_fpn_mstrain_1x_coco.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2Ô∏è‚É£ Modify data config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define type and path to the images.\n",
    "cfg.dataset_type = 'KittiTinyDataset'\n",
    "cfg.data_root = 'kitti_tiny/'\n",
    "\n",
    "cfg.data.test.type = 'KittiTinyDataset'\n",
    "cfg.data.test.data_root = 'kitti_tiny/'\n",
    "cfg.data.test.ann_file = 'train.txt'\n",
    "cfg.data.test.img_prefix = 'training/image_2'\n",
    "\n",
    "cfg.data.train.type = 'KittiTinyDataset'\n",
    "cfg.data.train.data_root = 'kitti_tiny/'\n",
    "cfg.data.train.ann_file = 'train.txt'\n",
    "cfg.data.train.img_prefix = 'training/image_2'\n",
    "\n",
    "cfg.data.val.type = 'KittiTinyDataset'\n",
    "cfg.data.val.data_root = 'kitti_tiny/'\n",
    "cfg.data.val.ann_file = 'val.txt'\n",
    "cfg.data.val.img_prefix = 'training/image_2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3Ô∏è‚É£ Modify model config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of unique objects in the training data.\n",
    "cfg.model.roi_head.bbox_head.num_classes = 3\n",
    "# Use the pretrained model.\n",
    "cfg.load_from = 'checkpoints/faster_rcnn_r50_caffe_fpn_mstrain_3x_coco_20210526_095054-1f77628b.pth'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4Ô∏è‚É£ Modify training config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The original learning rate (LR) is set for 8-GPU training.\n",
    "# We divide it by 8 since we only use one GPU.\n",
    "cfg.optimizer.lr = 0.02 / 8\n",
    "cfg.lr_config.warmup = None\n",
    "cfg.log_config.interval = 10\n",
    "\n",
    "# Epochs\n",
    "cfg.runner.max_epochs = 12\n",
    "\n",
    "# Set seed thus the results are more reproducible\n",
    "cfg.seed = 0\n",
    "set_random_seed(0, deterministic=False)\n",
    "cfg.gpu_ids = range(1)\n",
    "\n",
    "# ‚≠êÔ∏è Set the checkpoint interval.\n",
    "cfg.checkpoint_config.interval = 1\n",
    "\n",
    "# Set up working dir to save files and logs.\n",
    "cfg.work_dir = './tutorial_exps'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5Ô∏è‚É£ Modify evaluation config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the evaluation metric since we use customized dataset.\n",
    "cfg.evaluation.metric = 'mAP'\n",
    "\n",
    "# ‚≠êÔ∏è Set the evaluation interval.\n",
    "cfg.evaluation.interval = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéæ Define Weights and Biases Hook\n",
    "\n",
    "MMDetection comes with a dedicated Weights and Biases Hook - `MMDetWandHook`. MMCV, the parent repository, has a `WandbLoggerHook` that can be used to for basic logging. \n",
    "\n",
    "With this dedicated hook, you can:\n",
    "\n",
    "* log train and eval metrics along with system (CPU/GPU) metrics, \n",
    "* visualize the validation dataset as interactive [W&B Tables](https://docs.wandb.ai/guides/data-vis),\n",
    "* visualize the model prediction as interactive W&B Tables, and\n",
    "* save the model checkpoints as [W&B Artifacts](https://docs.wandb.ai/guides/artifacts)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use this hook, you can append a dict to `log_config.hooks`. The `log_config` wraps multiple logger hooks like  the `TextLoggerHook` used below.\n",
    "\n",
    "There are four important arguments in the `MMDetWandbHook` that can help you get the most out of MMDetection. \n",
    "\n",
    "- `init_kwargs`: Use this argument to in-turn pass arguments to `wandb.init`. You can use it to set the W&B project name, set the team name entity if you want to log the runs to a team account, pass the configuration, and more. Check out what all can you pass to `wandb.init` [here](https://docs.wandb.ai/ref/python/init).\n",
    "\n",
    "- `log_checkpoint`: The model checkpoints are saved at intervals determined by `checkpoint_config.interval` (starred above). If `log_checkpoint` is `True` the saved checkpoints will be saved as versioned W&B Artifact. Note that this feature is dependent on MMCV's [`CheckpointHook`](https://mmcv.readthedocs.io/en/latest/api.html#mmcv.runner.CheckpointHook).\n",
    "\n",
    "- `log_checkpoint_metadata`: If `log_checkpoint_metadata` is True, every checkpoint artifact will have a metadata associated with it. The metadata contains the evaluation metrics computed on validation data with that checkpoint along with the current epoch. If True, it also marks the checkpoint version with the best evaluation metric with a `best` alias. You can choose the best checkpoint in the W&B Artifacts UI using this.\n",
    "\n",
    "- `num_eval_images`: At every evaluation interval, the `MMDetWandbHook` logs the model prediction as interactive W&B Tables. The eval interval is determined by `evaluation.interval` (starred above). The number of samples logged is given by `num_eval_images`. The predicted bounding boxes along with the ground truth are logged at every evaluation interval. However, the validation data is logged just once. This Feature is dependent on MMCV's [`EvalHook`](https://mmcv.readthedocs.io/en/latest/api.html#mmcv.runner.EvalHook) or [`DistEvalHook`](https://mmcv.readthedocs.io/en/latest/api.html#mmcv.runner.DistEvalHook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.log_config.hooks = [\n",
    "    dict(type='TextLoggerHook'),\n",
    "    dict(type='MMDetWandbHook',\n",
    "         init_kwargs={'project': 'MMDetection-tutorial'},\n",
    "         interval=10,\n",
    "         log_checkpoint=True,\n",
    "         log_checkpoint_metadata=True,\n",
    "         num_eval_images=10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üèê Train\n",
    "\n",
    "Now that we have the dataset, pretrained model weight, and have defined the configs. Let's stitch them together to train an object detector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1Ô∏è‚É£ Build the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build dataset\n",
    "datasets = [build_dataset(cfg.data.train)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2Ô∏è‚É£ Build the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the detector\n",
    "model = build_detector(\n",
    "    cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
    "# Add an attribute for visualization convenience\n",
    "model.CLASSES = datasets[0].CLASSES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3Ô∏è‚É£ Train with W&B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create work_dir\n",
    "# mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
    "train_detector(model, datasets, cfg, distributed=False, validate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4Ô∏è‚É£ Notes on using `MMDetWandbHook`. \n",
    "\n",
    "Using `MMDetWandbHook` is easy and in most cases it will throw friendly `UserWarning` if something is not quite right. However in the best interest, here are some of things and best practices you should keep in mind:\n",
    "\n",
    "* The `MMDetWandbHook` depends on `CheckpointHook` for logging the checkpoints as W&B Artifacts and `EvalHook`/`DistEvalHook` for logging validation data and model predictions. If anyone or both aren't available, this hook will give `UserWarning` and not cause any error. \n",
    "\n",
    "* The priority of both `CheckpointHook` and `EvalHook`/`DistEvalHook` should be more than `MMDetWandbHook`. \n",
    "\n",
    "* The validation data is logged once as `val_data` W&B Table. The evaluation tables, use reference to this data thus you will not be uploading the same data multiple times. \n",
    "\n",
    "* If you want to log the configuration to W&B, pass this key-value pair `'config': cfg._cfg_dict.to_dict()` to `init_kwargs`. "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
