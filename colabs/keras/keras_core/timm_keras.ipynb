{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/wandb/examples/blob/master/colabs/keras/keras_core/timm_keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "<!--- @wandbcode{keras_core_timm} -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://keras.io/img/logo-k-keras-wb.png\" width=\"200\" alt=\"Keras\" />\n",
    "<img src=\"https://wandb.me/logo-im-png\" width=\"400\" alt=\"Weights & Biases\" />\n",
    "<!--- @wandbcode{keras_core_timm} -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ”¥ Fine-tune a [Timm](https://huggingface.co/docs/timm/index) Model with Keras and WandB ðŸ¦„\n",
    "\n",
    "[![](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/wandb/examples/blob/master/colabs/keras/keras_core/timm_keras.ipynb)\n",
    "\n",
    "This notebook demonstrates\n",
    "- how we can fine-tune a pre-trained model from timm using [KerasCore](https://github.com/keras-team/keras-core).\n",
    "- how we can use the backend-agnostic Keras callbacks for [Weights & Biases](https://wandb.ai/site) to manage and track our experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing and Importing the Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We install the `main` branch of [KerasCore](https://github.com/keras-team/keras-core), this lets us use the latest feature merged in KerasCore.\n",
    "- We install [timm](https://huggingface.co/docs/timm/index), a library containing SOTA computer vision models, layers, utilities, optimizers, schedulers, data-loaders, augmentations, and training/evaluation scripts.\n",
    "- We also install [wandb-addons](https://github.com/soumik12345/wandb-addons), a library that hosts the backend-agnostic callbacks compatible with KerasCore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install the `main` branch of KerasCore\n",
    "!pip install -qq namex\n",
    "!apt install python3.10-venv\n",
    "!git clone --depth 1 https://github.com/soumik12345/keras-core.git && cd keras-core && python pip_build.py --install\n",
    "\n",
    "# install timm and wandb-addons\n",
    "!pip install -qq git+https://github.com/soumik12345/wandb-addons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We specify the Keras backend to be using `torch` by explicitly specifying the environment variable `KERAS_BACKEND`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import timm\n",
    "from timm.data import resolve_data_config\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.transforms.functional import InterpolationMode\n",
    "\n",
    "import wandb\n",
    "from wandb_addons.keras import WandbMetricsLogger, WandbModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We initialize a [wandb run](https://docs.wandb.ai/guides/runs) and set the configs for the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project=\"keras-torch\")\n",
    "\n",
    "config = wandb.config\n",
    "config.model_name = \"xception41\"\n",
    "config.freeze_backbone = False\n",
    "config.preprocess_config = resolve_data_config({}, model=config.model_name)\n",
    "config.dropout_rate = 0.5\n",
    "config.batch_size = 4\n",
    "config.num_epochs = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A PyTorch-based Input Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using the [ImageNette](https://github.com/fastai/imagenette) dataset for this experiment. Imagenette is a subset of 10 easily classified classes from [Imagenet](https://www.image-net.org/) (tench, English springer, cassette player, chain saw, church, French horn, garbage truck, gas pump, golf ball, parachute).\n",
    "\n",
    "First, let's download this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://s3.amazonaws.com/fast-ai-imageclas/imagenette2-320.tgz -P imagenette\n",
    "!tar zxf imagenette/imagenette2-320.tgz -C imagenette\n",
    "!gzip -d imagenette/imagenette2-320.tgz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we create our standard torch-based data loading pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define pre-processing and augmentation transforms for the train and validation sets\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(\n",
    "            size=config.preprocess_config[\"input_size\"][1],\n",
    "            interpolation=InterpolationMode.BICUBIC,\n",
    "        ),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            config.preprocess_config[\"mean\"],\n",
    "            config.preprocess_config[\"std\"]\n",
    "        )\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(config.preprocess_config[\"input_size\"][1]),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            config.preprocess_config[\"mean\"],\n",
    "            config.preprocess_config[\"std\"]\n",
    "        )\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# Define the train and validation datasets\n",
    "data_dir = 'imagenette/imagenette2-320'\n",
    "image_datasets = {\n",
    "    x: datasets.ImageFolder(\n",
    "        os.path.join(data_dir, x), data_transforms[x]\n",
    "    )\n",
    "    for x in ['train', 'val']\n",
    "}\n",
    "\n",
    "# Define the torch dataloaders corresponding to the train and validation dataset\n",
    "dataloaders = {\n",
    "    x: torch.utils.data.DataLoader(\n",
    "        image_datasets[x],\n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=4\n",
    "    )\n",
    "    for x in ['train', 'val']\n",
    "}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "# Specify the global device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at a few of the samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Display image for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array(config.preprocess_config[\"mean\"])\n",
    "    std = np.array(config.preprocess_config[\"std\"])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)\n",
    "\n",
    "\n",
    "# Get a batch of training data\n",
    "inputs, classes = next(iter(dataloaders['train']))\n",
    "print(inputs.shape, classes.shape)\n",
    "\n",
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "\n",
    "imshow(out, title=[class_names[x] for x in classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating and Training our Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We typically define a model in PyTorch using [`torch.nn.Module`s](https://pytorch.org/docs/stable/notes/modules.html) which act as the building blocks of stateful computation. Even though Keras supports PyTorch as a backend, it does not mean that we can nest torch modules inside a [`keras_core.Model`](https://keras.io/keras_core/api/models/), because trainable variables inside a Keras Model is tracked exclusively via [Keras Layers](https://keras.io/keras_core/api/layers/).\n",
    "\n",
    "KerasCore provides us with a feature called `TorchModuleWrapper` which enables us to do exactly this. The `TorchModuleWrapper` is a Keras Layer that accepts a torch module and tracks its trainable variables, essentially converting the torch module into a Keras Layer. This enables us to put any torch modules inside a Keras Model and train them with a single `model.fit()`!\n",
    "\n",
    "The idea of the `TorchModuleWrapper` was proposed by Keras' creator [FranÃ§ois Chollet](https://github.com/fchollet) on [this issue thread](https://github.com/keras-team/keras-core/issues/604)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_core as keras\n",
    "from keras_core.utils import TorchModuleWrapper\n",
    "\n",
    "\n",
    "class TimmClassifier(keras.Model):\n",
    "\n",
    "    def __init__(self, model_name, freeze_backbone, dropout_rate, num_classes, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "        # Define the pre-trained module from timm\n",
    "        self.backbone = TorchModuleWrapper(\n",
    "            timm.create_model(model_name, pretrained=True)\n",
    "        )\n",
    "        self.backbone.trainable = not freeze_backbone\n",
    "        \n",
    "        # Build the classification head using keras layers\n",
    "        self.global_average_pooling = keras.layers.GlobalAveragePooling2D()\n",
    "        self.dropout = keras.layers.Dropout(dropout_rate)\n",
    "        self.classification_head = keras.layers.Dense(num_classes)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # We get the unpooled features from the timm backbone by calling `forward_features`\n",
    "        # on the torch module corresponding to the backbone.\n",
    "        x = self.backbone.module.forward_features(inputs)\n",
    "        x = self.global_average_pooling(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.classification_head(x)\n",
    "        return keras.activations.softmax(x, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** It is actually possible to use torch modules inside a Keras Model without having to explicitly have them wrapped with the `TorchModuleWrapper` as evident by [this tweet](https://twitter.com/fchollet/status/1697381832164290754) from FranÃ§ois Chollet. However, this doesn't seem to work at the point of time this example was created, as reported in [this issue](https://github.com/keras-team/keras-core/issues/834)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we define the model and pass a random tensor to check the output shape\n",
    "model = TimmClassifier(\n",
    "    model_name=config.model_name,\n",
    "    freeze_backbone=config.freeze_backbone,\n",
    "    dropout_rate=config.dropout_rate,\n",
    "    num_classes=len(class_names)\n",
    ")\n",
    "model(torch.ones(1, *config.preprocess_config[\"input_size\"]).to(device)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, in standard Keras fashion, all we need to do is compile the model and call `model.fit()`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create exponential decay learning rate scheduler\n",
    "decay_steps = config.num_epochs * len(dataloaders[\"train\"]) // config.batch_size\n",
    "lr_scheduler = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=1e-3, decay_steps=decay_steps, decay_rate=0.1,\n",
    ")\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=keras.optimizers.Adam(lr_scheduler),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "# Define the backend-agnostic WandB callbacks for KerasCore\n",
    "callbacks = [\n",
    "    # Track experiment metrics\n",
    "    WandbMetricsLogger(log_freq=\"batch\"),\n",
    "    # Track and version model checkpoints\n",
    "    WandbModelCheckpoint(\"model.keras\")\n",
    "]\n",
    "\n",
    "# Train the model by calling model.fit\n",
    "model.fit(\n",
    "    dataloaders[\"train\"],\n",
    "    validation_data=dataloaders[\"val\"],\n",
    "    epochs=config.num_epochs,\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to know more about the backend-agnostic Keras callbacks for Weights & Biases, check out the [docs for wandb-addons](https://geekyrakshit.dev/wandb-addons/keras/keras_core/)."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
