{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://keras.io/img/logo-k-keras-wb.png\" width=\"200\" alt=\"Keras\" />\n",
        "<img src=\"https://wandb.me/logo-im-png\" width=\"400\" alt=\"Weights & Biases\" />\n",
        "<!--- @wandbcode{keras_core_timm} -->"
      ],
      "metadata": {
        "id": "dMq6cFtJl2vR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ü©∫ Medical Image Classification Tutorial using MonAI and Keras\n",
        "\n",
        "This notebook demonstrates\n",
        "- an end-to-end training using [MonAI](https://github.com/Project-MONAI/MONAI) and [KerasCore](https://github.com/keras-team/keras-core).\n",
        "- how we can use the backend-agnostic Keras callbacks for [Weights & Biases](https://wandb.ai/site) to manage and track our experiment.\n",
        "\n",
        "Original Notebook: https://github.com/Project-MONAI/tutorials/blob/main/2d_classification/mednist_tutorial.ipynb"
      ],
      "metadata": {
        "id": "2eqSE_8rl6yo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installing and Importing the Dependencies"
      ],
      "metadata": {
        "id": "Ny_HOlvymX6O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We install the `main` branch of [KerasCore](https://github.com/keras-team/keras-core), this lets us use the latest feature merged in KerasCore.\n",
        "- We install [monai](https://github.com/Project-MONAI/MONAI), a PyTorch-based, open-source framework for deep learning in healthcare imaging, part of the PyTorch Ecosystem.\n",
        "- We also install [wandb-addons](https://github.com/soumik12345/wandb-addons), a library that hosts the backend-agnostic callbacks compatible with KerasCore"
      ],
      "metadata": {
        "id": "6SvDmUxVmatW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZO1xjFtvVdqQ"
      },
      "outputs": [],
      "source": [
        "# install the `main` branch of KerasCore\n",
        "!pip install -qq namex\n",
        "!apt install python3.10-venv\n",
        "!git clone https://github.com/soumik12345/keras-core.git && cd keras-core && python pip_build.py --install\n",
        "\n",
        "# install monai and wandb-addons\n",
        "!pip install -qq git+https://github.com/soumik12345/wandb-addons\n",
        "!pip install -q \"monai-weekly[pillow, tqdm]\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We specify the Keras backend to be using `torch` by explicitly specifying the environment variable `KERAS_BACKEND`."
      ],
      "metadata": {
        "id": "c6vd3NZ-mhxs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
        "\n",
        "import shutil\n",
        "import tempfile\n",
        "import matplotlib.pyplot as plt\n",
        "import PIL\n",
        "import torch\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import keras_core as keras\n",
        "from keras_core.utils import TorchModuleWrapper\n",
        "\n",
        "from monai.apps import download_and_extract\n",
        "from monai.config import print_config\n",
        "from monai.data import decollate_batch, DataLoader\n",
        "from monai.metrics import ROCAUCMetric\n",
        "from monai.networks.nets import DenseNet121\n",
        "from monai.transforms import (\n",
        "    Activations,\n",
        "    EnsureChannelFirst,\n",
        "    AsDiscrete,\n",
        "    Compose,\n",
        "    LoadImage,\n",
        "    RandFlip,\n",
        "    RandRotate,\n",
        "    RandZoom,\n",
        "    ScaleIntensity,\n",
        ")\n",
        "from monai.utils import set_determinism\n",
        "\n",
        "import wandb\n",
        "from wandb_addons.keras import WandbMetricsLogger, WandbModelCheckpoint"
      ],
      "metadata": {
        "id": "d5ZiQmMkW-h3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We initialize a [wandb run](https://docs.wandb.ai/guides/runs) and set the configs for the experiment."
      ],
      "metadata": {
        "id": "1BvtLvxKmkSp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.init(project=\"keras-torch\")\n",
        "\n",
        "config = wandb.config\n",
        "config.batch_size = 128\n",
        "config.num_epochs = 1"
      ],
      "metadata": {
        "id": "WUt7PAsado4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup data directory\n",
        "\n",
        "You can specify a directory with the `MONAI_DATA_DIRECTORY` environment variable.\n",
        "This allows you to save results and reuse downloads.\n",
        "If not specified a temporary directory will be used."
      ],
      "metadata": {
        "id": "NE938skxmoMI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "directory = os.environ.get(\"MONAI_DATA_DIRECTORY\")\n",
        "root_dir = tempfile.mkdtemp() if directory is None else directory\n",
        "print(root_dir)"
      ],
      "metadata": {
        "id": "82KX1Sj6XXY1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download dataset\n",
        "\n",
        "The MedNIST dataset was gathered from several sets from [TCIA](https://wiki.cancerimagingarchive.net/display/Public/Data+Usage+Policies+and+Restrictions),\n",
        "[the RSNA Bone Age Challenge](http://rsnachallenges.cloudapp.net/competitions/4),\n",
        "and [the NIH Chest X-ray dataset](https://cloud.google.com/healthcare/docs/resources/public-datasets/nih-chest).\n",
        "\n",
        "The dataset is kindly made available by [Dr. Bradley J. Erickson M.D., Ph.D.](https://www.mayo.edu/research/labs/radiology-informatics/overview) (Department of Radiology, Mayo Clinic)\n",
        "under the Creative Commons [CC BY-SA 4.0 license](https://creativecommons.org/licenses/by-sa/4.0/).\n",
        "\n",
        "If you use the MedNIST dataset, please acknowledge the source."
      ],
      "metadata": {
        "id": "nkVQ-tojmzwf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resource = \"https://github.com/Project-MONAI/MONAI-extra-test-data/releases/download/0.8.1/MedNIST.tar.gz\"\n",
        "md5 = \"0bc7306e7427e00ad1c5526a6677552d\"\n",
        "\n",
        "compressed_file = os.path.join(root_dir, \"MedNIST.tar.gz\")\n",
        "data_dir = os.path.join(root_dir, \"MedNIST\")\n",
        "if not os.path.exists(data_dir):\n",
        "    download_and_extract(resource, compressed_file, root_dir, md5)"
      ],
      "metadata": {
        "id": "DAHybyvdXZoH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read image filenames from the dataset folders\n",
        "\n",
        "First of all, check the dataset files and show some statistics.  \n",
        "There are 6 folders in the dataset: Hand, AbdomenCT, CXR, ChestCT, BreastMRI, HeadCT,  \n",
        "which should be used as the labels to train our classification model."
      ],
      "metadata": {
        "id": "u6m2Uas1nMi8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = sorted(x for x in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, x)))\n",
        "num_class = len(class_names)\n",
        "image_files = [\n",
        "    [os.path.join(data_dir, class_names[i], x) for x in os.listdir(os.path.join(data_dir, class_names[i]))]\n",
        "    for i in range(num_class)\n",
        "]\n",
        "num_each = [len(image_files[i]) for i in range(num_class)]\n",
        "image_files_list = []\n",
        "image_class = []\n",
        "for i in range(num_class):\n",
        "    image_files_list.extend(image_files[i])\n",
        "    image_class.extend([i] * num_each[i])\n",
        "num_total = len(image_class)\n",
        "image_width, image_height = PIL.Image.open(image_files_list[0]).size\n",
        "\n",
        "print(f\"Total image count: {num_total}\")\n",
        "print(f\"Image dimensions: {image_width} x {image_height}\")\n",
        "print(f\"Label names: {class_names}\")\n",
        "print(f\"Label counts: {num_each}\")"
      ],
      "metadata": {
        "id": "qtLr1T0gXydq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.subplots(3, 3, figsize=(8, 8))\n",
        "for i, k in enumerate(np.random.randint(num_total, size=9)):\n",
        "    im = PIL.Image.open(image_files_list[k])\n",
        "    arr = np.array(im)\n",
        "    plt.subplot(3, 3, i + 1)\n",
        "    plt.xlabel(class_names[image_class[k]])\n",
        "    plt.imshow(arr, cmap=\"gray\", vmin=0, vmax=255)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "k4WOUb4IX6KK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare training, validation and test data lists\n",
        "\n",
        "Randomly select 10% of the dataset as validation and 10% as test."
      ],
      "metadata": {
        "id": "wOGja_mEnQ5m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val_frac = 0.1\n",
        "test_frac = 0.1\n",
        "length = len(image_files_list)\n",
        "indices = np.arange(length)\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "test_split = int(test_frac * length)\n",
        "val_split = int(val_frac * length) + test_split\n",
        "test_indices = indices[:test_split]\n",
        "val_indices = indices[test_split:val_split]\n",
        "train_indices = indices[val_split:]\n",
        "\n",
        "train_x = [image_files_list[i] for i in train_indices]\n",
        "train_y = [image_class[i] for i in train_indices]\n",
        "val_x = [image_files_list[i] for i in val_indices]\n",
        "val_y = [image_class[i] for i in val_indices]\n",
        "test_x = [image_files_list[i] for i in test_indices]\n",
        "test_y = [image_class[i] for i in test_indices]\n",
        "\n",
        "print(f\"Training count: {len(train_x)}, Validation count: \" f\"{len(val_x)}, Test count: {len(test_x)}\")"
      ],
      "metadata": {
        "id": "BmHhKta1X8ZM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define MONAI transforms, Dataset and Dataloader to pre-process data"
      ],
      "metadata": {
        "id": "Lkhtr3p8nT1G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_transforms = Compose(\n",
        "    [\n",
        "        LoadImage(image_only=True),\n",
        "        EnsureChannelFirst(),\n",
        "        ScaleIntensity(),\n",
        "        RandRotate(range_x=np.pi / 12, prob=0.5, keep_size=True),\n",
        "        RandFlip(spatial_axis=0, prob=0.5),\n",
        "        RandZoom(min_zoom=0.9, max_zoom=1.1, prob=0.5),\n",
        "    ]\n",
        ")\n",
        "\n",
        "val_transforms = Compose([LoadImage(image_only=True), EnsureChannelFirst(), ScaleIntensity()])\n",
        "\n",
        "y_pred_trans = Compose([Activations(softmax=True)])\n",
        "y_trans = Compose([AsDiscrete(to_onehot=num_class)])"
      ],
      "metadata": {
        "id": "2b5H2WuUYLsc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MedNISTDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, image_files, labels, transforms):\n",
        "        self.image_files = image_files\n",
        "        self.labels = labels\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.transforms(self.image_files[index]), self.labels[index]\n",
        "\n",
        "\n",
        "train_ds = MedNISTDataset(train_x, train_y, train_transforms)\n",
        "train_loader = DataLoader(train_ds, batch_size=config.batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "val_ds = MedNISTDataset(val_x, val_y, val_transforms)\n",
        "val_loader = DataLoader(val_ds, batch_size=config.batch_size, num_workers=2)\n",
        "\n",
        "test_ds = MedNISTDataset(test_x, test_y, val_transforms)\n",
        "test_loader = DataLoader(test_ds, batch_size=config.batch_size, num_workers=2)"
      ],
      "metadata": {
        "id": "QdFnaFUDYOaq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We typically define a model in PyTorch using [`torch.nn.Module`s](https://pytorch.org/docs/stable/notes/modules.html) which act as the building blocks of stateful computation. Even though Keras supports PyTorch as a backend, it does not mean that we can nest torch modules inside a [`keras_core.Model`](https://keras.io/keras_core/api/models/), because trainable variables inside a Keras Model is tracked exclusively via [Keras Layers](https://keras.io/keras_core/api/layers/).\n",
        "\n",
        "KerasCore provides us with a feature called `TorchModuleWrapper` which enables us to do exactly this. The `TorchModuleWrapper` is a Keras Layer that accepts a torch module and tracks its trainable variables, essentially converting the torch module into a Keras Layer. This enables us to put any torch modules inside a Keras Model and train them with a single `model.fit()`!\n",
        "\n",
        "The idea of the `TorchModuleWrapper` was proposed by Keras' creator [Fran√ßois Chollet](https://github.com/fchollet) on [this issue thread](https://github.com/keras-team/keras-core/issues/604)."
      ],
      "metadata": {
        "id": "FIhKqMrVnZV9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "inputs = keras.Input(shape=(1, 64, 64))\n",
        "outputs = TorchModuleWrapper(\n",
        "    DenseNet121(\n",
        "        spatial_dims=2, in_channels=1, out_channels=num_class\n",
        "    )\n",
        ")(inputs)\n",
        "model = keras.Model(inputs, outputs)\n",
        "\n",
        "# model = MedMnistModel()\n",
        "model(next(iter(train_loader))[0].to(device)).shape"
      ],
      "metadata": {
        "id": "7zbinqy4ZsEy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** It is actually possible to use torch modules inside a Keras Model without having to explicitly have them wrapped with the `TorchModuleWrapper` as evident by [this tweet](https://twitter.com/fchollet/status/1697381832164290754) from Fran√ßois Chollet. However, this doesn't seem to work at the point of time this example was created, as reported in [this issue](https://github.com/keras-team/keras-core/issues/834)."
      ],
      "metadata": {
        "id": "opjBI87nneYU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    optimizer=keras.optimizers.Adam(1e-5),\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "# Define the backend-agnostic WandB callbacks for KerasCore\n",
        "callbacks = [\n",
        "    # Track experiment metrics\n",
        "    WandbMetricsLogger(log_freq=\"batch\")\n",
        "]\n",
        "\n",
        "# Train the model by calling model.fit\n",
        "model.fit(\n",
        "    train_loader,\n",
        "    validation_data=val_loader,\n",
        "    epochs=config.num_epochs,\n",
        "    callbacks=callbacks,\n",
        ")\n",
        "\n",
        "wandb.finish()"
      ],
      "metadata": {
        "id": "y3H-cUKraRDh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q0E-kiGBeCnZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}