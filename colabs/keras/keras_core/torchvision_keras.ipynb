{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://keras.io/img/logo-k-keras-wb.png\" width=\"200\" alt=\"Keras\" />\n",
    "<img src=\"https://wandb.me/logo-im-png\" width=\"400\" alt=\"Weights & Biases\" />\n",
    "<!--- @wandbcode{keras_core_torchvision} -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ”¥ Fine-tune a TorchVision Model with Keras and WandB ðŸ¦„\n",
    "\n",
    "[![](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/wandb/examples/blob/master/colabs/keras/keras_core/torchvision_keras.ipynb)\n",
    "\n",
    "This notebook demonstrates\n",
    "- how we can fine-tune a pre-trained model from torchvision using [KerasCore](https://github.com/keras-team/keras-core).\n",
    "- how we can use the backend-agnostic Keras callbacks for [Weights & Biases](https://wandb.ai/site) to manage and track our experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing and Importing the Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We install the `main` branch of [KerasCore](https://github.com/keras-team/keras-core), this lets us use the latest feature merged in KerasCore.\n",
    "- We also install [wandb-addons](https://github.com/soumik12345/wandb-addons), a library that hosts the backend-agnostic callbacks compatible with KerasCore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install the `main` branch of KerasCore\n",
    "!pip install -qq namex\n",
    "!apt install python3.10-venv\n",
    "!git clone https://github.com/soumik12345/keras-core.git && cd keras-core && python pip_build.py --install\n",
    "\n",
    "# install wandb-addons\n",
    "!pip install -qq git+https://github.com/soumik12345/wandb-addons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We specify the Keras backend to be using `torch` by explicitly specifying the environment variable `KERAS_BACKEND`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "import wandb\n",
    "from wandb_addons.keras import WandbMetricsLogger, WandbModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We initialize a [wandb run](https://docs.wandb.ai/guides/runs) and set the configs for the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project=\"keras-torch\")\n",
    "\n",
    "config = wandb.config\n",
    "config.batch_size = 4\n",
    "config.num_epochs = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A PyTorch-based Input Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using the [ImageNette](https://github.com/fastai/imagenette) dataset for this experiment. Imagenette is a subset of 10 easily classified classes from [Imagenet](https://www.image-net.org/) (tench, English springer, cassette player, chain saw, church, French horn, garbage truck, gas pump, golf ball, parachute).\n",
    "\n",
    "First, let's download this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://s3.amazonaws.com/fast-ai-imageclas/imagenette2-320.tgz -P imagenette\n",
    "!tar zxf imagenette/imagenette2-320.tgz -C imagenette\n",
    "!gzip -d imagenette/imagenette2-320.tgz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we create our standard torch-based data loading pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define pre-processing and augmentation transforms for the train and validation sets\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "# Define the train and validation datasets\n",
    "data_dir = 'imagenette/imagenette2-320'\n",
    "image_datasets = {\n",
    "    x: datasets.ImageFolder(\n",
    "        os.path.join(data_dir, x), data_transforms[x]\n",
    "    )\n",
    "    for x in ['train', 'val']\n",
    "}\n",
    "\n",
    "# Define the torch dataloaders corresponding to the train and validation dataset\n",
    "dataloaders = {\n",
    "    x: torch.utils.data.DataLoader(\n",
    "        image_datasets[x],\n",
    "        batch_size=config.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=4\n",
    "    )\n",
    "    for x in ['train', 'val']\n",
    "}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "# Specify the global device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at a few of the samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Display image for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "\n",
    "\n",
    "# Get a batch of training data\n",
    "inputs, classes = next(iter(dataloaders['train']))\n",
    "print(inputs.shape, classes.shape)\n",
    "\n",
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(inputs)\n",
    "\n",
    "imshow(out, title=[class_names[x] for x in classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating and Training our Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We typically define a model in PyTorch using [`torch.nn.Module`s](https://pytorch.org/docs/stable/notes/modules.html) which act as the building blocks of stateful computation. Even though Keras supports PyTorch as a backend, it does not mean that we can nest torch modules inside a [`keras_core.Model`](https://keras.io/keras_core/api/models/), because trainable variables inside a Keras Model is tracked exclusively via [Keras Layers](https://keras.io/keras_core/api/layers/).\n",
    "\n",
    "KerasCore provides us with a feature called `TorchModuleWrapper` which enables us to do exactly this. The `TorchModuleWrapper` is a Keras Layer that accepts a torch module and tracks its trainable variables, essentially converting the torch module into a Keras Layer. This enables us to put any torch modules inside a Keras Model and train them with a single `model.fit()`!\n",
    "\n",
    "The idea of the `TorchModuleWrapper` was proposed by Keras' creator [FranÃ§ois Chollet](https://github.com/fchollet) on [this issue thread](https://github.com/keras-team/keras-core/issues/604)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_core as keras\n",
    "from keras_core.utils import TorchModuleWrapper\n",
    "\n",
    "\n",
    "class ResNet18Classifier(keras.Model):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "        # Define the pre-trained ResNet18 module from torchvision\n",
    "        resnet_18 = models.resnet18(weights='IMAGENET1K_V1')\n",
    "        num_ftrs = resnet_18.fc.in_features\n",
    "\n",
    "        # Set the classification head of the pre-trained ResNet18\n",
    "        # module to an identity module\n",
    "        resnet_18.fc = nn.Identity()\n",
    "        \n",
    "        # Set the trainable ResNet18 backbone to be a Keras Layer\n",
    "        # using `TorchModuleWrapper`\n",
    "        self.backbone = TorchModuleWrapper(resnet_18)\n",
    "\n",
    "        # Set this to `False` if you want to freeze the backbone\n",
    "        self.backbone.trainable = True\n",
    "\n",
    "        # Note that we don't convert nn.Dropout to a Keras Layer\n",
    "        # because it doesn't consist of trainable variables.\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "        # We define the classification head as a Keras Layer\n",
    "        self.fc = keras.layers.Dense(10)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.backbone(inputs)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        return keras.activations.softmax(x, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** It is actually possible to use torch modules inside a Keras Model without having to explicitly have them wrapped with the `TorchModuleWrapper` as evident by [this tweet](https://twitter.com/fchollet/status/1697381832164290754) from FranÃ§ois Chollet. However, this doesn't seem to work at the point of time this example was created, as reported in [this issue](https://github.com/keras-team/keras-core/issues/834)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we define the model and pass a random tensor to check the output shape\n",
    "model = ResNet18Classifier()\n",
    "model(torch.ones(1, 3, 224, 224).to(\"cuda\")).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, in standard Keras fashion, all we need to do is compile the model and call `model.fit()`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create exponential decay learning rate scheduler\n",
    "decay_steps = config.num_epochs * len(dataloaders[\"train\"]) // config.batch_size\n",
    "lr_scheduler = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=1e-3, decay_steps=decay_steps, decay_rate=0.1,\n",
    ")\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=keras.optimizers.Adam(lr_scheduler),\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "# Define the backend-agnostic WandB callbacks for KerasCore\n",
    "callbacks = [\n",
    "    # Track experiment metrics\n",
    "    WandbMetricsLogger(log_freq=\"batch\"),\n",
    "    # Track and version model checkpoints\n",
    "    WandbModelCheckpoint(\"model.keras\")\n",
    "]\n",
    "\n",
    "# Train the model by calling model.fit\n",
    "model.fit(\n",
    "    dataloaders[\"train\"],\n",
    "    validation_data=dataloaders[\"val\"],\n",
    "    epochs=config.num_epochs,\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to know more about the backend-agnostic Keras callbacks for Weights & Biases, check out the [docs for wandb-addons](https://geekyrakshit.dev/wandb-addons/keras/keras_core/)."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
