{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/wandb/examples/blob/master/colabs/keras/keras_nsynth_instrument_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "<!--- @wandbcode{keras-nsynth} -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NSynth Instrument Prediction using Keras\n",
    "\n",
    "<!--- @wandbcode{keras-nsynth} -->\n",
    "\n",
    "Based on the [Medium post](https://bit.ly/2UaNKQp) made by David Schwertfeger "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -Uq wandb soundfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Configuration Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_N_CLASSES = 11\n",
    "_SAMPLE_RATE = 16000\n",
    "_DURATION = 4 #seconds?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_FFT_SIZE = 1024\n",
    "_HOP_SIZE = 512\n",
    "_N_MEL_BINS = 64\n",
    "_N_SPECTROGRAM_BINS = (_FFT_SIZE // 2) + 1\n",
    "_F_MIN = 0.0\n",
    "_F_MAX = _SAMPLE_RATE / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_TRAIN_DS_SIZE = 289205  # Adjust this to reduce the amount of data during training\n",
    "_TRAIN_EPOCHS = 2\n",
    "_TRAIN_BATCH_SIZE = 256\n",
    "_TRAIN_STEPS = 40000 // _TRAIN_BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_VAL_DS_SIZE = 12678  # Adjust this to reduce the amount of data during validation\n",
    "_VAL_BATCH_SIZE = 256\n",
    "_VAL_STEPS = _VAL_DS_SIZE / _VAL_BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_TEST_DS_SIZE = 4096\n",
    "_TEST_BATCH_SIZE = 256\n",
    "_TEST_STEPS = _TEST_DS_SIZE / _TEST_BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config_defaults = {\n",
    "    #Dataset Specific\n",
    "    \"n_classes\": _N_CLASSES,\n",
    "    \"sample_rate\" : _SAMPLE_RATE,\n",
    "    \"duration\": _DURATION,\n",
    "\n",
    "    #Model specific\n",
    "    \"fft_size\" : _FFT_SIZE,\n",
    "    \"hop_size\" : _HOP_SIZE,\n",
    "    \"n_mels\" : _N_MEL_BINS,\n",
    "    \"f_min\" : _F_MIN,\n",
    "    \"f_max\" : _F_MAX,\n",
    "\n",
    "    #Training data\n",
    "    \"train_ds_size\": _TRAIN_DS_SIZE,\n",
    "    \"train_epochs\": _TRAIN_EPOCHS,\n",
    "    \"train_batch_size\": _TRAIN_BATCH_SIZE,\n",
    "    \"train_steps\": _TRAIN_STEPS,\n",
    "\n",
    "    #Validation data\n",
    "    \"val_ds_size\": _VAL_DS_SIZE,\n",
    "    \"val_batch_size\": _VAL_BATCH_SIZE,\n",
    "    \"val_steps\": _VAL_STEPS,\n",
    "\n",
    "    #Testing data\n",
    "    \"test_ds_size\": _TEST_DS_SIZE,\n",
    "    \"test_batch_size\": _TEST_BATCH_SIZE,\n",
    "    \"test_steps\": _TEST_STEPS,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = wandb.init(config = model_config_defaults, project=\"keras_nsynth_instrument_prediction-test\")\n",
    "model_config = run.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load ~~and Save Data~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load NSynth's test split as a tf.data.Dataset\n",
    "# https://www.tensorflow.org/datasets/catalog/nsynth\n",
    "(raw_train_ds, raw_validation_ds, raw_test_ds), ds_info = tfds.load(name='nsynth/full', \n",
    "               split=['train', 'valid', \"test\"],\n",
    "               try_gcs=True,\n",
    "               with_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(raw_ds, batch_size, data_type):\n",
    "  # Let's train a model to predict the instrument family from audio\n",
    "  # https://magenta.tensorflow.org/datasets/nsynth#instrument-families\n",
    "  ds = raw_ds.map(lambda x: (x['audio'], x['instrument']['family']))\n",
    "\n",
    "  # Build your input pipeline\n",
    "  if data_type in [\"train\", \"validation\"]:\n",
    "    prepped_ds = (ds\n",
    "                  .shuffle(1000, reshuffle_each_iteration=True) #is having 2 shuffles redundant?\n",
    "                  .batch(batch_size)\n",
    "                  .prefetch(tf.data.AUTOTUNE)\n",
    "                  .repeat()\n",
    "                  )\n",
    "  else:\n",
    "    prepped_ds = (ds\n",
    "                  .batch(batch_size)\n",
    "                  .prefetch(tf.data.AUTOTUNE)\n",
    "                  )\n",
    "  return prepped_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = prep_data(raw_train_ds, model_config[\"train_batch_size\"], \"train\")\n",
    "validation_ds = prep_data(raw_validation_ds, model_config[\"val_batch_size\"], \"validation\")\n",
    "test_ds = prep_data(raw_test_ds, model_config[\"test_batch_size\"], \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Causes disk error\n",
    "# tf.data.experimental.save(train_ds, \"./train\")\n",
    "# tf.data.experimental.save(validation_ds, \"./val\")\n",
    "# tf.data.experimental.save(test_ds, \"./test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_artifact = wandb.Artifact(name=\"nsynth_train\", type=\"dataset\")\n",
    "# train_data_artifact.add_dir(\"./train\")\n",
    "# run.log_artifact(train_data_artifact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_data_artifact = wandb.Artifact(name=\"nsynth_val\", type=\"dataset\")\n",
    "# val_data_artifact.add_dir(\"./val\")\n",
    "# run.log_artifact(val_data_artifact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_data_artifact = wandb.Artifact(name=\"nsynth_test\", type=\"dataset\")\n",
    "# test_data_artifact.add_dir(\"./test\")\n",
    "# run.log_artifact(test_data_artifact)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Keras Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Custom LogMel Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogMelSpectrogram(tf.keras.layers.Layer):\n",
    "    \"\"\"Compute log-magnitude mel-scaled spectrograms.\"\"\"\n",
    "\n",
    "    def __init__(self, sample_rate, fft_size, hop_size, n_mels,\n",
    "                 f_min=0.0, f_max=None, **kwargs):\n",
    "        super(LogMelSpectrogram, self).__init__(**kwargs)\n",
    "        self.sample_rate = sample_rate\n",
    "        self.fft_size = fft_size\n",
    "        self.hop_size = hop_size\n",
    "        self.n_mels = n_mels\n",
    "        self.f_min = f_min\n",
    "        self.f_max = f_max if f_max else sample_rate / 2\n",
    "        self.mel_filterbank = tf.signal.linear_to_mel_weight_matrix(\n",
    "            num_mel_bins=self.n_mels,\n",
    "            num_spectrogram_bins=fft_size // 2 + 1,\n",
    "            sample_rate=self.sample_rate,\n",
    "            lower_edge_hertz=self.f_min,\n",
    "            upper_edge_hertz=self.f_max)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.non_trainable_weights.append(self.mel_filterbank)\n",
    "        super(LogMelSpectrogram, self).build(input_shape)\n",
    "\n",
    "    def call(self, waveforms):\n",
    "        \"\"\"Forward pass.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        waveforms : tf.Tensor, shape = (None, n_samples)\n",
    "            A Batch of mono waveforms.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        log_mel_spectrograms : (tf.Tensor), shape = (None, time, freq, ch)\n",
    "            The corresponding batch of log-mel-spectrograms\n",
    "        \"\"\"\n",
    "        def _tf_log10(x):\n",
    "            numerator = tf.math.log(x)\n",
    "            denominator = tf.math.log(tf.constant(10, dtype=numerator.dtype))\n",
    "            return numerator / denominator\n",
    "\n",
    "        def power_to_db(magnitude, amin=1e-16, top_db=80.0):\n",
    "            \"\"\"\n",
    "            https://librosa.github.io/librosa/generated/librosa.core.power_to_db.html\n",
    "            \"\"\"\n",
    "            ref_value = tf.reduce_max(magnitude)\n",
    "            log_spec = 10.0 * _tf_log10(tf.maximum(amin, magnitude))\n",
    "            log_spec -= 10.0 * _tf_log10(tf.maximum(amin, ref_value))\n",
    "            log_spec = tf.maximum(log_spec, tf.reduce_max(log_spec) - top_db)\n",
    "\n",
    "            return log_spec\n",
    "\n",
    "        spectrograms = tf.signal.stft(waveforms,\n",
    "                                      frame_length=self.fft_size,\n",
    "                                      frame_step=self.hop_size,\n",
    "                                      pad_end=False)\n",
    "\n",
    "        magnitude_spectrograms = tf.abs(spectrograms)\n",
    "\n",
    "        mel_spectrograms = tf.matmul(tf.square(magnitude_spectrograms),\n",
    "                                     self.mel_filterbank)\n",
    "\n",
    "        log_mel_spectrograms = power_to_db(mel_spectrograms)\n",
    "\n",
    "        # add channel dimension\n",
    "        log_mel_spectrograms = tf.expand_dims(log_mel_spectrograms, 3)\n",
    "\n",
    "        return log_mel_spectrograms\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'fft_size': self.fft_size,\n",
    "            'hop_size': self.hop_size,\n",
    "            'n_mels': self.n_mels,\n",
    "            'sample_rate': self.sample_rate,\n",
    "            'f_min': self.f_min,\n",
    "            'f_max': self.f_max,\n",
    "        }\n",
    "        config.update(super(LogMelSpectrogram, self).get_config())\n",
    "\n",
    "        return config\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use LogMel Layer in Keras Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import (BatchNormalization, Conv2D, Dense,\n",
    "                                     Dropout, Flatten, Input, MaxPool2D)\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConvModel(n_classes, sample_rate, duration, fft_size, hop_size, n_mels, f_min=0.0, f_max=None, **kwargs):\n",
    "    n_samples = sample_rate * duration\n",
    "    input_shape = (n_samples,)\n",
    "\n",
    "    x = Input(shape=input_shape, name='input', dtype='float32')    \n",
    "    y = LogMelSpectrogram(sample_rate, fft_size, hop_size, n_mels, f_min, f_max)(x)\n",
    "    \n",
    "    # data normalization (on frequency axis)\n",
    "    y = BatchNormalization(axis=2)(y)\n",
    "    \n",
    "    # effectively 1D convolution, since kernel spans entire frequency-axis\n",
    "    y = Conv2D(32, (3, n_mels), activation='relu')(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = MaxPool2D((1, y.shape[2]))(y)\n",
    "\n",
    "    y = Conv2D(32, (3, 1), activation='relu')(y)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = MaxPool2D(pool_size=(2, 1))(y)\n",
    "\n",
    "    y = Flatten()(y)\n",
    "    y = Dense(64, activation='relu')(y)\n",
    "    y = Dropout(0.25)(y)\n",
    "    y = Dense(n_classes, activation='softmax')(y)\n",
    "\n",
    "    return Model(inputs=x, outputs=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvModel(**model_config)\n",
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['sparse_categorical_accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aside: Visualize Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install visualkeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import visualkeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualkeras.layered_view(model, to_file='model.png', legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.log({\"model_image\": wandb.Image(\"model.png\", caption=\"Visualized Keras Model\")})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wandb.keras import WandbMetricsLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"bass\", \"brass\", \"flute\", \"guitar\", \"keyboard\", \"mallet\", \"organ\", \"reed\", \"string\", \"synth_lead\", \"vocal\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_callback = WandbMetricsLogger(log_freq=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioPredictionCallback(Callback):\n",
    "    def __init__(self, labels, prediction_data, sr):\n",
    "\n",
    "          super(AudioPredictionCallback, self).__init__()\n",
    "          self.labels = labels\n",
    "          self.prediction_data = prediction_data\n",
    "          self.sr = sr\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "      id_list = []\n",
    "      input_audio = []\n",
    "      true_index = []\n",
    "      true_labels = []\n",
    "      prediction_probs_list = []\n",
    "      predicted_index = []\n",
    "      predicted_labels = []\n",
    "\n",
    "      for batch_x, batch_y in self.prediction_data:\n",
    "        prediction_probs = self.model.predict(batch_x)\n",
    "        predictions = prediction_probs.argmax(axis=1)\n",
    "\n",
    "        for x in batch_x:\n",
    "          wandb_audio = wandb.Audio(x, sample_rate=self.sr)\n",
    "          input_audio.append(wandb_audio)\n",
    "        \n",
    "        for y in batch_y:\n",
    "          true_index.append(y.numpy())\n",
    "          true_labels.append(self.labels[y])\n",
    "\n",
    "        for prediction_prob in prediction_probs:\n",
    "          prediction_probs_list.append(prediction_prob)\n",
    "\n",
    "        for pred in predictions:\n",
    "          predicted_index.append(pred)\n",
    "          predicted_labels.append(self.labels[pred])\n",
    "      \n",
    "      #All ids should match on repeate calls as the data is assumed to be never shuffled\n",
    "      id_list = list(range(len(input_audio)))\n",
    "\n",
    "      table_data = np.array([id_list, input_audio, true_labels, predicted_labels]).T\n",
    "      columns = [\"id\", \"audio\", \"true\", \"prediction\"]\n",
    "      prediction_table = wandb.Table(data=table_data, columns=columns)\n",
    "\n",
    "      prediction_table_artifact = wandb.Artifact(name=\"audio_table\", type=\"prediction\")\n",
    "      prediction_table_artifact.add(prediction_table, \"audio_table\")\n",
    "\n",
    "      acc = accuracy_score(true_labels, predicted_labels)\n",
    "\n",
    "      cm = wandb.plot.confusion_matrix(\n",
    "        y_true=true_index,\n",
    "        preds=predicted_index,\n",
    "        class_names = self.labels,\n",
    "        title=\"Confusion Matrix\")\n",
    "      pr_curve = wandb.plot.pr_curve(true_index, prediction_probs_list, labels=self.labels, title=\"Precision vs. Recall\")\n",
    "\n",
    "      run.log_artifact(prediction_table_artifact)\n",
    "      run.log({\n",
    "          \"test_cm\": cm,\n",
    "          \"test_pr_curve\": pr_curve,\n",
    "          \"test_acc\": acc\n",
    "      })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_prediction_callback = AudioPredictionCallback(labels, test_ds, model_config[\"sample_rate\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_ds, \n",
    "          epochs=model_config[\"train_epochs\"], \n",
    "          steps_per_epoch=model_config[\"train_steps\"], \n",
    "          validation_data = validation_ds,\n",
    "          validation_steps = model_config[\"val_steps\"],\n",
    "          callbacks=[wandb_callback, audio_prediction_callback],\n",
    "          verbose=\"auto\",\n",
    "          shuffle=True #Do i need this?\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.finish()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
