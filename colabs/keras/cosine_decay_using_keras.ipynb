{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/wandb/examples/blob/master/colabs/keras/cosine_decay_using_keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "<!--- @wandbcode{keras-cosine-decay} -->"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Cosine Decay with Keras\n",
    "<!--- @wandbcode{keras-cosine-decay} -->\n",
    "This notebook demonstrates how to use the Cosine Decay learning rate schedule with Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qq wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# Weights and Biases related imports\n",
    "import wandb\n",
    "from wandb.keras import WandbMetricsLogger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = dict(\n",
    "    num_classes = 10,\n",
    "    shuffle_buffer = 1024,\n",
    "    batch_size = 64,\n",
    "    image_size = 28,\n",
    "    image_channels = 1,\n",
    "    earlystopping_patience = 3,\n",
    "    learning_rate = 1e-3,\n",
    "    epochs = 10,\n",
    "    num_steps = 0.7,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "\n",
    "def parse_data(example):\n",
    "    # Get image\n",
    "    image = example[\"image\"]\n",
    "\n",
    "    # Get label\n",
    "    label = example[\"label\"]\n",
    "    label = tf.one_hot(label, depth=configs[\"num_classes\"])\n",
    "\n",
    "    return image, label\n",
    "\n",
    "\n",
    "def get_dataloader(ds, configs, dataloader_type=\"train\"):\n",
    "    dataloader = ds.map(parse_data, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "    if dataloader_type==\"train\":\n",
    "        dataloader = dataloader.shuffle(configs[\"shuffle_buffer\"])\n",
    "      \n",
    "    dataloader = (\n",
    "        dataloader\n",
    "        .batch(configs[\"batch_size\"])\n",
    "        .prefetch(AUTOTUNE)\n",
    "    )\n",
    "\n",
    "    return dataloader\n",
    "\n",
    "train_ds, valid_ds = tfds.load('fashion_mnist', split=['train', 'test'])\n",
    "\n",
    "trainloader = get_dataloader(train_ds, configs)\n",
    "validloader = get_dataloader(valid_ds, configs, dataloader_type=\"valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(configs):\n",
    "    backbone = tf.keras.applications.mobilenet_v2.MobileNetV2(weights='imagenet', include_top=False)\n",
    "    backbone.trainable = True\n",
    "\n",
    "    inputs = layers.Input(shape=(configs[\"image_size\"], configs[\"image_size\"], configs[\"image_channels\"]))\n",
    "    resize = layers.Resizing(32, 32)(inputs)\n",
    "    neck = layers.Conv2D(3, (3,3), padding=\"same\")(resize)\n",
    "    preprocess_input = tf.keras.applications.mobilenet.preprocess_input(neck)\n",
    "    x = backbone(preprocess_input)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    outputs = layers.Dense(configs[\"num_classes\"], activation=\"softmax\")(x)\n",
    "\n",
    "    return models.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "model = get_model(configs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Rate\n",
    "total_steps = len(trainloader)*configs[\"epochs\"]\n",
    "decay_steps = total_steps * configs[\"num_steps\"]\n",
    "\n",
    "cosine_decay_scheduler = tf.keras.optimizers.schedules.CosineDecay(\n",
    "    initial_learning_rate = configs[\"learning_rate\"],\n",
    "    decay_steps = decay_steps,\n",
    "    alpha=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(cosine_decay_scheduler),\n",
    "    loss = \"categorical_crossentropy\",\n",
    "    metrics = [\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a W&B run\n",
    "run = wandb.init(\n",
    "    project = \"cosine_decay\",\n",
    "    config = configs,\n",
    ")\n",
    "\n",
    "# Train your model\n",
    "model.fit(\n",
    "    trainloader,\n",
    "    epochs = configs[\"epochs\"],\n",
    "    validation_data = validloader,\n",
    "    callbacks = [\n",
    "        WandbMetricsLogger(log_freq=2),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_loss, eval_acc = model.evaluate(validloader)\n",
    "\n",
    "wandb.log({\n",
    "    \"eval_loss\": eval_loss,\n",
    "    \"eval_acc\": eval_acc\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the W&B run\n",
    "run.finish()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
