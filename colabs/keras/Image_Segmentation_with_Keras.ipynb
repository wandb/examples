{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/wandb/examples/blob/master/colabs/keras/Image_Segmentation_with_Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "<!--- @wandbcode{keras-segmentation} -->"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Setups\n",
    "<!--- @wandbcode{keras-segmentation} -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -qq wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "from wandb.keras import WandbMetricsLogger\n",
    "from wandb.keras import WandbEvalCallback\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from argparse import Namespace\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "configs = Namespace(\n",
    "    img_size = 128,\n",
    "    batch_size = 32,\n",
    "    num_classes = 3,\n",
    ")\n",
    "configs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloader\n",
    "\n",
    "We will be using Oxford Pets Dataset which we can directly get from TensorFlow Datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "train_ds, valid_ds = tfds.load('oxford_iiit_pet', split=[\"train\", \"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "\n",
    "def parse_data(example):\n",
    "    # Parse image\n",
    "    image = example[\"image\"]\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    image = tf.image.resize(image, size=(configs.img_size, configs.img_size))\n",
    "\n",
    "    # Parse mask\n",
    "    mask = example[\"segmentation_mask\"] - 1 # ground truth labels are [1,2,3].\n",
    "    mask = tf.image.resize(mask, size=(configs.img_size, configs.img_size), method='nearest')\n",
    "    mask = tf.one_hot(tf.squeeze(mask, axis=-1), depth=configs.num_classes)\n",
    "\n",
    "    return image, mask\n",
    "\n",
    "trainloader = (\n",
    "    train_ds\n",
    "    .shuffle(1024)\n",
    "    .map(parse_data, num_parallel_calls=AUTOTUNE)\n",
    "    .batch(configs.batch_size)\n",
    "    .prefetch(AUTOTUNE)\n",
    ")\n",
    "\n",
    "validloader = (\n",
    "    valid_ds\n",
    "    .map(parse_data, num_parallel_calls=AUTOTUNE)\n",
    "    .batch(configs.batch_size)\n",
    "    .prefetch(AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# ref: https://github.com/ayulockin/deepimageinpainting/blob/master/Image_Inpainting_Autoencoder_Decoder_v2_0.ipynb\n",
    "class SegmentationModel:\n",
    "    '''\n",
    "    Build UNET based model for segmentation task.\n",
    "    '''\n",
    "    def prepare_model(self, OUTPUT_CHANNEL, input_size=(configs.img_size, configs.img_size, 3)):\n",
    "        inputs = layers.Input(input_size)\n",
    "\n",
    "        conv1, pool1 = self.__ConvBlock(32, (3,3), (2,2), 'relu', 'same', inputs)\n",
    "        conv2, pool2 = self.__ConvBlock(64, (3,3), (2,2), 'relu', 'same', pool1)\n",
    "        conv3, pool3 = self.__ConvBlock(128, (3,3), (2,2), 'relu', 'same', pool2)\n",
    "        conv4, pool4 = self.__ConvBlock(256, (3,3), (2,2), 'relu', 'same', pool3)\n",
    "        \n",
    "        conv5, up6 = self.__UpConvBlock(512, 256, (3,3), (2,2), (2,2), 'relu', 'same', pool4, conv4)\n",
    "        conv6, up7 = self.__UpConvBlock(256, 128, (3,3), (2,2), (2,2), 'relu', 'same', up6, conv3)\n",
    "        conv7, up8 = self.__UpConvBlock(128, 64, (3,3), (2,2), (2,2), 'relu', 'same', up7, conv2)\n",
    "        conv8, up9 = self.__UpConvBlock(64, 32, (3,3), (2,2), (2,2), 'relu', 'same', up8, conv1)\n",
    "\n",
    "        conv9 = self.__ConvBlock(32, (3,3), (2,2), 'relu', 'same', up9, False)\n",
    "        \n",
    "        outputs = layers.Conv2D(OUTPUT_CHANNEL, (3, 3), activation='softmax', padding='same')(conv9)\n",
    "\n",
    "        return models.Model(inputs=[inputs], outputs=[outputs])  \n",
    "\n",
    "    def __ConvBlock(self, filters, kernel_size, pool_size, activation, padding, connecting_layer, pool_layer=True):\n",
    "        conv = layers.Conv2D(filters=filters, kernel_size=kernel_size, activation=activation, padding=padding)(connecting_layer)\n",
    "        conv = layers.Conv2D(filters=filters, kernel_size=kernel_size, activation=activation, padding=padding)(conv)\n",
    "        if pool_layer:\n",
    "          pool = layers.MaxPooling2D(pool_size)(conv)\n",
    "          return conv, pool\n",
    "        else:\n",
    "          return conv\n",
    "\n",
    "    def __UpConvBlock(self, filters, up_filters, kernel_size, up_kernel, up_stride, activation, padding, connecting_layer, shared_layer):\n",
    "        conv = layers.Conv2D(filters=filters, kernel_size=kernel_size, activation=activation, padding=padding)(connecting_layer)\n",
    "        conv = layers.Conv2D(filters=filters, kernel_size=kernel_size, activation=activation, padding=padding)(conv)\n",
    "        up = layers.Conv2DTranspose(filters=up_filters, kernel_size=up_kernel, strides=up_stride, padding=padding)(conv)\n",
    "        up = layers.concatenate([up, shared_layer], axis=3)\n",
    "\n",
    "        return conv, up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize Model and Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# output channel is 3 because we have three classes in our mask\n",
    "tf.keras.backend.clear_session()\n",
    "model = SegmentationModel().prepare_model(configs.num_classes)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"categorical_crossentropy\",\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "segmentation_classes = ['pet', 'pet_outline', 'background']\n",
    "\n",
    "# returns a dictionary of labels\n",
    "def labels():\n",
    "    l = {}\n",
    "    for i, label in enumerate(segmentation_classes):\n",
    "        l[i] = label\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "class WandbSemanticLogger(WandbEvalCallback):\n",
    "    def __init__(\n",
    "        self,\n",
    "        validloader,\n",
    "        data_table_columns=[\"index\", \"image\"],\n",
    "        pred_table_columns=[\"epoch\", \"index\", \"image\", \"prediction\"],\n",
    "        num_samples=100,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            data_table_columns,\n",
    "            pred_table_columns,\n",
    "        )\n",
    "\n",
    "        self.val_data = validloader.unbatch().take(num_samples)\n",
    "\n",
    "    def add_ground_truth(self, logs):\n",
    "        for idx, (image, mask) in enumerate(self.val_data):\n",
    "            self.data_table.add_data(\n",
    "                idx,\n",
    "                self._prepare_wandb_mask(\n",
    "                    image.numpy(),\n",
    "                    np.argmax(mask.numpy(), axis=-1),\n",
    "                    \"ground_truth\"\n",
    "                )\n",
    "            )\n",
    "\n",
    "    def add_model_predictions(self, epoch, logs):\n",
    "        data_table_ref = self.data_table_ref\n",
    "        table_idxs = data_table_ref.get_index()\n",
    "\n",
    "        for idx, (image, mask) in enumerate(self.val_data):\n",
    "            prediction = self.model.predict(tf.expand_dims(image, axis=0), verbose=0)\n",
    "            prediction = np.argmax(tf.squeeze(prediction, axis=0).numpy(), axis=-1)\n",
    "\n",
    "            self.pred_table.add_data(\n",
    "                epoch,\n",
    "                data_table_ref.data[idx][0],\n",
    "                self._prepare_wandb_mask(\n",
    "                    data_table_ref.data[idx][1],\n",
    "                    np.argmax(mask.numpy(), axis=-1),\n",
    "                    \"ground_truth\"\n",
    "                ),\n",
    "                self._prepare_wandb_mask(\n",
    "                    data_table_ref.data[idx][1],\n",
    "                    prediction,\n",
    "                    \"prediction\"\n",
    "                )\n",
    "            )\n",
    "\n",
    "    def _prepare_wandb_mask(self, image, mask, mask_type):\n",
    "        return wandb.Image(\n",
    "            image,\n",
    "            masks = {\n",
    "                \"ground_truth\": {\n",
    "                    \"mask_data\": mask,\n",
    "                    \"class_labels\": labels()\n",
    "            }})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "run = wandb.init(project='image-segmentation', config=configs)\n",
    "\n",
    "_ = model.fit(\n",
    "    trainloader, \n",
    "    epochs=10, \n",
    "    validation_data=validloader,\n",
    "    callbacks=[\n",
    "        WandbMetricsLogger(log_freq=2),\n",
    "        WandbSemanticLogger(validloader)\n",
    "      ]\n",
    "    )\n",
    "\n",
    "run.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
