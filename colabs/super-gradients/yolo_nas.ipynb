{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üî• Fine-tuning YOLO-NAS using Super-Gradients and Weights & Biases üêù\n",
    "\n",
    "This notebook demonstrates how to fine-tune YOLO-NAS on a custom dataset using the [Super-Graidents](https://github.com/Deci-AI/super-gradients) library and performing experiment-tracking, logging and versioning model checkpoints, and viusalizing your detection datasets and prediction results during training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing Dependencies\n",
    "\n",
    "We install [Super-Graidents](https://github.com/Deci-AI/super-gradients) and [Weights & Biases](wandb.ai/site)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qq super_gradients wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Setup\n",
    "\n",
    "First, we initialize a W&B [run](https://docs.wandb.ai/guides/runs) using `wandb.init`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "\n",
    "wandb.init(project=\"yolo-nas-integration-2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will initialize our trainer which will be in charge of the whole workflow, including the likes of training, evaluation, saving checkpoints, visualization of results, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from super_gradients.training import Trainer\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    experiment_name='transfer_learning_object_detection_yolo_nas', ckpt_root_dir=\"./checkpoints/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the Dataset\n",
    "\n",
    "Next, we fetch a subset of the [BDD100K dataset](https://www.vis.xyz/bdd100k/) hosted on Weights & Biases as a [dataset artifact](https://docs.wandb.ai/guides/artifacts). Hosting the dataset as an artifact not only enables us to maintain different versions of our datasets, but also enables us to keep track of the runs that produced it or the runs that are using it via the [lineage panel](https://docs.wandb.ai/guides/app/pages/project-page#lineage-panel)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artifact = wandb.use_artifact('geekyrakshit/yolo-nas-integration/bdd100k-subset-yolo:v2', type='dataset')\n",
    "artifact_dir = artifact.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we set up the dataset parameters, and create the dataloaders for training, validation and testing using the `coco_detection_yolo_format_train` and the `coco_detection_yolo_format_val` functions from [Super-Graidents](https://github.com/Deci-AI/super-gradients), that would automatically create the dataset loading, pre-processing and augmentation pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from super_gradients.training.dataloaders.dataloaders import (\n",
    "    coco_detection_yolo_format_train, coco_detection_yolo_format_val\n",
    ")\n",
    "\n",
    "\n",
    "with open(os.path.join(artifact_dir, \"labels.txt\"), \"r\") as f:\n",
    "    labels = f.read().split(\"\\n\")\n",
    "\n",
    "dataset_params = {\n",
    "    'data_dir': artifact_dir,\n",
    "    'train_images_dir':'train/images',\n",
    "    'train_labels_dir':'train/labels',\n",
    "    'val_images_dir':'val/images',\n",
    "    'val_labels_dir':'val/labels',\n",
    "    'test_images_dir':'test/images',\n",
    "    'test_labels_dir':'test/labels',\n",
    "    'classes': labels\n",
    "}\n",
    "\n",
    "train_data = coco_detection_yolo_format_train(\n",
    "    dataset_params={\n",
    "        'data_dir': dataset_params['data_dir'],\n",
    "        'images_dir': dataset_params['train_images_dir'],\n",
    "        'labels_dir': dataset_params['train_labels_dir'],\n",
    "        'classes': dataset_params['classes']\n",
    "    },\n",
    "    dataloader_params={\n",
    "        'batch_size':16,\n",
    "        'num_workers':2\n",
    "    }\n",
    ")\n",
    "\n",
    "val_data = coco_detection_yolo_format_val(\n",
    "    dataset_params={\n",
    "        'data_dir': dataset_params['data_dir'],\n",
    "        'images_dir': dataset_params['val_images_dir'],\n",
    "        'labels_dir': dataset_params['val_labels_dir'],\n",
    "        'classes': dataset_params['classes']\n",
    "    },\n",
    "    dataloader_params={\n",
    "        'batch_size':16,\n",
    "        'num_workers':2\n",
    "    }\n",
    ")\n",
    "\n",
    "test_data = coco_detection_yolo_format_val(\n",
    "    dataset_params={\n",
    "        'data_dir': dataset_params['data_dir'],\n",
    "        'images_dir': dataset_params['test_images_dir'],\n",
    "        'labels_dir': dataset_params['test_labels_dir'],\n",
    "        'classes': dataset_params['classes']\n",
    "    },\n",
    "    dataloader_params={\n",
    "        'batch_size':16,\n",
    "        'num_workers':2\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize our datasets using the `plot_detection_dataset_on_wandb` function on our Weights & Biases dashboard. The datasets are logged into a [Weights & Biases Table](https://docs.wandb.ai/guides/tables), in which the images can be visualized overlayed with an [interactive overlays for computer vision tasks](https://docs.wandb.ai/guides/track/log/media#image-overlays)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from super_gradients.common.plugins.wandb import plot_detection_dataset_on_wandb\n",
    "\n",
    "\n",
    "plot_detection_dataset_on_wandb(train_data.dataset, max_examples=20, dataset_name=\"Train-Dataset\")\n",
    "plot_detection_dataset_on_wandb(val_data.dataset, max_examples=20, dataset_name=\"Validation-Dataset\")\n",
    "plot_detection_dataset_on_wandb(test_data.dataset, max_examples=20, dataset_name=\"Test-Dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how the datasets look on Weights & Biases üëá"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing Transfer Learning\n",
    "\n",
    "For performing transfer learning, we first define the `YOLO_NAS_S` model as the pre-trained backbone from [Super-Graidents](https://github.com/Deci-AI/super-gradients). You can check the [Super-Gradients Model Zoo](https://docs.deci.ai/super-gradients/documentation/source/model_zoo.html#computer-vision-models-pretrained-checkpoints) for all the available pre-trained models for object detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from super_gradients.training import models\n",
    "from super_gradients.common.object_names import Models\n",
    "\n",
    "\n",
    "net = models.get(Models.YOLO_NAS_S, pretrained_weights=\"coco\", num_classes=len(dataset_params[\"classes\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Tracking with Weights & Biases\n",
    "\n",
    "Now, we define the training parameters for the experiment. In order to perform experiment tracking with Weights & Biases, in the training parameters, we set the value of `sg_logger` to `wandb_sg_logger`. You can also set the value of additional parameters for the `wandb_sg_logger` by defining them under `sg_logger_params` like\n",
    "\n",
    "```python\n",
    "train_params = {\n",
    "    ...\n",
    "    \"sg_logger\": \"wandb_sg_logger\",\n",
    "    \"sg_logger_params\": {\n",
    "        \"save_checkpoints_remote\": True,\n",
    "        \"save_tensorboard_remote\": True,\n",
    "        \"save_logs_remote\": True,\n",
    "        \"save_checkpoint_as_artifact\": True,\n",
    "    },\n",
    "}\n",
    "```\n",
    "\n",
    "Here's a complete list of params for the `wandb_sg_logger`:\n",
    "\n",
    "|Parameter|Description|Default Value|\n",
    "|---|---|---|\n",
    "|experiment_name|Name used for logging and loading purposes|   |\n",
    "|storage_location|If set to 's3' (i.e. s3://my-bucket) saves the Checkpoints in AWS S3 otherwise saves the Checkpoints Locally|   |\n",
    "|resumed|If true, then old tensorboard files will **NOT** be deleted when tb_files_user_prompt=True|   |\n",
    "|training_params|training_params for the experiment|   |\n",
    "|checkpoints_dir_path|Local root directory path where all experiment logging directories will reside.|   |\n",
    "|tb_files_user_prompt|Asks user for Tensorboard deletion prompt.|   |\n",
    "|launch_tensorboard|Whether to launch a TensorBoard process.|False|\n",
    "|tensorboard_port|Specific port number for the tensorboard to use when launched (when set to None, some free port number will be used)|False|\n",
    "|save_checkpoints_remote|Saves checkpoints in s3.|True|\n",
    "|save_tensorboard_remote|Saves tensorboard in s3.|True|\n",
    "|save_logs_remote|Saves log files in s3.|True|\n",
    "|save_code|Save current code to wandb|False|\n",
    "|save_checkpoint_as_artifact|Save model checkpoint using Weights & Biases Artifact. Note that setting this option to True would save model checkpoints every epoch as a versioned artifact, which will result in use of increased storage usage on Weights & Biases.|False|\n",
    "\n",
    "The Weights & Biases integration for Super Gradients also come with the callback `WandBDetectionValidationPredictionLoggerCallback` for logging object detection predictions to Weights & Biases during training. In order to log object detection predictions to Weights & Biases, we can include this callback in the training parameters:\n",
    "\n",
    "```python\n",
    "train_params = {\n",
    "    ...\n",
    "    \"sg_logger\": \"wandb_sg_logger\",\n",
    "    \"sg_logger_params\": {\n",
    "        \"save_checkpoints_remote\": True,\n",
    "        \"save_tensorboard_remote\": True,\n",
    "        \"save_logs_remote\": True,\n",
    "        \"save_checkpoint_as_artifact\": True,\n",
    "    },\n",
    "    \"phase_callbacks\": [\n",
    "        WandBDetectionValidationPredictionLoggerCallback(class_names=labels),\n",
    "    ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from super_gradients.training.losses import PPYoloELoss\n",
    "from super_gradients.training.metrics import DetectionMetrics_050\n",
    "from super_gradients.training.models.detection_models.pp_yolo_e import PPYoloEPostPredictionCallback\n",
    "from super_gradients.common.plugins.wandb.validation_logger import WandBDetectionValidationPredictionLoggerCallback\n",
    "\n",
    "\n",
    "train_params = {\n",
    "    'silent_mode': True,\n",
    "    \"average_best_models\":True,\n",
    "    \"warmup_mode\": \"linear_epoch_step\",\n",
    "    \"warmup_initial_lr\": 1e-6,\n",
    "    \"lr_warmup_epochs\": 3,\n",
    "    \"initial_lr\": 5e-4,\n",
    "    \"lr_mode\": \"cosine\",\n",
    "    \"cosine_final_lr_ratio\": 0.1,\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"optimizer_params\": {\"weight_decay\": 0.0001},\n",
    "    \"zero_weight_decay_on_bias_and_bn\": True,\n",
    "    \"ema\": True,\n",
    "    \"ema_params\": {\"decay\": 0.9, \"decay_type\": \"threshold\"},\n",
    "    \"max_epochs\": 10,\n",
    "    \"mixed_precision\": True,\n",
    "    \"loss\": PPYoloELoss(\n",
    "        use_static_assigner=False,\n",
    "        num_classes=len(dataset_params['classes']),\n",
    "        reg_max=16\n",
    "    ),\n",
    "    \"valid_metrics_list\": [\n",
    "        DetectionMetrics_050(\n",
    "            score_thres=0.1,\n",
    "            top_k_predictions=300,\n",
    "            # NOTE: num_classes needs to be defined here\n",
    "            num_cls=len(dataset_params['classes']),\n",
    "            normalize_targets=True,\n",
    "            post_prediction_callback=PPYoloEPostPredictionCallback(\n",
    "                score_threshold=0.01,\n",
    "                nms_top_k=1000,\n",
    "                max_predictions=300,\n",
    "                nms_threshold=0.7\n",
    "            )\n",
    "        )\n",
    "    ],\n",
    "    \"metric_to_watch\": 'mAP@0.50',\n",
    "    \"sg_logger\": \"wandb_sg_logger\",\n",
    "    \"sg_logger_params\": {\n",
    "        \"save_checkpoints_remote\": True,\n",
    "        \"save_tensorboard_remote\": True,\n",
    "        \"save_logs_remote\": True,\n",
    "        \"save_checkpoint_as_artifact\": True,\n",
    "    },\n",
    "    \"phase_callbacks\": [\n",
    "        WandBDetectionValidationPredictionLoggerCallback(class_names=labels),\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we perform the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train(model=net, training_params=train_params, train_loader=train_data, valid_loader=val_data)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
