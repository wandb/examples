{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wandb/examples/blob/ken-add-llm-examples/colabs/prompts/W%26B_LLM_QA_Bot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building an LLM App for Document Retrieval / Extraction\n",
        "This tutorial runs through [this report](https://wandb.ai/gladiator/gradient_dissent_qabot/reports/Building-a-Q-A-Bot-for-Weights-Biases-Gradient-Dissent-Podcast--Vmlldzo0MTcyMDQz) on how to build a basic LLM App for retrieval-augmented question-answering.\n",
        "- Track datasets and embeddings as artifacts\n",
        "- Track prompts and chain executions\n",
        "- Log token counts and cost"
      ],
      "metadata": {
        "id": "dQVmJG9g2zaM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ko6ccyOGiRIV"
      },
      "outputs": [],
      "source": [
        "!pip install -qqq wandb langchain pytube tiktoken openai youtube-transcript-api chromadb"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Log in to W&B\n",
        "- You can explicitly login using `wandb login` or `wandb.login()` (See below)\n",
        "- Alternatively you can set environment variables. There are several env variables which you can set to change the behavior of W&B logging. The most important are:\n",
        "    - `WANDB_API_KEY` - find this in your \"Settings\" section under your profile\n",
        "    - `WANDB_BASE_URL` - this is the url of the W&B server (You only need this if you are using a private instance)\n",
        "- Find your API Token in \"Profile\" -> \"Setttings\" in the W&B App\n",
        "\n",
        "![api_token](https://drive.google.com/uc?export=view&id=1Xn7hnn0rfPu_EW0A_-32oCXqDmpA0-kx)"
      ],
      "metadata": {
        "id": "I3t3yDP35wKc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.login()"
      ],
      "metadata": {
        "id": "spQPxgX77Wap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "import os\n",
        "\n",
        "if os.getenv(\"OPENAI_API_KEY\") is None:\n",
        "  if any(['VSCODE' in x for x in os.environ.keys()]):\n",
        "    print('Please enter password in the VS Code prompt at the top of your VS Code window!')\n",
        "  os.environ[\"OPENAI_API_KEY\"] = getpass(\"Paste your OpenAI key from: https://platform.openai.com/account/api-keys\\n\")\n",
        "\n",
        "assert os.getenv(\"OPENAI_API_KEY\", \"\").startswith(\"sk-\"), \"This doesn't look like a valid OpenAI API key\"\n",
        "print(\"OpenAI API key configured\")"
      ],
      "metadata": {
        "id": "FJaWWuCw7V73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Set up config and environment variables\n",
        "- NOTE: set the `entity` to your username or team name\n",
        "- Set wandb [environment variables](https://docs.wandb.ai/guides/track/environment-variables) to change behavior of logging\n",
        "- `ENTITY` - username or team where your projects live\n",
        "- `PROJECT` - project where your runs will live\n",
        "- `LANGCHAIN_WANDB_TRACING` - automatically logs langchain traces, inputs and outputs as part of runs in Weights and Biases"
      ],
      "metadata": {
        "id": "QVTppeTSJKuD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k3GncOVPtWSE"
      },
      "outputs": [],
      "source": [
        "from dataclasses import dataclass\n",
        "from pathlib import Path\n",
        "import os\n",
        "\n",
        "project_name = \"gradient-dissent-qabot\" #@param\n",
        "entity = \"<wandb username or team name>\" #@param\n",
        "TOTAL_EPISODES = 5\n",
        "\n",
        "@dataclass\n",
        "class Config:\n",
        "    playlist_url: str = \"https://www.youtube.com/playlist?list=PLD80i8An1OEEb1jP0sjEyiLG8ULRXFob_\"\n",
        "\n",
        "    # paths\n",
        "    root_data_dir: Path = Path(\"/contents/data\")\n",
        "    root_artifact_dir: Path = Path(\"downloaded_artifacts\")\n",
        "\n",
        "    # wandb\n",
        "    project_name: str = \"gradient_dissent_qabot\"\n",
        "    yt_podcast_data_artifact: str = f\"{entity}/{project_name}/yt_podcast_transcript:latest\"\n",
        "    summarized_data_artifact: str = f\"{entity}/{project_name}/summarized_podcasts:latest\"\n",
        "    summarized_que_data_artifact: str = (\n",
        "        f\"{entity}/{project_name}/summarized_que_podcasts:latest\"\n",
        "    )\n",
        "    transcript_embeddings_artifact: str = (\n",
        "        f\"{entity}/{project_name}/transcript_embeddings:latest\"\n",
        "    )\n",
        "\n",
        "\n",
        "os.makedirs(\"/contents/data\", exist_ok=True)\n",
        "os.environ[\"LANGCHAIN_WANDB_TRACING\"] = \"true\"\n",
        "os.environ['WANDB_PROJECT'] = project_name\n",
        "os.environ['WANDB_ENTITY'] = entity\n",
        "config = Config()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fSqpRMDBhqUH"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "from dataclasses import asdict\n",
        "\n",
        "import pandas as pd\n",
        "import wandb\n",
        "from langchain.document_loaders import YoutubeLoader\n",
        "from pytube import Playlist, YouTube\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def retry_access_yt_object(url, max_retries=5, interval_secs=5):\n",
        "    \"\"\"\n",
        "    Retries creating a YouTube object with the given URL and accessing its title several times\n",
        "    with a given interval in seconds, until it succeeds or the maximum number of attempts is reached.\n",
        "    If the object still cannot be created or the title cannot be accessed after the maximum number\n",
        "    of attempts, the last exception is raised.\n",
        "    \"\"\"\n",
        "    last_exception = None\n",
        "    for i in range(max_retries):\n",
        "        try:\n",
        "            yt = YouTube(url)\n",
        "            title = yt.title  # Access the title of the YouTube object.\n",
        "            return yt  # Return the YouTube object if successful.\n",
        "        except Exception as err:\n",
        "            last_exception = err  # Keep track of the last exception raised.\n",
        "            print(\n",
        "                f\"Failed to create YouTube object or access title. Retrying... ({i+1}/{max_retries})\"\n",
        "            )\n",
        "            time.sleep(interval_secs)  # Wait for the specified interval before retrying.\n",
        "\n",
        "    # If the YouTube object still cannot be created or the title cannot be accessed after the maximum number of attempts, raise the last exception.\n",
        "    raise last_exception"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Et8HPeJnuqZ6"
      },
      "source": [
        "## Log Data Snapshots as Artifacts\n",
        "\n",
        "W&B is very unopinionated with regard to how you track your experiments.  We could log data in any number of ways.  \n",
        "* Log one artifact which represents all the data - training, validation, and test data to one artifact\n",
        "* Log several artifacts - one for each of the training, validation, and test data loaders.  \n",
        "\n",
        "It is a matter of what best suites your needs and workflows and expectations.  \n",
        "\n",
        "### Anatomy of an artifact\n",
        "\n",
        "The `Artifact` class will correspond to an entry in the W&B Artifact registry.  The artifact has\n",
        "* a name\n",
        "* a type\n",
        "* metadata\n",
        "* description\n",
        "* files, directory of files, or references\n",
        "\n",
        "Example usage\n",
        "```\n",
        "run = wandb.init(project = \"my-project\")\n",
        "artifact = wandb.Artifact(name = \"my_artifact\", type = \"data\")\n",
        "artifact.add_file(\"/path/to/my/file.txt\")\n",
        "run.log_artifact(artifact)\n",
        "run.finish()\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run = wandb.init(project=project_name, entity=entity, job_type=\"dataset\", config=asdict(config))\n",
        "\n",
        "playlist = Playlist(config.playlist_url)\n",
        "playlist_video_urls = playlist.video_urls[0:TOTAL_EPISODES]\n",
        "\n",
        "print(f\"There are total {len(playlist_video_urls)} videos in the playlist.\")\n",
        "\n",
        "video_data = []\n",
        "for video in tqdm(playlist_video_urls, total=len(playlist_video_urls)):\n",
        "    try:\n",
        "        curr_video_data = {}\n",
        "        yt = retry_access_yt_object(video, max_retries=25, interval_secs=2)\n",
        "        curr_video_data[\"title\"] = yt.title\n",
        "        curr_video_data[\"url\"] = video\n",
        "        curr_video_data[\"duration\"] = yt.length\n",
        "        curr_video_data[\"publish_date\"] = yt.publish_date.strftime(\"%Y-%m-%d\")\n",
        "        loader = YoutubeLoader.from_youtube_url(video)\n",
        "        transcript = loader.load()[0].page_content\n",
        "        transcript = \" \".join(transcript.split())\n",
        "        curr_video_data[\"transcript\"] = transcript\n",
        "        curr_video_data[\"total_words\"] = len(transcript.split())\n",
        "        video_data.append(curr_video_data)\n",
        "    except Exception as inst:\n",
        "        print(type(inst))    # the exception type\n",
        "        print(inst.args)     # arguments stored in .args\n",
        "        print(inst)\n",
        "        print(f\"Failed to scrape {video}\")\n",
        "\n",
        "print(f\"Total podcast episodes scraped: {len(video_data)}\")\n",
        "\n",
        "# save the scraped data to a csv file\n",
        "df = pd.DataFrame(video_data)\n",
        "data_path = config.root_data_dir / \"yt_podcast_transcript.csv\"\n",
        "df.to_csv(data_path, index=False)\n",
        "\n",
        "# upload the scraped data to wandb\n",
        "artifact = wandb.Artifact(\"yt_podcast_transcript\", type=\"dataset\")\n",
        "artifact.add_file(data_path)\n",
        "run.log_artifact(artifact)\n"
      ],
      "metadata": {
        "id": "mBfjQyNL6UiX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Log a wandb Table to interact with your data\n",
        "- Here we log the dataframe of metadata about the youtube transcripts (urls, length, transcripts)\n",
        "- This allows us to interrogate the original data (filtering, grouping, etc.)"
      ],
      "metadata": {
        "id": "562NeZAfQQ-z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create wandb table\n",
        "table = wandb.Table(dataframe=df)\n",
        "run.log({\"yt_podcast_transcript\": table})\n",
        "run.finish()"
      ],
      "metadata": {
        "id": "aIN3ZOKSQOjX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summarize YouTube Transcripts\n",
        "- Here we summarize the transcripts in chunks, summarizing each chunk and then summarizing the summaries using the LangChain `load_summarize_chain`\n",
        "- We can do this in parallel since each chunk of a transcript can be summarized independently so we employ `map_reduce`"
      ],
      "metadata": {
        "id": "FvwNk5HyY8iO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from dataclasses import asdict\n",
        "\n",
        "import pandas as pd\n",
        "from langchain.callbacks import get_openai_callback\n",
        "from langchain.chains.summarize import load_summarize_chain\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.document_loaders import DataFrameLoader\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.text_splitter import TokenTextSplitter\n",
        "from tqdm import tqdm\n",
        "\n",
        "import wandb\n",
        "\n",
        "\n",
        "def get_data(artifact_name: str, total_episodes: int = None):\n",
        "    podcast_artifact = wandb.use_artifact(artifact_name, type=\"dataset\")\n",
        "    podcast_artifact_dir = podcast_artifact.download(config.root_artifact_dir)\n",
        "    filename = artifact_name.split(\":\")[0].split(\"/\")[-1]\n",
        "    df = pd.read_csv(os.path.join(podcast_artifact_dir, f\"{filename}.csv\"))\n",
        "    if total_episodes is not None:\n",
        "        df = df.iloc[:total_episodes]\n",
        "    return df\n",
        "\n",
        "\n",
        "def summarize_episode(episode_df: pd.DataFrame):\n",
        "    # load docs into langchain format\n",
        "    loader = DataFrameLoader(episode_df, page_content_column=\"transcript\")\n",
        "    data = loader.load()\n",
        "\n",
        "    # split the documents\n",
        "    text_splitter = TokenTextSplitter.from_tiktoken_encoder(chunk_size=1000, chunk_overlap=0)\n",
        "    docs = text_splitter.split_documents(data)\n",
        "    print(f\"Number of documents for podcast {data[0].metadata['title']}: {len(docs)}\")\n",
        "\n",
        "    # initialize LLM\n",
        "    llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
        "\n",
        "    # define map prompt\n",
        "    map_prompt = \"\"\"Write a concise summary of the following short transcript from a podcast.\n",
        "    Don't add your opinions or interpretations.\n",
        "\n",
        "    {text}\n",
        "\n",
        "    CONCISE SUMMARY:\"\"\"\n",
        "\n",
        "    # define combine prompt\n",
        "    combine_prompt = \"\"\"You have been provided with summaries of chunks of transcripts from a podcast.\n",
        "    Your task is to merge these intermediate summaries to create a brief and comprehensive summary of the entire podcast.\n",
        "    The summary should encompass all the crucial points of the podcast.\n",
        "    Ensure that the summary is atleast 2 paragraph long and effectively captures the essence of the podcast.\n",
        "    {text}\n",
        "\n",
        "    SUMMARY:\"\"\"\n",
        "\n",
        "    map_prompt_template = PromptTemplate(template=map_prompt, input_variables=[\"text\"])\n",
        "    combine_prompt_template = PromptTemplate(template=combine_prompt, input_variables=[\"text\"])\n",
        "\n",
        "    # initialize the summarizer chain\n",
        "    chain = load_summarize_chain(\n",
        "        llm,\n",
        "        chain_type=\"map_reduce\",\n",
        "        return_intermediate_steps=True,\n",
        "        map_prompt=map_prompt_template,\n",
        "        combine_prompt=combine_prompt_template,\n",
        "    )\n",
        "\n",
        "    summary = chain({\"input_documents\": docs})\n",
        "    return summary"
      ],
      "metadata": {
        "id": "R4sssb0AX6_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Execute Summary Chain and log results\n",
        "- Call `wandb.init(job_type=\"<my_job_type>\", config=\"my_user_defined_python_dict\")` to attach additional metadata to the run and help organize this run of your chain against all others.\n",
        "- Log the outputs of the chain like tokens used, cost, etc.\n",
        "- Log the resulting summaries as artifacts"
      ],
      "metadata": {
        "id": "JrbfcDQ9Qy-e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.init(job_type = \"summarize\",\n",
        "           config = asdict(config))\n",
        "\n",
        "# get scraped data\n",
        "df = get_data(artifact_name=config.yt_podcast_data_artifact, total_episodes=TOTAL_EPISODES)\n",
        "\n",
        "summaries = []\n",
        "with get_openai_callback() as cb:\n",
        "    for episode in tqdm(df.iterrows(), total=len(df), desc=\"Summarizing episodes\"):\n",
        "        episode_data = episode[1].to_frame().T\n",
        "\n",
        "        summary = summarize_episode(episode_data)\n",
        "        summaries.append(summary[\"output_text\"])\n",
        "\n",
        "    print(\"*\" * 25)\n",
        "    print(cb)\n",
        "    print(\"*\" * 25)\n",
        "\n",
        "    wandb.log(\n",
        "        {\n",
        "            \"total_prompt_tokens\": cb.prompt_tokens,\n",
        "            \"total_completion_tokens\": cb.completion_tokens,\n",
        "            \"total_tokens\": cb.total_tokens,\n",
        "            \"total_cost\": cb.total_cost,\n",
        "        }\n",
        "    )\n",
        "\n",
        "df[\"summary\"] = summaries\n",
        "\n",
        "# save data\n",
        "path_to_save = os.path.join(config.root_data_dir, \"summarized_podcasts.csv\")\n",
        "df.to_csv(path_to_save, index=False)\n",
        "\n",
        "# log to wandb artifact\n",
        "artifact = wandb.Artifact(\"summarized_podcasts\", type=\"dataset\")\n",
        "artifact.add_file(path_to_save)\n",
        "wandb.log_artifact(artifact)\n",
        "\n",
        "# create wandb table\n",
        "table = wandb.Table(dataframe=df)\n",
        "wandb.log({\"summarized_podcasts\": table})\n",
        "\n",
        "wandb.finish()"
      ],
      "metadata": {
        "id": "rixol7KcYYdj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Embed the contents of the YouTube transcripts\n",
        "- Here we use OpenAI embeddings and [ChromaDB](https://www.trychroma.com/) to embed the summaries to make them queriable via vector similarity search when we ask contextual questions to the LLM\n",
        "- Use `wandb.log` and artifacts to log the resulting ChromaDB serialized embeddings."
      ],
      "metadata": {
        "id": "Qy-pRGM7FLkR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GaiqnOimiP_0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from dataclasses import asdict\n",
        "\n",
        "import pandas as pd\n",
        "from langchain.callbacks import get_openai_callback\n",
        "from langchain.document_loaders import DataFrameLoader\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import TokenTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "from tqdm import tqdm\n",
        "from wandb.integration.langchain import WandbTracer\n",
        "\n",
        "import wandb\n",
        "\n",
        "\n",
        "def get_data(artifact_name: str, total_episodes=None):\n",
        "    podcast_artifact = wandb.use_artifact(artifact_name, type=\"dataset\")\n",
        "    podcast_artifact_dir = podcast_artifact.download(config.root_artifact_dir)\n",
        "    filename = artifact_name.split(\":\")[0].split(\"/\")[-1]\n",
        "    df = pd.read_csv(os.path.join(podcast_artifact_dir, f\"{filename}.csv\"))\n",
        "    if total_episodes is not None:\n",
        "        df = df.iloc[:total_episodes]\n",
        "    return df\n",
        "\n",
        "\n",
        "def create_embeddings(episode_df: pd.DataFrame, index: int):\n",
        "    # load docs into langchain format\n",
        "    loader = DataFrameLoader(episode_df, page_content_column=\"transcript\")\n",
        "    data = loader.load()\n",
        "\n",
        "    # split the documents\n",
        "    text_splitter = TokenTextSplitter.from_tiktoken_encoder(chunk_size=1000, chunk_overlap=0)\n",
        "    docs = text_splitter.split_documents(data)\n",
        "\n",
        "    title = data[0].metadata[\"title\"]\n",
        "    print(f\"Number of documents for podcast {title}: {len(docs)}\")\n",
        "\n",
        "    # initialize embedding engine\n",
        "    embeddings = OpenAIEmbeddings()\n",
        "\n",
        "    db = Chroma.from_documents(\n",
        "        docs,\n",
        "        embeddings,\n",
        "        persist_directory=os.path.join(config.root_data_dir / \"chromadb\", str(index)),\n",
        "    )\n",
        "    db.persist()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.init(job_type=\"embed_transcripts\",\n",
        "           config=asdict(config))\n",
        "\n",
        "# get data\n",
        "df = get_data(artifact_name=config.summarized_data_artifact, total_episodes=TOTAL_EPISODES)\n",
        "\n",
        "# create embeddings\n",
        "with get_openai_callback() as cb:\n",
        "    for episode in tqdm(df.iterrows(), total=len(df), desc=\"Embedding transcripts\"):\n",
        "        episode_data = episode[1].to_frame().T\n",
        "\n",
        "        create_embeddings(episode_data, index=episode[0])\n",
        "\n",
        "    print(\"*\" * 25)\n",
        "    print(cb)\n",
        "    print(\"*\" * 25)\n",
        "\n",
        "    wandb.log(\n",
        "        {\n",
        "            \"total_prompt_tokens\": cb.prompt_tokens,\n",
        "            \"total_completion_tokens\": cb.completion_tokens,\n",
        "            \"total_tokens\": cb.total_tokens,\n",
        "            \"total_cost\": cb.total_cost,\n",
        "        }\n",
        "    )\n",
        "\n",
        "# log embeddings to wandb artifact\n",
        "artifact = wandb.Artifact(\"transcript_embeddings\", type=\"dataset\")\n",
        "artifact.add_dir(config.root_data_dir / \"chromadb\")\n",
        "wandb.log_artifact(artifact)\n",
        "\n",
        "wandb.finish()"
      ],
      "metadata": {
        "id": "aZ9WNHQaGLWc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ask Questions Against your Summarized Documents\n",
        "- Finally we tie everything together\n",
        "1. We can pull down our ChromaDB embeddings from W&B\n",
        "2. Pass them along with a prompt template for QA to the `RetrievalQA` chain and start asking questions!"
      ],
      "metadata": {
        "id": "BmvO-2Z8SJdU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "\n",
        "def get_answer(podcast: str, question: str):\n",
        "  index = df[df[\"title\"] == podcast].index[0]\n",
        "  db_dir = os.path.join(chromadb_dir, str(index))\n",
        "  embeddings = OpenAIEmbeddings()\n",
        "  db = Chroma(persist_directory=db_dir, embedding_function=embeddings)\n",
        "\n",
        "  prompt_template = \"\"\"Use the following pieces of context to answer the question.\n",
        "  If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
        "  Don't add your opinions or interpretations. Ensure that you complete the answer.\n",
        "  If the question is not relevant to the context, just say that it is not relevant.\n",
        "\n",
        "  CONTEXT:\n",
        "  {context}\n",
        "\n",
        "  QUESTION: {question}\n",
        "\n",
        "  ANSWER:\"\"\"\n",
        "\n",
        "  prompt = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
        "\n",
        "  retriever = db.as_retriever()\n",
        "  retriever.search_kwargs[\"k\"] = 2\n",
        "\n",
        "  qa = RetrievalQA.from_chain_type(\n",
        "      llm=ChatOpenAI(temperature=0),\n",
        "      chain_type=\"stuff\",\n",
        "      retriever=retriever,\n",
        "      chain_type_kwargs={\"prompt\": prompt},\n",
        "      return_source_documents=True,\n",
        "  )\n",
        "\n",
        "  with get_openai_callback() as cb:\n",
        "      result = qa({\"query\": question})\n",
        "      print(cb)\n",
        "\n",
        "  answer = result[\"result\"]\n",
        "  return answer"
      ],
      "metadata": {
        "id": "uxtRzXvBSiYl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download and read data\n",
        "api = wandb.Api()\n",
        "artifact_df = api.artifact(config.summarized_data_artifact)\n",
        "artifact_df.download(config.root_data_dir)\n",
        "\n",
        "artifact_embeddings = api.artifact(config.transcript_embeddings_artifact)\n",
        "chromadb_dir = artifact_embeddings.download(config.root_data_dir / \"chromadb\")\n",
        "\n",
        "df_path = config.root_data_dir / \"summarized_podcasts.csv\"\n",
        "df = pd.read_csv(df_path)"
      ],
      "metadata": {
        "id": "6pIOIEon2fzm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"title\"].tolist()[0:TOTAL_EPISODES]"
      ],
      "metadata": {
        "id": "_mQKlD1C4uxO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.init(job_type=\"retrievalQA\", config=asdict(config))\n",
        "\n",
        "answer = get_answer('Enabling LLM-Powered Applications with Harrison Chase of LangChain', \"What did Harrison Chase say?\")\n",
        "print(answer)\n",
        "\n",
        "wandb.finish()"
      ],
      "metadata": {
        "id": "0r4gKa0p2l6k"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMqwucGcuYKlRO5Ds95/Rv3",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}