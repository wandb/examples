{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/wandb/examples/blob/master/colabs/openai/OpenAI_API_Autologger_Quickstart.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "<!--- @wandbcode{openai-autologger-colab} -->"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://wandb.me/logo-im-png\" width=\"400\" alt=\"Weights & Biases\" />\n",
    "<!--- @wandbcode{openai-autologger-colab} -->"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üèÉ‚Äç‚ôÄÔ∏è OpenAI API Logger\n",
    "Use the **[Weights & Biases](https://wandb.ai/site?utm_source=openai_autologger_colab&utm_medium=code&utm_campaign=openai_autologger)** OpenAI API logger to seamlessly log all all inputs and outputs to your OpenAI API. See the full Weights & Biases **[OpenAI Autologger Documentationhere](https://docs.wandb.ai/guides/integrations/openai)** for more\n",
    "\n",
    "### Logging with just 1 line of code\n",
    "With just 1 line of code you can log all of the inputs and outputs from your OpenAI python libray to Weights & Biases for analysis later\n",
    "\n",
    "1Ô∏è‚É£. **Call autolog** and login to wandb with your wandb api key\n",
    "\n",
    "2Ô∏è‚É£. **Run OpenAI API** to generate preductions as normal\n",
    "\n",
    "3Ô∏è‚É£. **Visualize results** by doing to the wandb run link generated in step 1Ô∏è‚É£"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü™Ñ 1. Install `wandb` and `openai`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "!pip install wandb openai -qU"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü™Ñ 2. Import and call `autolog`\n",
    "\n",
    "When you call `autolog` you will be prompted to login to Weights & Biases with your api key, which you can find at https://www.wandb.ai/authorize\n",
    "\n",
    "\n",
    "You can optionally pass a dictionary with arguments for [wandb.init()](https://docs.wandb.ai/ref/python/init) such as a project name, team name, entity, and more. For more information about wandb.init, see the [API Reference Guide](https://docs.wandb.ai/ref/python/init)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "from wandb.integration.openai import autolog\n",
    "\n",
    "autolog({\"project\":\"my_llm_project\"})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you login, a **Weights & Biases run link will be generated**. This will take you to your workspace where you will be able to see all of the inputs and outputs to your OpenAI API calls."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü™Ñ 3. Use the OpenAI API as normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# pass your OpenAI key\n",
    "import openai\n",
    "openai.api_key = \"sk-foo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# make some calls to OpenAI \n",
    "# Call 1\n",
    "chat_request_kwargs = dict(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Who won the superbowl in 2014?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"The Seattle Seahawks\"},\n",
    "        {\"role\": \"user\", \"content\": \"Where was it played?\"},\n",
    "    ],\n",
    ")\n",
    "\n",
    "response_1 = openai.ChatCompletion.create(**chat_request_kwargs)\n",
    "print(response_1)\n",
    "\n",
    "# Call 2\n",
    "chat_request_kwargs = dict(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"The Los Angeles Dodgers\"},\n",
    "        {\"role\": \"user\", \"content\": \"Where was it played?\"},\n",
    "    ],\n",
    ")\n",
    "\n",
    "response_2 = openai.ChatCompletion.create(**chat_request_kwargs)\n",
    "print(response_2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü™Ñ 4. View your logged results in Weights & Biases\n",
    "- You can find your interactive dashboard by clicking the üëÜ wandb links above in step (2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü™Ñ 5. Disable `autolog`\n",
    "Call disable() to close all W&B processes when you are finished using the OpenAI API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "autolog.disable()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What's next üöÄ ?\n",
    "Doing more advanced LLM system chaining or using LangChain?\n",
    "## üëâ [Try W&B Prompts to understand your LLM systems](https://docs.wandb.ai/guides/prompts?utm_source=openai_api_colab&utm_medium=code&utm_campaign=openai_api_colab)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
