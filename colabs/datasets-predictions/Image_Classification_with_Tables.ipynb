{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/wandb/examples/blob/master/colabs/datasets-predictions/Image_Classification_with_Tables.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.imgur.com/gb6B4ig.png\" width=\"400\" alt=\"Weights & Biases\" />\n",
    "\n",
    "<!--- @wandbcode{tables_mendeleev} -->\n",
    "\n",
    "# Image Classification with W&B Tables\n",
    "\n",
    "This is a walkthrough of [Tables for visualization](https://docs.wandb.ai/guides/data-vis/tables) and [Artifacts for versioning](https://docs.wandb.com/artifacts) deep learning models in Weights & Biases. As an example, I finetune a convnet in Keras on photos from  [iNaturalist 2017](https://github.com/visipedia/inat_comp/tree/master/2017) to identify 10 classes of living things (plants, insects, birds, etc). \n",
    "\n",
    "<img src=\"https://i.imgur.com/PK4VA6u.png\"\n",
    "alt=\"Table comparison example\"/>\n",
    "\n",
    "## [Explore more examples in this W&B Report](https://wandb.ai/stacey/mendeleev/reports/DSViz-for-Image-Classification--VmlldzozNjE3NjA)\n",
    "\n",
    "\n",
    "## Sign up or login\n",
    "\n",
    "[Sign up or login](https://wandb.ai/login) to W&B to see and interact with your experiments in the browser.\n",
    "\n",
    "In this example we're using Google Colab as a convenient hosted environment, but you can run your own training scripts from anywhere and visualize metrics with W&B's experiment tracking tool."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download sample data: Choose 1 of 4 sizes\n",
    "\n",
    "Choose one of the three dataset size options below to run the rest of the demo. With fewer images, you'll run through the demo much faster and use less storage space. With more images, you'll get more realistic model training and more interesting results and examples to explore.\n",
    "\n",
    "Note: **for the largest dataset, this stage might take a few minutes**. If you end up needing to rerun a cell, comment out the first capture line (change ```%%capture``` to ```#%%capture``` ) so you can respond to the prompt about re-downloading the dataset (and see the progress bar).\n",
    "\n",
    "Each zipped directory contains randomly sampled images from the [iNaturalist dataset](https://github.com/visipedia/inat_comp), evenly distributed across 10 classes of living things like birds, insects, plants, and mammals (names given in Latin—so Aves, Insecta, Plantae, etc :). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set SIZE to \"TINY\", \"SMALL\", \"MEDIUM\", or \"LARGE\"\n",
    "# to select one of these three datasets\n",
    "# TINY dataset: 100 images, 30MB\n",
    "# SMALL dataset: 1000 images, 312MB\n",
    "# MEDIUM dataset: 5000 images, 1.5GB\n",
    "# LARGE dataset: 12,000 images, 3.6GB\n",
    "\n",
    "SIZE = \"SMALL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SIZE == \"TINY\":\n",
    "  src_url = \"https://storage.googleapis.com/wandb_datasets/nature_100.zip\"\n",
    "  src_zip = \"nature_100.zip\"\n",
    "  DATA_SRC = \"nature_100\"\n",
    "  IMAGES_PER_LABEL = 10\n",
    "  BALANCED_SPLITS = {\"train\" : 8, \"val\" : 1, \"test\": 1}\n",
    "elif SIZE == \"SMALL\":\n",
    "  src_url = \"https://storage.googleapis.com/wandb_datasets/nature_1K.zip\"\n",
    "  src_zip = \"nature_1K.zip\"\n",
    "  DATA_SRC = \"nature_1K\"\n",
    "  IMAGES_PER_LABEL = 100\n",
    "  BALANCED_SPLITS = {\"train\" : 80, \"val\" : 10, \"test\": 10}\n",
    "elif SIZE == \"MEDIUM\":\n",
    "  src_url = \"https://storage.googleapis.com/wandb_datasets/nature_12K.zip\"\n",
    "  src_zip = \"nature_12K.zip\"\n",
    "  DATA_SRC = \"inaturalist_12K/train\" # (technically a subset of only 10K images)\n",
    "  IMAGES_PER_LABEL = 500\n",
    "  BALANCED_SPLITS = {\"train\" : 400, \"val\" : 50, \"test\": 50}\n",
    "elif SIZE == \"LARGE\":\n",
    "  src_url = \"https://storage.googleapis.com/wandb_datasets/nature_12K.zip\"\n",
    "  src_zip = \"nature_12K.zip\"\n",
    "  DATA_SRC = \"inaturalist_12K/train\" # (technically a subset of only 10K images)\n",
    "  IMAGES_PER_LABEL = 1000\n",
    "  BALANCED_SPLITS = {\"train\" : 800, \"val\" : 100, \"test\": 100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!curl -SL $src_url > $src_zip\n",
    "!unzip $src_zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0: Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start out by installing the experiment tracking library and setting up your free W&B account:\n",
    "\n",
    "\n",
    "*   **pip install wandb** – Install the W&B library\n",
    "*   **import wandb** – Import the wandb library\n",
    "*   **wandb login** – Login to your W&B account so you can log all your metrics in one place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wandb -qqq\n",
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "\n",
    "# source directory for all raw data\n",
    "SRC = DATA_SRC\n",
    "PREFIX = \"inat\" # convenient for tracking local data\n",
    "PROJECT_NAME = \"nature_photos\"\n",
    "\n",
    "# number of images per class label\n",
    "# the total number of images is 10X this (10 classes)\n",
    "TOTAL_IMAGES = IMAGES_PER_LABEL * 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Upload raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if this is a substantially new dataset, give it a new name\n",
    "# this will create a whole new placeholder (Artifact) for this dataset\n",
    "# instead of just incrementing a version of the old dataset\n",
    "RAW_DATA_AT = \"_\".join([PREFIX, \"raw_data\", str(TOTAL_IMAGES)])\n",
    "run = wandb.init(project=PROJECT_NAME, job_type=\"upload\")\n",
    "# create an artifact for all the raw data\n",
    "raw_data_at = wandb.Artifact(RAW_DATA_AT, type=\"raw_data\")\n",
    "\n",
    "# SRC_DIR contains 10 folders, one for each of 10 class labels\n",
    "# each folder contains images of the corresponding class\n",
    "labels = os.listdir(SRC)\n",
    "for l in labels:\n",
    "  imgs_per_label = os.path.join(SRC, l)\n",
    "  if os.path.isdir(imgs_per_label):\n",
    "    # filter out \"DS_Store\"\n",
    "    imgs = [i for i in os.listdir(imgs_per_label) if not i.startswith(\".DS\")]\n",
    "    # randomize the order\n",
    "    shuffle(imgs)\n",
    "    img_file_ids = imgs[:IMAGES_PER_LABEL]\n",
    "    for f in img_file_ids:\n",
    "      file_path = os.path.join(SRC, l, f)\n",
    "      # add file to artifact by full path\n",
    "      raw_data_at.add_file(file_path, name=l + \"/\" + f)\n",
    "\n",
    "# save artifact to W&B\n",
    "run.log_artifact(raw_data_at)\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](https://i.imgur.com/EjVjKuL.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Split raw data to prepare for training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if this is a substantially different dataset, give it a new name\n",
    "# this will create a whole new placeholder (Artifact) for this split\n",
    "# instead of just incrementing a version of the old data split\n",
    "SPLIT_DATA_AT = \"_\".join([PREFIX, \"80-10-10\", str(TOTAL_IMAGES)])\n",
    "run = wandb.init(project=PROJECT_NAME, job_type=\"data_split\")\n",
    "\n",
    "# create balanced train, val, test splits\n",
    "# each count is the number of images per label\n",
    "SPLIT_COUNTS = BALANCED_SPLITS\n",
    "\n",
    "# find the most recent (\"latest\") version of the full raw data\n",
    "# you can of course pass around programmatic aliases and not string literals\n",
    "# note: RAW_DATA_AT is defined in the previous cell—if you're running\n",
    "# just this step, you may need to hardcode it\n",
    "data_at = run.use_artifact(RAW_DATA_AT + \":latest\")\n",
    "# download it locally (for illustration purposes/across hardware; you can\n",
    "# also sync/version artifacts by reference)\n",
    "data_dir = data_at.download()\n",
    "\n",
    "data_split_at = wandb.Artifact(SPLIT_DATA_AT, type=\"balanced_data\")\n",
    "\n",
    "# create a table with columns we want to track/compare\n",
    "preview_dt = wandb.Table(columns=[\"id\", \"image\", \"label\", \"split\"])\n",
    "\n",
    "labels = os.listdir(data_dir)\n",
    "for l in labels:\n",
    "  if l.startswith(\".\"): # skip non-label file\n",
    "    continue\n",
    "  imgs_per_label = os.listdir(os.path.join(data_dir, l))\n",
    "  shuffle(imgs_per_label)\n",
    "  start_id = 0\n",
    "  for split, count in SPLIT_COUNTS.items():\n",
    "    # take a subset\n",
    "    split_imgs = imgs_per_label[start_id:start_id+count]\n",
    "    for img_file in split_imgs:\n",
    "      f_id = img_file.split(\".\")[0]\n",
    "      full_path = os.path.join(data_dir, l, img_file)\n",
    "      # add file to artifact by full path\n",
    "      # note: pass the label to the name parameter to retain it in\n",
    "      # the data structure \n",
    "      data_split_at.add_file(full_path, name = os.path.join(split, l, img_file))\n",
    "      # add a preview of the image\n",
    "      if SIZE == \"LARGE\": # skip for the largest dataset for efficiency\n",
    "        continue\n",
    "      if split != \"test\":\n",
    "        preview_dt.add_data(f_id, wandb.Image(full_path), l, split)\n",
    "      else:\n",
    "        # pretend we have unlabeled test data\n",
    "        # (replace \"unknown\" with l if you'd like to keep the labels :)\n",
    "        preview_dt.add_data(f_id, wandb.Image(full_path), \"unknown\", split)\n",
    "    start_id += count\n",
    "\n",
    "# log artifact to W&B\n",
    "data_split_at.add(preview_dt, \"data_split\")\n",
    "run.log_artifact(data_split_at)\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: if this Colab is running out of RAM, try running this cell\n",
    "del data_split_at\n",
    "del preview_dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Train with artifacts and save model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPERIMENT CONFIG\n",
    "#------------------------\n",
    "# Core globals to modify\n",
    "NUM_EPOCHS = 1 # set low for demo purposes, try 3, or 5, or as many as you like\n",
    "\n",
    "\n",
    "# optional globals to modify\n",
    "# set to a custom name to help keep your experiments organized\n",
    "RUN_NAME = \"\" \n",
    "# change this if you'd like start a new set of comparable Tables\n",
    "# (only Tables logged to the same key can be compared)\n",
    "VAL_TABLE_NAME = \"predictions\" \n",
    "\n",
    "# hyperparams set low for demo/training speed\n",
    "# if you set these higher, be mindful of how many items are in\n",
    "# the dataset artifacts you chose by setting the SIZE at the top\n",
    "NUM_TRAIN = BALANCED_SPLITS[\"train\"]*10\n",
    "NUM_VAL = BALANCED_SPLITS[\"val\"]*10\n",
    "\n",
    "# enforced max for this is ceil(NUM_VAL/batch_size)\n",
    "NUM_LOG_BATCHES = 16\n",
    "\n",
    "# ARTIFACTS CONFIG\n",
    "#------------------------\n",
    "# training data artifact to load\n",
    "TRAIN_DATA_AT = PREFIX + \"_80-10-10_\" + str(TOTAL_IMAGES)\n",
    "\n",
    "# model name\n",
    "# if you want to train a sufficiently different model, give this a new name\n",
    "# to start a new lineage for the model, instead of just incrementing the\n",
    "# version of the old model\n",
    "MODEL_NAME = \"iv3_finetuned\"\n",
    "\n",
    "# folder in which to save the final, trained model\n",
    "# if you want to train a sufficiently different model, give this a new name\n",
    "# to start a new lineage for the model, instead of just incrementing the\n",
    "# version of the old model\n",
    "SAVE_MODEL_DIR = \"finetune_iv3_keras\"\n",
    "\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "# experiment configuration saved to W&B\n",
    "CFG = {\n",
    "  \"num_train\" : NUM_TRAIN,\n",
    "  \"num_val\" : NUM_VAL,\n",
    "  \"num_classes\" : 10,\n",
    "  \"fc_size\" : 1024,\n",
    "  \"epochs\" : NUM_EPOCHS,\n",
    "  \"batch_size\" : 32,\n",
    "\n",
    "  # inceptionV3 settings\n",
    "  \"img_width\" : 299,\n",
    "  \"img_height\": 299\n",
    "}\n",
    "\n",
    "# number of validation data batches to log/use when computing metrics\n",
    "# at the end of each epoch\n",
    "max_log_batches = int(np.ceil(float(CFG[\"num_val\"])/float(CFG[\"batch_size\"])))\n",
    "# change this min to max to log ALL the available images to a Table\n",
    "CFG[\"num_log_batches\"] = min(max_log_batches, NUM_LOG_BATCHES)\n",
    "\n",
    "def finetune_inception_model(fc_size, num_classes):\n",
    "  \"\"\"Load InceptionV3 with ImageNet weights, freeze it,\n",
    "  and attach a finetuning top for this classification task\"\"\"\n",
    "  # load InceptionV3 as base\n",
    "  base = InceptionV3(weights=\"imagenet\", include_top=\"False\")\n",
    "  # freeze base layers\n",
    "  for layer in base.layers:\n",
    "    layer.trainable = False\n",
    "  x = base.get_layer('mixed10').output \n",
    "\n",
    "  # attach a fine-tuning layer\n",
    "  x = GlobalAveragePooling2D()(x)\n",
    "  x = Dense(fc_size, activation='relu')(x)\n",
    "  guesses = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "  model = Model(inputs=base.input, outputs=guesses)\n",
    "  model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "  return model\n",
    "\n",
    "def train():\n",
    "  \"\"\" Main training loop which freezes the InceptionV3 layers of the model\n",
    "  and only trains the new top layers on the new data. A subsequent training\n",
    "  phase might unfreeze all the layers and finetune the whole model on the new data\"\"\" \n",
    "  run = wandb.init(project=PROJECT_NAME, name=RUN_NAME, job_type=\"train\", config=CFG)\n",
    "  cfg = wandb.config\n",
    "\n",
    "  # locate and download training and validation data\n",
    "  data_at = TRAIN_DATA_AT + \":latest\"\n",
    "  data = run.use_artifact(data_at, type=\"balanced_data\")\n",
    "  data_dir = data.download()\n",
    "  train_dir = os.path.join(data_dir, \"train\")\n",
    "  val_dir = os.path.join(data_dir, \"val\")\n",
    "\n",
    "  # create train and validation data generators\n",
    "  train_datagen = ImageDataGenerator(\n",
    "      rescale=1. / 255,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True)\n",
    "  val_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "  train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(cfg.img_width, cfg.img_height),\n",
    "    batch_size=cfg.batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "  val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(cfg.img_width, cfg.img_height),\n",
    "    batch_size=cfg.batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False)\n",
    "\n",
    "  # instantiate model and callbacks\n",
    "  model = finetune_inception_model(cfg.fc_size, cfg.num_classes)\n",
    "  callbacks = [WandbCallback(), ValLog(val_generator, cfg.num_log_batches)]\n",
    "\n",
    "  # train!\n",
    "  model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch = cfg.num_train // cfg.batch_size,\n",
    "    epochs=cfg.epochs,\n",
    "    validation_data=val_generator,\n",
    "    callbacks = callbacks,\n",
    "    validation_steps = cfg.num_val // cfg.batch_size)\n",
    "\n",
    "  # save trained model as artifact\n",
    "  trained_model_artifact = wandb.Artifact(\n",
    "            MODEL_NAME, type=\"model\",\n",
    "            description=\"finetuned inception v3\",\n",
    "            metadata=dict(cfg))\n",
    "  \n",
    "  model.save(SAVE_MODEL_DIR)\n",
    "  trained_model_artifact.add_dir(SAVE_MODEL_DIR)\n",
    "  run.log_artifact(trained_model_artifact)\n",
    "  run.finish()\n",
    "\n",
    "class ValLog(Callback):\n",
    "  \"\"\" Custom callback to log validation images\n",
    "  at the end of each training epoch\"\"\"\n",
    "  def __init__(self, generator=None, num_log_batches=1):\n",
    "    self.generator = generator\n",
    "    self.num_batches = num_log_batches\n",
    "    # store full names of classes\n",
    "    self.flat_class_names = [k for k, v in generator.class_indices.items()]\n",
    "\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    # collect validation data and ground truth labels from generator\n",
    "    val_data, val_labels = zip(*(self.generator[i] for i in range(self.num_batches)))\n",
    "    val_data, val_labels = np.vstack(val_data), np.vstack(val_labels)\n",
    "\n",
    "    # use the trained model to generate predictions for the given number\n",
    "    # of validation data batches (num_batches)\n",
    "    val_preds = self.model.predict(val_data)\n",
    "    true_ids = val_labels.argmax(axis=1)\n",
    "    max_preds = val_preds.argmax(axis=1)\n",
    "\n",
    "    # log validation predictions alongside the run\n",
    "    columns=[\"id\", \"image\", \"guess\", \"truth\"]\n",
    "    for a in self.flat_class_names:\n",
    "      columns.append(\"score_\" + a)\n",
    "    predictions_table = wandb.Table(columns = columns)\n",
    "    \n",
    "    # log image, predicted and actual labels, and all scores\n",
    "    for filepath, img, top_guess, scores, truth in zip(self.generator.filenames,\n",
    "                                                       val_data, \n",
    "                                                       max_preds, \n",
    "                                                       val_preds,\n",
    "                                                       true_ids):\n",
    "      img_id = filepath.split('/')[-1].split(\".\")[0]\n",
    "      row = [img_id, wandb.Image(img), \n",
    "             self.flat_class_names[top_guess], self.flat_class_names[truth]]\n",
    "      for s in scores.tolist():\n",
    "        row.append(np.round(s, 4))\n",
    "      predictions_table.add_data(*row)\n",
    "    wandb.run.log({VAL_TABLE_NAME : predictions_table})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Load model for inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional globals to modify\n",
    "# set to a custom name to help keep your experiments organized\n",
    "RUN_NAME = \"\" \n",
    "# change this if you'd like start a new set of comparable Tables\n",
    "# (only Tables logged to the same key can be compared)\n",
    "TEST_TABLE_NAME = \"test_results\" \n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "MODEL_NAME = \"iv3_finetuned\"\n",
    "# location of test data from our original split\n",
    "# should match SPLIT_DATA_AT\n",
    "TEST_DATA_AT = \"_\".join([PREFIX, \"80-10-10\", str(TOTAL_IMAGES)])\n",
    "\n",
    "run = wandb.init(project=PROJECT_NAME, job_type=\"inference\", name=RUN_NAME)\n",
    "model_at = run.use_artifact(MODEL_NAME + \":latest\")\n",
    "model_dir = model_at.download()\n",
    "print(\"model: \", model_dir)\n",
    "model = keras.models.load_model(model_dir)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# download latest version of test data\n",
    "test_data_at = run.use_artifact(TEST_DATA_AT + \":latest\")\n",
    "test_dir = test_data_at.download()\n",
    "test_dir += \"/test/\"\n",
    "\n",
    "class_names = [\"Animalia\", \"Amphibia\", \"Arachnida\", \"Aves\", \"Fungi\", \n",
    "               \"Insecta\", \"Mammalia\", \"Mollusca\", \"Plantae\", \"Reptilia\"]\n",
    "\n",
    "# load test images\n",
    "imgs = []\n",
    "filenames = []\n",
    "class_labels = os.listdir(test_dir)\n",
    "truth = []\n",
    "for l in class_labels:\n",
    "  if l.startswith(\".\"):\n",
    "    continue\n",
    "  imgs_per_class = os.listdir(os.path.join(test_dir, l))\n",
    "  for img in imgs_per_class:\n",
    "    # track the image id\n",
    "    filenames.append(img.split(\".\")[0])\n",
    "    truth.append(l)\n",
    "    img_path = os.path.join(test_dir, l, img)\n",
    "    img = image.load_img(img_path, target_size=(299, 299))\n",
    "    img = image.img_to_array(img)\n",
    "    # don't forget to rescale test images to match the range of inputs\n",
    "    # to the network\n",
    "    img = np.expand_dims(img/255.0, axis=0)\n",
    "    imgs.append(img)\n",
    "\n",
    "# predict on test data and bin predictions by guessed label \n",
    "preds = {}\n",
    "imgs = np.vstack(imgs)\n",
    "classes = model.predict(imgs, batch_size=32)\n",
    "for c in classes:\n",
    "  class_id = np.argmax(c)\n",
    "  if class_id in preds:\n",
    "    preds[class_id] += 1\n",
    "  else:\n",
    "    preds[class_id] = 1\n",
    "\n",
    "# log inference results as a Table to the run workspace\n",
    "columns=[\"id\", \"image\", \"guess\", \"truth\"]\n",
    "for a in class_names:\n",
    "  columns.append(\"score_\" + a)\n",
    "test_dt = wandb.Table(columns = columns)\n",
    "\n",
    "# store all the scores for each image\n",
    "for img_id, i, t, c in zip(filenames, imgs, truth, classes):\n",
    "  guess = class_names[np.argmax(c)]\n",
    "  row = [img_id, wandb.Image(i), guess, t]\n",
    "  for c_i in c.tolist():\n",
    "    row.append(np.round(c_i, 4))\n",
    "  test_dt.add_data(*row)\n",
    "  \n",
    "run.log({TEST_TABLE_NAME : test_dt})\n",
    "print(\"Quick distribution of predicted classes: \")\n",
    "print(preds)\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More about Weights & Biases\n",
    "We're always free for academics and open source projects. Email carey@wandb.com with any questions or feature suggestions. Here are some more resources:\n",
    "\n",
    "1. [Documentation](http://docs.wandb.com) - Python docs\n",
    "2. [Gallery](https://app.wandb.ai/gallery) - example reports in W&B\n",
    "3. [Articles](https://www.wandb.com/articles) - blog posts and tutorials\n",
    "4. [Community](wandb.me/slack) - join our Slack community forum"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
