{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.imgur.com/gb6B4ig.png\" width=\"400\" alt=\"Weights & Biases\" />\n",
    "\n",
    "# View & analyze model predictions during training\n",
    "\n",
    "This notebook shows how to track, visualize, and compare model predictions over the course of training, using Pytorch on MNIST data. \n",
    "\n",
    "With W&B's newest feature for [Dataset and Prediction Visualization (in Beta)](https://docs.wandb.com/datasets-and-predictions), you can\n",
    "* log metrics, images, text, etc. to a wandb.Table() during model training or evaluation\n",
    "* view, sort, filter, group, join, interactively query, and otherwise explore these tables\n",
    "* compare model predictions or results over time: dynamically across different epochs or validation steps\n",
    "\n",
    "## Compare predicted scores for specific images\n",
    "[Live example: compare predictions after 1 vs 5 epochs of training →](https://wandb.ai/stacey/mnist-viz/artifacts/predictions/test_samples_222yogf6/620ddb9966343696912d/files/predictions.table.json#e6232e8a664e34740d7f)\n",
    "<img src=\"https://i.imgur.com/EwXO0HY.png\" alt=\"MNIST test predictions\"/>\n",
    "The histograms compare per-class scores between the two models. The top bar in each histogram represents model v0, which only trained for 1 epoch. The bottom bar represents model v4, which trained for 5 epochs. For example, the 1 in the middle row has much higher confidence scores for classes 0, 2, 3, and 4 (all incorrect labels) after 1 epoch than after 5 epochs of training.\n",
    "<img src=\"https://i.imgur.com/VoGXdsj.png\" alt=\"middle row\"/>\n",
    "\n",
    "## Focus on top errors over time\n",
    "See incorrect predictions (filter to rows where \"guess\" != \"truth\") on the full test data\n",
    "<img src=\"https://i.imgur.com/8KulMp0.png\" alt=\"MNIST errors compare\"/>\n",
    "Note that there are 213 wrong guesses after 1 training epoch, but only 84 after 5 epochs.\n",
    "\n",
    "## Compare model performance and find patterns\n",
    "Filter out correct answers, then group by the guess to see examples of misclassified images and the underlying distribution of true labels—for two models side-by-side. A baseline model is on the left, and a variant with double the layer sizes is on the right.\n",
    "<img src=\"https://i.imgur.com/yOSAiGh.png\" alt=\"MNIST grouped\"/>\n",
    "\n",
    "## Sign up or login\n",
    "\n",
    "[Sign up or login](https://wandb.ai/login) to W&B to see and interact with your experiments in the browser.\n",
    "\n",
    "In this example we're using Google Colab as a convenient hosted environment, but you can run your own training scripts from anywhere and visualize metrics with W&B's experiment tracking tool."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/wandb/examples/blob/master/colabs/datasets-predictions/Visualize_Model_Predictions_over_Time.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install wandb -qqq\n",
    "WANDB_PROJECT = \"mnist-viz\"\n",
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Setup\n",
    "\n",
    "Install dependencies, download MNIST, and create train and test datasets using Pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# workaround to fetch MNIST data\n",
    "!wget www.di.ens.fr/~lelarge/MNIST.tar.gz\n",
    "!tar -zxvf MNIST.tar.gz\n",
    "\n",
    "# create train and test sets\n",
    "train_set = MNIST('./', download=True,\n",
    "transform=transforms.Compose([\n",
    "transforms.ToTensor(),\n",
    "]), train=True)\n",
    "\n",
    "test_set = MNIST('./', download=True,\n",
    "transform=transforms.Compose([\n",
    "transforms.ToTensor(),\n",
    "]), train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Define the model and training schedule\n",
    "\n",
    "* Set the number of epochs to run, where each epoch consists of a training step and a validation step. Optionally configure the amount of data to log per validation step. Here the number of batches and number of images per batch to visualize are set low to simplify the demo. \n",
    "* Define a simple convolutional neural net (following [pytorch-tutorial](https://github.com/yunjey/pytorch-tutorial) code).\n",
    "* Load in train and test sets using Pytorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of epochs to run\n",
    "# Each epoch includes a training step and a test step, so this sets\n",
    "# the number of tables of test predictions to log\n",
    "EPOCHS = 5\n",
    "\n",
    "# Number of batches to log from the test data for each test step\n",
    "# (default set low to simplify demo)\n",
    "NUM_BATCHES_TO_LOG = 78\n",
    "\n",
    "# Number of images to log per test batch\n",
    "# (default set low to simplify demo)\n",
    "LOG_IMAGES_PER_BATCH = 128\n",
    "\n",
    "# training configuration and hyperparameters\n",
    "NUM_CLASSES = 10\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 0.001\n",
    "L1_SIZE = 32\n",
    "L2_SIZE = 64\n",
    "# changing this may require changing the shape of adjacent layers\n",
    "CONV_KERNEL_SIZE = 5\n",
    "\n",
    "# define a two-layer convolutional neural network\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, L1_SIZE, CONV_KERNEL_SIZE, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(L1_SIZE),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(L1_SIZE, L2_SIZE, CONV_KERNEL_SIZE, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(L2_SIZE),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.fc = nn.Linear(7*7*L2_SIZE, NUM_CLASSES)\n",
    "        self.softmax = nn.Softmax(NUM_CLASSES)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # uncomment to see the shape of a given layer:\n",
    "        #print(\"x: \", x.size())\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_set,\n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_set,\n",
    "                                          batch_size=BATCH_SIZE,\n",
    "                                          shuffle=False)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Run training and log test predictions\n",
    "\n",
    "For every epoch, run a training step and a test step. For each test step, create a wandb.Table() in which to store test predictions. These can be visualized, dynamically queried, adn compared side by side in your browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log to a specific project which will store all your experiments\n",
    "wandb.init(project=WANDB_PROJECT)\n",
    "# log model comnfiguration to wandb\n",
    "cfg = wandb.config\n",
    "cfg.update({\"epochs\" : EPOCHS, \"batch_size\": BATCH_SIZE, \"lr\" : LEARNING_RATE,\n",
    "            \"l1_size\" : L1_SIZE, \"l2_size\": L2_SIZE,\n",
    "            \"conv_kernel\" : CONV_KERNEL_SIZE})\n",
    "\n",
    "model = ConvNet(NUM_CLASSES).to(device)\n",
    "# loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# optionally log gradients and parameters to wandb\n",
    "#wandb.watch(model, log=\"all\")\n",
    "\n",
    "# convenience funtion to log predictions for a batch of test images\n",
    "def log_test_predictions(images, labels, outputs, predicted, test_table, log_counter):\n",
    "  # obtain confidence scores for ALL classes\n",
    "  scores = F.softmax(outputs.data, dim=1)\n",
    "  log_scores = scores.cpu().numpy()\n",
    "  log_images = images.cpu().numpy()\n",
    "  log_labels = labels.cpu().numpy()\n",
    "  log_preds = predicted.cpu().numpy()\n",
    "  # assing ids based on the order of the images\n",
    "  _id = 0\n",
    "  for i, l, p, s in zip(log_images, log_labels, log_preds, log_scores):\n",
    "    # add required info to data table:\n",
    "    # id, image pixels, model's guess, true label, scores for all classes\n",
    "    img_id = str(_id) + \"_\" + str(log_counter)\n",
    "    test_table.add_data(img_id, wandb.Image(i), p, l, *s)\n",
    "    _id += 1\n",
    "    if _id == LOG_IMAGES_PER_BATCH:\n",
    "      break\n",
    "\n",
    "# train the model\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(EPOCHS):\n",
    "    # training step\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        # backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "  \n",
    "        # log loss to wandb\n",
    "        wandb.log({\"loss\" : loss})\n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
    "                .format(epoch+1, EPOCHS, i+1, total_step, loss.item()))\n",
    "            \n",
    "    \n",
    "    \n",
    "    # create a wandb Artifact to version each test step separately\n",
    "    test_data_at = wandb.Artifact(\"test_samples_\" + str(wandb.run.id), type=\"predictions\")\n",
    "    # create a wandb.Table() in which to store predictions for each test step\n",
    "    columns=[\"id\", \"image\", \"guess\", \"truth\"]\n",
    "    for digit in range(10):\n",
    "      columns.append(\"score_\" + str(digit))\n",
    "    test_table = wandb.Table(columns=columns)\n",
    "\n",
    "    # test the model\n",
    "    model.eval()\n",
    "    log_counter = 0\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            if log_counter < NUM_BATCHES_TO_LOG:\n",
    "              log_test_predictions(images, labels, outputs, predicted, test_table, log_counter)\n",
    "              log_counter += 1\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        acc = 100 * correct / total\n",
    "        # log acc to wandb (and epoch so you can sync up model performance across batch sizes)\n",
    "        wandb.log({\"epoch\" : epoch, \"acc\" : acc})\n",
    "        print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))\n",
    "\n",
    "    # log predictions table to wandb\n",
    "    test_data_at.add(test_table, \"predictions\")\n",
    "    wandb.run.log_artifact(test_data_at)\n",
    "\n",
    "wandb.run.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
