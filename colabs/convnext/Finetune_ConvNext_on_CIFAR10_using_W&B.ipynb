{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/wandb/examples/blob/master/colabs/convnext/Finetune_ConvNext_on_CIFAR10_using_W&B.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this notebook to finetune a ConvNeXt-tiny model on CIFAR 10 dataset. The [official ConvNeXt repository](https://github.com/facebookresearch/ConvNeXt) is instrumented with [Weights and Biases](https://wandb.ai/site). You can now easily log your train/test metrics and version control your model checkpoints to Weigths and Biases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ‚öΩÔ∏è Installation and Setup\n",
    "\n",
    "The following installation instruction is based on [INSTALL.md](https://github.com/facebookresearch/ConvNeXt/blob/main/INSTALL.md) provided by the official ConvNeXt repository. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qq torch==1.8.0+cu111 torchvision==0.9.0+cu111 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "!pip install -qq wandb timm==0.3.2 six tensorboardX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the official ConvNeXt respository. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone --depth 1 https://github.com/facebookresearch/ConvNeXt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üèÄ Download the Dataset\n",
    "\n",
    "We will be finetuning on CIFAR-10 dataset. To use any custom dataset (CIFAR-10 here) the format of the dataset should be as shown below:\n",
    "\n",
    "```\n",
    "/path/to/dataset/\n",
    "  train/\n",
    "    class1/\n",
    "      img1.jpeg\n",
    "    class2/\n",
    "      img2.jpeg\n",
    "  val/\n",
    "    class1/\n",
    "      img3.jpeg\n",
    "    class2/\n",
    "      img4.jpeg\n",
    "```\n",
    "\n",
    "I have used this [repository](https://github.com/YoongiKim/CIFAR-10-images) that has the CIFAR-10 images in the required format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone --depth 1 https://github.com/YoongiKim/CIFAR-10-images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üèà Download Pretrained Weights\n",
    "\n",
    "We will be finetuning the ConvNeXt Tiny model pretrained on ImageNet 1K dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ConvNeXt/\n",
    "!wget https://dl.fbaipublicfiles.com/convnext/convnext_tiny_1k_224_ema.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéæ Train with Weights and Biases\n",
    "\n",
    "If you want to log the train and evaluation metrics using Weights and Biases pass `--enable_wandb true`. \n",
    "\n",
    "You can also save the finetuned checkpoints as version controlled W&B [Artifacts](https://docs.wandb.ai/guides/artifacts) if you pass `--wandb_ckpt true`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python main.py --epochs 10 \\\n",
    "                --model convnext_tiny \\\n",
    "                --data_set image_folder \\\n",
    "                --data_path ../CIFAR-10-images/train \\\n",
    "                --eval_data_path ../CIFAR-10-images/test \\\n",
    "                --nb_classes 10 \\\n",
    "                --num_workers 8 \\\n",
    "                --warmup_epochs 0 \\\n",
    "                --save_ckpt true \\\n",
    "                --output_dir model_ckpt \\\n",
    "                --finetune convnext_tiny_1k_224_ema.pth \\\n",
    "                --cutmix 0 \\\n",
    "                --mixup 0 --lr 4e-4 \\\n",
    "                --enable_wandb true --wandb_ckpt true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üèê Conclusion\n",
    "\n",
    "* **The above setting gives a top-1 accuracy of ~95%.**\n",
    "* The ConvNeXt repository comes with modern training regimes and is easy to finetune on any dataset. \n",
    "* The finetune model achieves competitive results. \n",
    "\n",
    "* By passing two arguments you get the following:\n",
    "\n",
    "  * Repository of all your experiments (train and test metrics) as a [W&B Project](https://docs.wandb.ai/ref/app/pages/project-page). You can easily compare experiments to find the best performing model.\n",
    "  * Hyperparameters (Configs) used to train individual models. \n",
    "  * System (CPU/GPU/Disk) metrics.\n",
    "  * Model checkpoints saved as W&B Artifacts. They are versioned and easy to share. \n",
    "\n",
    "  Check out the associated [W&B run page](https://wandb.ai/ayut/convnext/runs/16vi9e31). $‚Üí$"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
