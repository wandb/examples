{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Train Object Detector with MMDetection and W&B",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNKEQN2YDj2X7wfNwVyfFy4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "459724d95943402a9f0e3e8e25fee172": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_48d05465bc2d425994191be14967abfe",
              "IPY_MODEL_49ed2a828c1c4d089716eb7f3fbbe250"
            ],
            "layout": "IPY_MODEL_49c80972112e4a0080a66ed82095c0c8"
          }
        },
        "48d05465bc2d425994191be14967abfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3fbcbcbacd9a4c33a74f2707ff8f5381",
            "placeholder": "​",
            "style": "IPY_MODEL_63b239b43e014cac856f7801231f2312",
            "value": "3784.781 MB of 3784.781 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "49ed2a828c1c4d089716eb7f3fbbe250": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b07721c0e5a460997386b99ddc4d69d",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e7f9e300d6c845e8afba216fbfb44d18",
            "value": 1
          }
        },
        "49c80972112e4a0080a66ed82095c0c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fbcbcbacd9a4c33a74f2707ff8f5381": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63b239b43e014cac856f7801231f2312": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2b07721c0e5a460997386b99ddc4d69d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7f9e300d6c845e8afba216fbfb44d18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayulockin/examples/blob/master/colabs/integrations/mmdetection/Train_Object_Detector_with_MMDetection_and_W%26B.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"http://wandb.me/logo-im-png\" width=\"400\" alt=\"Weights & Biases\"/> <br>\n",
        "\n",
        "<!--- @wandbcode{mmdetection-wandb-colab, v=1} -->\n",
        "\n",
        "<img src=\"http://wandb.me/mini-diagram\" width=\"600\" alt=\"Weights & Biases\"/>"
      ],
      "metadata": {
        "id": "XVZ-P0UVSSJA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 💡 Train an Object Detector with MMDetection and Weights and Biases\n",
        "\n",
        "In this colab, we will train an object detector using [MMDetection](https://mmdetection.readthedocs.io/en/latest/1_exist_data_model.html) on a tiny [Kitti](https://paperswithcode.com/dataset/kitti) dataset. Through this colab you will learn to:\n",
        "\n",
        "* use MMDetection to train an object detector on a custom dataset,\n",
        "* use [Weights and Biases](https://wandb.ai/site) to log training and validation metrics, visualize model predictions, version raw validation dataset, and more.\n",
        "\n",
        "This colab in particular, will showcase a dedicated `MMDetWandbHook` for MMDetection that can be used to:\n",
        "\n",
        "✅ Log training and evaluation metrics. <br>\n",
        "✅ Log versioned model checkpoints. <br>\n",
        "✅ Log versioned validation dataset with ground truth bounding boxes. <br>\n",
        "✅ Log and visualize model predictions.\n",
        "\n",
        "But before we continue, here's a quick summary of MMDetection and W&B if you are not familiar with them.\n",
        "\n",
        "### 📸 MMDetection\n",
        "\n",
        "MMDetection is an open source object detection toolbox based on PyTorch. It provides composable components that are easy to customize and has out-of-box support for single and multi GPU training/inference. It also has hundreds of pretrained detection models in Model Zoo, and supports multiple standard datasets. Check out the GitHub repository [here](https://github.com/open-mmlab/mmdetection).\n",
        "\n",
        "### 📸 Weights and Biases\n",
        "\n",
        "Consider **[Weights and Biases](https://wandb.ai/site)** (W&B) to be the GitHub for machine learning. Use W&B for machine learning experiment tracking, dataset and model versioning, project collaboration, hyperparameter optimization, dataset exploration, model evaluation and so much more. If you are new to W&B, check out this [intro colab](https://wandb.me/intro)."
      ],
      "metadata": {
        "id": "dM3mQv0uRZKK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ⚽️ Imports and Setup"
      ],
      "metadata": {
        "id": "nU2xpv095Zs5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1️⃣ Install MMDetection\n",
        "\n",
        "MMDetection is heavily dependent on the [MMCV](https://mmcv.readthedocs.io/en/latest/#installation) library. We will have to install the version of MMCV that is compatible with the given PyTorch version. Check out the [Installation documentation](https://mmdetection.readthedocs.io/en/latest/get_started.html#installation) for more details. "
      ],
      "metadata": {
        "id": "TrMyl0NO5PwK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_6aWe_n23gv",
        "outputId": "09611975-2181-4ab1-d726-eb7ec6b9e5af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |█████████████                   | 834.1 MB 1.6 MB/s eta 0:12:51tcmalloc: large alloc 1147494400 bytes == 0x557640bc0000 @  0x7f0d2e163615 0x557607f893bc 0x55760806a18a 0x557607f8c1cd 0x55760807eb3d 0x557608000458 0x557607ffb02f 0x557607f8daba 0x5576080002c0 0x557607ffb02f 0x557607f8daba 0x557607ffccd4 0x55760807f986 0x557607ffc350 0x55760807f986 0x557607ffc350 0x55760807f986 0x557607ffc350 0x557607f8df19 0x557607fd1a79 0x557607f8cb32 0x5576080001dd 0x557607ffb02f 0x557607f8daba 0x557607ffccd4 0x557607ffb02f 0x557607f8daba 0x557607ffbeae 0x557607f8d9da 0x557607ffc108 0x557607ffb02f\n",
            "\u001b[K     |████████████████▌               | 1055.7 MB 1.5 MB/s eta 0:11:03tcmalloc: large alloc 1434370048 bytes == 0x557685216000 @  0x7f0d2e163615 0x557607f893bc 0x55760806a18a 0x557607f8c1cd 0x55760807eb3d 0x557608000458 0x557607ffb02f 0x557607f8daba 0x5576080002c0 0x557607ffb02f 0x557607f8daba 0x557607ffccd4 0x55760807f986 0x557607ffc350 0x55760807f986 0x557607ffc350 0x55760807f986 0x557607ffc350 0x557607f8df19 0x557607fd1a79 0x557607f8cb32 0x5576080001dd 0x557607ffb02f 0x557607f8daba 0x557607ffccd4 0x557607ffb02f 0x557607f8daba 0x557607ffbeae 0x557607f8d9da 0x557607ffc108 0x557607ffb02f\n",
            "\u001b[K     |█████████████████████           | 1336.2 MB 1.5 MB/s eta 0:07:51tcmalloc: large alloc 1792966656 bytes == 0x55760a048000 @  0x7f0d2e163615 0x557607f893bc 0x55760806a18a 0x557607f8c1cd 0x55760807eb3d 0x557608000458 0x557607ffb02f 0x557607f8daba 0x5576080002c0 0x557607ffb02f 0x557607f8daba 0x557607ffccd4 0x55760807f986 0x557607ffc350 0x55760807f986 0x557607ffc350 0x55760807f986 0x557607ffc350 0x557607f8df19 0x557607fd1a79 0x557607f8cb32 0x5576080001dd 0x557607ffb02f 0x557607f8daba 0x557607ffccd4 0x557607ffb02f 0x557607f8daba 0x557607ffbeae 0x557607f8d9da 0x557607ffc108 0x557607ffb02f\n",
            "\u001b[K     |██████████████████████████▌     | 1691.1 MB 1.6 MB/s eta 0:03:37tcmalloc: large alloc 2241208320 bytes == 0x557674e30000 @  0x7f0d2e163615 0x557607f893bc 0x55760806a18a 0x557607f8c1cd 0x55760807eb3d 0x557608000458 0x557607ffb02f 0x557607f8daba 0x5576080002c0 0x557607ffb02f 0x557607f8daba 0x557607ffccd4 0x55760807f986 0x557607ffc350 0x55760807f986 0x557607ffc350 0x55760807f986 0x557607ffc350 0x557607f8df19 0x557607fd1a79 0x557607f8cb32 0x5576080001dd 0x557607ffb02f 0x557607f8daba 0x557607ffccd4 0x557607ffb02f 0x557607f8daba 0x557607ffbeae 0x557607f8d9da 0x557607ffc108 0x557607ffb02f\n",
            "\u001b[K     |████████████████████████████████| 2041.3 MB 1.3 MB/s eta 0:00:01tcmalloc: large alloc 2041348096 bytes == 0x5576fa792000 @  0x7f0d2e1621e7 0x557607fbf5d7 0x557607f893bc 0x55760806a18a 0x557607f8c1cd 0x55760807eb3d 0x557608000458 0x557607ffb02f 0x557607f8daba 0x557607ffc108 0x557607ffb02f 0x557607f8daba 0x557607ffc108 0x557607ffb02f 0x557607f8daba 0x557607ffc108 0x557607ffb02f 0x557607f8daba 0x557607ffc108 0x557607ffb02f 0x557607f8daba 0x557607ffc108 0x557607f8d9da 0x557607ffc108 0x557607ffb02f 0x557607f8daba 0x557607ffccd4 0x557607ffb02f 0x557607f8daba 0x557607ffccd4 0x557607ffb02f\n",
            "tcmalloc: large alloc 2551685120 bytes == 0x5577e86de000 @  0x7f0d2e163615 0x557607f893bc 0x55760806a18a 0x557607f8c1cd 0x55760807eb3d 0x557608000458 0x557607ffb02f 0x557607f8daba 0x557607ffc108 0x557607ffb02f 0x557607f8daba 0x557607ffc108 0x557607ffb02f 0x557607f8daba 0x557607ffc108 0x557607ffb02f 0x557607f8daba 0x557607ffc108 0x557607ffb02f 0x557607f8daba 0x557607ffc108 0x557607f8d9da 0x557607ffc108 0x557607ffb02f 0x557607f8daba 0x557607ffccd4 0x557607ffb02f 0x557607f8daba 0x557607ffccd4 0x557607ffb02f 0x557607f8e151\n",
            "\u001b[K     |████████████████████████████████| 2041.3 MB 7.4 kB/s \n",
            "\u001b[K     |████████████████████████████████| 23.2 MB 1.5 MB/s \n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.9.0+cu111 which is incompatible.\n",
            "torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.9.0+cu111 which is incompatible.\u001b[0m\n",
            "\u001b[K     |████████████████████████████████| 45.4 MB 7.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 190 kB 5.0 MB/s \n",
            "\u001b[?25hCloning into 'mmdetection'...\n",
            "remote: Enumerating objects: 23585, done.\u001b[K\n",
            "remote: Total 23585 (delta 0), reused 0 (delta 0), pack-reused 23585\u001b[K\n",
            "Receiving objects: 100% (23585/23585), 35.29 MiB | 24.53 MiB/s, done.\n",
            "Resolving deltas: 100% (16492/16492), done.\n",
            "/content/mmdetection\n",
            "Obtaining file:///content/mmdetection\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mmdet==2.22.0) (3.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mmdet==2.22.0) (1.21.5)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from mmdet==2.22.0) (2.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from mmdet==2.22.0) (1.15.0)\n",
            "Collecting terminaltables\n",
            "  Downloading terminaltables-3.1.10-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmdet==2.22.0) (3.0.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmdet==2.22.0) (1.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmdet==2.22.0) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mmdet==2.22.0) (0.11.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->mmdet==2.22.0) (3.10.0.2)\n",
            "Installing collected packages: terminaltables, mmdet\n",
            "  Running setup.py develop for mmdet\n",
            "Successfully installed mmdet-2.22.0 terminaltables-3.1.10\n"
          ]
        }
      ],
      "source": [
        "# install dependencies: (use cu111 because colab has CUDA 11.1)\n",
        "!pip install -qq torch==1.9.0+cu111 torchvision==0.10.0+cu111 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "# install mmcv-full thus we could use CUDA operators\n",
        "!pip install -qq mmcv-full -f https://download.openmmlab.com/mmcv/dist/cu111/torch1.9.0/index.html\n",
        "\n",
        "# Install mmdetection\n",
        "!rm -rf mmdetection\n",
        "!git clone -b wandb2 https://github.com/ayulockin/mmdetection/\n",
        "%cd mmdetection\n",
        "\n",
        "!pip install -e ."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2️⃣ Install Weights and Biases\n",
        "\n",
        "Install the latest version of W&B. "
      ],
      "metadata": {
        "id": "MIy1-mbK5fOy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q --upgrade wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFbNRtgY5YNi",
        "outputId": "46b99c8f-fdef-4d24-81e2-cb5bdcc87ff7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.7 MB 5.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 181 kB 47.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 144 kB 46.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.3 MB/s \n",
            "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3️⃣ General Imports"
      ],
      "metadata": {
        "id": "DliUWrY45pva"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import os.path as osp\n",
        "import torch\n",
        "import torchvision\n",
        "import numpy as np\n",
        "\n",
        "# MMDetection\n",
        "import mmdet\n",
        "print(mmdet.__version__)\n",
        "from mmdet.datasets import build_dataset\n",
        "from mmdet.models import build_detector\n",
        "from mmdet.apis import train_detector\n",
        "from mmdet.datasets.builder import DATASETS\n",
        "from mmdet.datasets.custom import CustomDataset\n",
        "from mmdet.apis import set_random_seed\n",
        "\n",
        "# MMCV\n",
        "import mmcv\n",
        "from mmcv import Config\n",
        "\n",
        "# Weights and Biases\n",
        "import wandb\n",
        "print(wandb.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ryN6BF965sHw",
        "outputId": "3331a86d-3d19-404b-d055-7ef019a8d1e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.22.0\n",
            "0.12.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4️⃣ Login with you W&B account\n",
        "\n",
        "Create a free W&B account (it's free for personal and academic usage). Visit wandb.ai/authorize to get your unique authentication token. "
      ],
      "metadata": {
        "id": "10jiR5Qq5s1H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "id": "BaFvJ3_c5wzR",
        "outputId": "b975dd64-8ed5-464e-f929-9f2503ac569b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit: ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🏀 Dataset\n",
        "\n",
        "We will be using a tiny KITTI dataset for this colab notebook. \n",
        "\n",
        "Even though KITTI is a standard dataset for object detection, tiny KITTI can be considered as a custom dataset (lesser number of classes). MMDetection, recommends to convert the data into COCO or PASCAL VOC formats or the middle format."
      ],
      "metadata": {
        "id": "mC8XIX7i6e7s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1️⃣ Download the dataset"
      ],
      "metadata": {
        "id": "qotbN11G6hcT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ../\n",
        "!wget https://download.openmmlab.com/mmdetection/data/kitti_tiny.zip\n",
        "!unzip -q kitti_tiny.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gnrFgJ016gyB",
        "outputId": "ef2c7b6c-9789-44b1-e161-8ec11259e74b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "--2022-03-24 08:51:00--  https://download.openmmlab.com/mmdetection/data/kitti_tiny.zip\n",
            "Resolving download.openmmlab.com (download.openmmlab.com)... 47.252.96.28\n",
            "Connecting to download.openmmlab.com (download.openmmlab.com)|47.252.96.28|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6918271 (6.6M) [application/zip]\n",
            "Saving to: ‘kitti_tiny.zip’\n",
            "\n",
            "kitti_tiny.zip      100%[===================>]   6.60M  8.35MB/s    in 0.8s    \n",
            "\n",
            "2022-03-24 08:51:02 (8.35 MB/s) - ‘kitti_tiny.zip’ saved [6918271/6918271]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls kitti_tiny"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gL3OAZtd7ivV",
        "outputId": "4901fedf-5fa0-4883-d6d0-d1ab08ef6a3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training  train.txt  val.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Note: The `training` folder contains both training and validation data samples. This split is determined by the `train.txt` and `val.txt` files. "
      ],
      "metadata": {
        "id": "mBrJTC11hMqs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2️⃣ Build Custom Dataloader\n",
        "\n",
        "To support a new data format, it's recommended to convert the annotations to COCO format or PASCAL VOC format. You can also convert them the \"middle format\". \n",
        "\n",
        "If you are converting annotations to COCO format, do so offline and use the `CocoDataset` class. If you are converting it to the PASCAL format, use the `VOCDataset` class.\n",
        "\n",
        "In the example below, we are converting it to the middle format. The `KittiTinyDataset` class will thus inherit the `CustomDataset` class and override the `load_annotations` method. \n",
        "\n",
        "You can find more details about customizing the dataset [here](https://mmdetection.readthedocs.io/en/latest/tutorials/customize_dataset.html)."
      ],
      "metadata": {
        "id": "UbMk6P-z8FRE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@DATASETS.register_module()\n",
        "class KittiTinyDataset(CustomDataset):\n",
        "\n",
        "    CLASSES = ('Car', 'Pedestrian', 'Cyclist')\n",
        "\n",
        "    def load_annotations(self, ann_file):\n",
        "        cat2label = {k: i for i, k in enumerate(self.CLASSES)}\n",
        "        # load image list from file\n",
        "        image_list = mmcv.list_from_file(self.ann_file)\n",
        "    \n",
        "        data_infos = []\n",
        "        # convert annotations to middle format\n",
        "        for image_id in image_list:\n",
        "            filename = f'{self.img_prefix}/{image_id}.jpeg'\n",
        "            image = mmcv.imread(filename)\n",
        "            height, width = image.shape[:2]\n",
        "    \n",
        "            data_info = dict(filename=f'{image_id}.jpeg', width=width, height=height)\n",
        "    \n",
        "            # load annotations\n",
        "            label_prefix = self.img_prefix.replace('image_2', 'label_2')\n",
        "            lines = mmcv.list_from_file(os.path.join(label_prefix, f'{image_id}.txt'))\n",
        "    \n",
        "            content = [line.strip().split(' ') for line in lines]\n",
        "            bbox_names = [x[0] for x in content]\n",
        "            bboxes = [[float(info) for info in x[4:8]] for x in content]\n",
        "    \n",
        "            gt_bboxes = []\n",
        "            gt_labels = []\n",
        "            gt_bboxes_ignore = []\n",
        "            gt_labels_ignore = []\n",
        "    \n",
        "            # filter 'DontCare'\n",
        "            for bbox_name, bbox in zip(bbox_names, bboxes):\n",
        "                if bbox_name in cat2label:\n",
        "                    gt_labels.append(cat2label[bbox_name])\n",
        "                    gt_bboxes.append(bbox)\n",
        "                else:\n",
        "                    gt_labels_ignore.append(-1)\n",
        "                    gt_bboxes_ignore.append(bbox)\n",
        "\n",
        "            data_anno = dict(\n",
        "                bboxes=np.array(gt_bboxes, dtype=np.float32).reshape(-1, 4),\n",
        "                labels=np.array(gt_labels, dtype=np.long),\n",
        "                bboxes_ignore=np.array(gt_bboxes_ignore,\n",
        "                                       dtype=np.float32).reshape(-1, 4),\n",
        "                labels_ignore=np.array(gt_labels_ignore, dtype=np.long))\n",
        "\n",
        "            data_info.update(ann=data_anno)\n",
        "            data_infos.append(data_info)\n",
        "\n",
        "        return data_infos"
      ],
      "metadata": {
        "id": "pzTHefAI7zJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🏈 Model\n",
        "\n",
        "There are over hundred pre-trained object detectors provided by MMDetection via Model Zoo. Check out the Model Zoo [documentation](https://mmdetection.readthedocs.io/en/v2.21.0/model_zoo.html) page.\n",
        "\n",
        "You can also customize the model's backbone, neck, head, ROI, and loss. More on customizing the model [here](https://mmdetection.readthedocs.io/en/latest/tutorials/customize_models.html)."
      ],
      "metadata": {
        "id": "RFVEfNl49Yeu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1️⃣ Download the model\n",
        "\n",
        "We will be using a pretrained model checkpoint to fine tune on our custom dataset. Let's download the model in the `checkpoints` directory."
      ],
      "metadata": {
        "id": "X17YHtik9aAg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir checkpoints\n",
        "!wget -c https://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_caffe_fpn_mstrain_3x_coco/faster_rcnn_r50_caffe_fpn_mstrain_3x_coco_20210526_095054-1f77628b.pth \\\n",
        "      -O checkpoints/faster_rcnn_r50_caffe_fpn_mstrain_3x_coco_20210526_095054-1f77628b.pth"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHY8K0wP8oIF",
        "outputId": "74433eef-424c-4a85-9033-e6e8476ae1b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-03-24 08:51:03--  https://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_caffe_fpn_mstrain_3x_coco/faster_rcnn_r50_caffe_fpn_mstrain_3x_coco_20210526_095054-1f77628b.pth\n",
            "Resolving download.openmmlab.com (download.openmmlab.com)... 47.252.96.28\n",
            "Connecting to download.openmmlab.com (download.openmmlab.com)|47.252.96.28|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 167291982 (160M) [application/octet-stream]\n",
            "Saving to: ‘checkpoints/faster_rcnn_r50_caffe_fpn_mstrain_3x_coco_20210526_095054-1f77628b.pth’\n",
            "\n",
            "checkpoints/faster_ 100%[===================>] 159.54M  8.50MB/s    in 19s     \n",
            "\n",
            "2022-03-24 08:51:22 (8.50 MB/s) - ‘checkpoints/faster_rcnn_r50_caffe_fpn_mstrain_3x_coco_20210526_095054-1f77628b.pth’ saved [167291982/167291982]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ⚾️ Configuration\n",
        "\n",
        "MMDetection relies heavily on a config system. In the cell below, we will be loading a config file and modify few of the methods as per the need of this notebook.\n",
        "\n",
        "Note that both train and test dataloaders will use the same training samples. This is not a recommended practice but for the sake of a simplified notebook, let's use it. \n",
        "\n",
        "Learn more about the MMDetection Config system [here](https://mmdetection.readthedocs.io/en/latest/tutorials/config.html)."
      ],
      "metadata": {
        "id": "98ZoL0u9kGV5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1️⃣ Load the config file"
      ],
      "metadata": {
        "id": "CZ8xnCGWCDG0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cfg = Config.fromfile('mmdetection/configs/faster_rcnn/faster_rcnn_r50_caffe_fpn_mstrain_1x_coco.py')"
      ],
      "metadata": {
        "id": "QIuFiLM0CFwE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2️⃣ Modify data config"
      ],
      "metadata": {
        "id": "7B5be5GkCHke"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define type and path to the images.\n",
        "cfg.dataset_type = 'KittiTinyDataset'\n",
        "cfg.data_root = 'kitti_tiny/'\n",
        "\n",
        "cfg.data.test.type = 'KittiTinyDataset'\n",
        "cfg.data.test.data_root = 'kitti_tiny/'\n",
        "cfg.data.test.ann_file = 'train.txt'\n",
        "cfg.data.test.img_prefix = 'training/image_2'\n",
        "\n",
        "cfg.data.train.type = 'KittiTinyDataset'\n",
        "cfg.data.train.data_root = 'kitti_tiny/'\n",
        "cfg.data.train.ann_file = 'train.txt'\n",
        "cfg.data.train.img_prefix = 'training/image_2'\n",
        "\n",
        "cfg.data.val.type = 'KittiTinyDataset'\n",
        "cfg.data.val.data_root = 'kitti_tiny/'\n",
        "cfg.data.val.ann_file = 'val.txt'\n",
        "cfg.data.val.img_prefix = 'training/image_2'"
      ],
      "metadata": {
        "id": "Zy2bYsIiCN8U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3️⃣ Modify model config"
      ],
      "metadata": {
        "id": "96j2GcQiCWP1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The number of unique objects in the training data.\n",
        "cfg.model.roi_head.bbox_head.num_classes = 3\n",
        "# Use the pretrained model.\n",
        "cfg.load_from = 'checkpoints/faster_rcnn_r50_caffe_fpn_mstrain_3x_coco_20210526_095054-1f77628b.pth'"
      ],
      "metadata": {
        "id": "QVWYy0z_CbD5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4️⃣ Modify training config"
      ],
      "metadata": {
        "id": "0Mqrkgn2CbvJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The original learning rate (LR) is set for 8-GPU training.\n",
        "# We divide it by 8 since we only use one GPU.\n",
        "cfg.optimizer.lr = 0.02 / 8\n",
        "cfg.lr_config.warmup = None\n",
        "cfg.log_config.interval = 10\n",
        "\n",
        "# Epochs\n",
        "cfg.runner.max_epochs = 12\n",
        "\n",
        "# Set seed thus the results are more reproducible\n",
        "cfg.seed = 0\n",
        "set_random_seed(0, deterministic=False)\n",
        "cfg.gpu_ids = range(1)\n",
        "\n",
        "# ⭐️ Set the checkpoint interval.\n",
        "cfg.checkpoint_config.interval = 1\n",
        "\n",
        "# Set up working dir to save files and logs.\n",
        "cfg.work_dir = './tutorial_exps'"
      ],
      "metadata": {
        "id": "UzrcQ8_FCegz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5️⃣ Modify evaluation config"
      ],
      "metadata": {
        "id": "tjy1AZxvC1B6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Change the evaluation metric since we use customized dataset.\n",
        "cfg.evaluation.metric = 'mAP'\n",
        "\n",
        "# ⭐️ Set the evaluation interval.\n",
        "cfg.evaluation.interval = 1"
      ],
      "metadata": {
        "id": "Kdv9vlNa9bdD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🎾 Define Weights and Biases Hook\n",
        "\n",
        "MMDetection comes with a dedicated Weights and Biases Hook - `MMDetWandHook`. MMCV, the parent repository, has a `WandbLoggerHook` that can be used to for basic logging. \n",
        "\n",
        "With this dedicated hook, you can:\n",
        "\n",
        "* log train and eval metrics along with system (CPU/GPU) metrics, \n",
        "* visualize the validation dataset as interactive [W&B Tables](https://docs.wandb.ai/guides/data-vis),\n",
        "* visualize the model prediction as interactive W&B Tables, and\n",
        "* save the model checkpoints as [W&B Artifacts](https://docs.wandb.ai/guides/artifacts)."
      ],
      "metadata": {
        "id": "4tPeETQSBuHH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To use this hook, you can append a dict to `log_config.hooks`. The `log_config` wraps multiple logger hooks like  the `TextLoggerHook` used below.\n",
        "\n",
        "There are four important arguments in the `MMDetWandbHook` that can help you get the most out of MMDetection. \n",
        "\n",
        "- `init_kwargs`: Use this argument to in-turn pass arguments to `wandb.init`. You can use it to set the W&B project name, set the team name entity if you want to log the runs to a team account, pass the configuration, and more. Check out what all can you pass to `wandb.init` [here](https://docs.wandb.ai/ref/python/init).\n",
        "\n",
        "- `log_checkpoint`: The model checkpoints are saved at intervals determined by `checkpoint_config.interval` (starred above). If `log_checkpoint` is `True` the saved checkpoints will be saved as versioned W&B Artifact. Note that this feature is dependent on MMCV's [`CheckpointHook`](https://mmcv.readthedocs.io/en/latest/api.html#mmcv.runner.CheckpointHook).\n",
        "\n",
        "- `log_checkpoint_metadata`: If `log_checkpoint_metadata` is True, every checkpoint artifact will have a metadata associated with it. The metadata contains the evaluation metrics computed on validation data with that checkpoint along with the current epoch. If True, it also marks the checkpoint version with the best evaluation metric with a `best` alias. You can choose the best checkpoint in the W&B Artifacts UI using this.\n",
        "\n",
        "- `num_eval_images`: At every evaluation interval, the `MMDetWandbHook` logs the model prediction as interactive W&B Tables. The eval interval is determined by `evaluation.interval` (starred above). The number of samples logged is given by `num_eval_images`. The predicted bounding boxes along with the ground truth are logged at every evaluation interval. However, the validation data is logged just once. This Feature is dependent on MMCV's [`EvalHook`](https://mmcv.readthedocs.io/en/latest/api.html#mmcv.runner.EvalHook) or [`DistEvalHook`](https://mmcv.readthedocs.io/en/latest/api.html#mmcv.runner.DistEvalHook)."
      ],
      "metadata": {
        "id": "9CfkqGQU5qTs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cfg.log_config.hooks = [\n",
        "    dict(type='TextLoggerHook'),\n",
        "    dict(type='MMDetWandbHook',\n",
        "         init_kwargs={'project': 'MMDetection-tutorial'},\n",
        "         interval=10,\n",
        "         log_checkpoint=True,\n",
        "         log_checkpoint_metadata=True,\n",
        "         num_eval_images=10)]"
      ],
      "metadata": {
        "id": "WTEdPDRaBz2C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🏐 Train\n",
        "\n",
        "Now that we have the dataset, pretrained model weight, and have defined the configs. Let's stitch them together to train an object detector."
      ],
      "metadata": {
        "id": "lEULcJ8HkKD9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1️⃣ Build the Dataset"
      ],
      "metadata": {
        "id": "hyiDMPIZkLX4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build dataset\n",
        "datasets = [build_dataset(cfg.data.train)]"
      ],
      "metadata": {
        "id": "J8EXRJIC_-gp",
        "outputId": "72705e56-c90e-45ed-917a-3104b87df25a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:44: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:47: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "/content/mmdetection/mmdet/datasets/custom.py:180: UserWarning: CustomDataset does not support filtering empty gt images.\n",
            "  'CustomDataset does not support filtering empty gt images.')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2️⃣ Build the Model"
      ],
      "metadata": {
        "id": "o1ONHfVZkNLg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the detector\n",
        "model = build_detector(\n",
        "    cfg.model, train_cfg=cfg.get('train_cfg'), test_cfg=cfg.get('test_cfg'))\n",
        "# Add an attribute for visualization convenience\n",
        "model.CLASSES = datasets[0].CLASSES"
      ],
      "metadata": {
        "id": "WGvp8VgXAB-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3️⃣ Train with W&B"
      ],
      "metadata": {
        "id": "JWXWkg7tkO0Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create work_dir\n",
        "# mmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\n",
        "train_detector(model, datasets, cfg, distributed=False, validate=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "459724d95943402a9f0e3e8e25fee172",
            "48d05465bc2d425994191be14967abfe",
            "49ed2a828c1c4d089716eb7f3fbbe250",
            "49c80972112e4a0080a66ed82095c0c8",
            "3fbcbcbacd9a4c33a74f2707ff8f5381",
            "63b239b43e014cac856f7801231f2312",
            "2b07721c0e5a460997386b99ddc4d69d",
            "e7f9e300d6c845e8afba216fbfb44d18"
          ]
        },
        "id": "vyT_rLeKeGk7",
        "outputId": "c331daab-d1fd-4a76-a705-da6a8d25406b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:44: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:47: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "2022-03-24 08:55:36,594 - mmdet - INFO - load checkpoint from local path: checkpoints/faster_rcnn_r50_caffe_fpn_mstrain_3x_coco_20210526_095054-1f77628b.pth\n",
            "2022-03-24 08:55:36,730 - mmdet - WARNING - The model and loaded state dict do not match exactly\n",
            "\n",
            "size mismatch for roi_head.bbox_head.fc_cls.weight: copying a param with shape torch.Size([81, 1024]) from checkpoint, the shape in current model is torch.Size([4, 1024]).\n",
            "size mismatch for roi_head.bbox_head.fc_cls.bias: copying a param with shape torch.Size([81]) from checkpoint, the shape in current model is torch.Size([4]).\n",
            "size mismatch for roi_head.bbox_head.fc_reg.weight: copying a param with shape torch.Size([320, 1024]) from checkpoint, the shape in current model is torch.Size([12, 1024]).\n",
            "size mismatch for roi_head.bbox_head.fc_reg.bias: copying a param with shape torch.Size([320]) from checkpoint, the shape in current model is torch.Size([12]).\n",
            "2022-03-24 08:55:36,738 - mmdet - INFO - Start running, host: root@335684d19037, work_dir: /content/tutorial_exps\n",
            "2022-03-24 08:55:36,739 - mmdet - INFO - Hooks will be executed in the following order:\n",
            "before_run:\n",
            "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
            "(NORMAL      ) CheckpointHook                     \n",
            "(LOW         ) EvalHook                           \n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            "(VERY_LOW    ) MMDetWandbHook                     \n",
            " -------------------- \n",
            "before_train_epoch:\n",
            "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
            "(NORMAL      ) NumClassCheckHook                  \n",
            "(LOW         ) IterTimerHook                      \n",
            "(LOW         ) EvalHook                           \n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            "(VERY_LOW    ) MMDetWandbHook                     \n",
            " -------------------- \n",
            "before_train_iter:\n",
            "(VERY_HIGH   ) StepLrUpdaterHook                  \n",
            "(LOW         ) IterTimerHook                      \n",
            "(LOW         ) EvalHook                           \n",
            " -------------------- \n",
            "after_train_iter:\n",
            "(ABOVE_NORMAL) OptimizerHook                      \n",
            "(NORMAL      ) CheckpointHook                     \n",
            "(LOW         ) IterTimerHook                      \n",
            "(LOW         ) EvalHook                           \n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            "(VERY_LOW    ) MMDetWandbHook                     \n",
            " -------------------- \n",
            "after_train_epoch:\n",
            "(NORMAL      ) CheckpointHook                     \n",
            "(LOW         ) EvalHook                           \n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            "(VERY_LOW    ) MMDetWandbHook                     \n",
            " -------------------- \n",
            "before_val_epoch:\n",
            "(NORMAL      ) NumClassCheckHook                  \n",
            "(LOW         ) IterTimerHook                      \n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            "(VERY_LOW    ) MMDetWandbHook                     \n",
            " -------------------- \n",
            "before_val_iter:\n",
            "(LOW         ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_iter:\n",
            "(LOW         ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_epoch:\n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            "(VERY_LOW    ) MMDetWandbHook                     \n",
            " -------------------- \n",
            "after_run:\n",
            "(VERY_LOW    ) TextLoggerHook                     \n",
            "(VERY_LOW    ) MMDetWandbHook                     \n",
            " -------------------- \n",
            "2022-03-24 08:55:36,741 - mmdet - INFO - workflow: [('train', 1)], max: 12 epochs\n",
            "2022-03-24 08:55:36,745 - mmdet - INFO - Checkpoints will be saved to /content/tutorial_exps by HardDiskBackend.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mayut\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220324_085536-1jr64j4h</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/ayut/MMDetection-tutorial/runs/1jr64j4h\" target=\"_blank\">robust-vortex-1</a></strong> to <a href=\"https://wandb.ai/ayut/MMDetection-tutorial\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/mmdetection/mmdet/core/hook/wandblogger_hook.py:109: UserWarning: To log mmdetection Config, pass it to init_kwargs of MMDetWandbHook.\n",
            "  'pass it to init_kwargs of MMDetWandbHook.', UserWarning)\n",
            "2022-03-24 08:56:00,585 - mmdet - INFO - Epoch [1][10/25]\tlr: 2.500e-03, eta: 0:05:39, time: 1.171, data_time: 0.230, memory: 2770, loss_rpn_cls: 0.0250, loss_rpn_bbox: 0.0173, loss_cls: 0.5387, acc: 81.6016, loss_bbox: 0.3951, loss: 0.9761\n",
            "2022-03-24 08:56:10,622 - mmdet - INFO - Epoch [1][20/25]\tlr: 2.500e-03, eta: 0:05:04, time: 1.003, data_time: 0.059, memory: 2770, loss_rpn_cls: 0.0135, loss_rpn_bbox: 0.0119, loss_cls: 0.1753, acc: 93.4668, loss_bbox: 0.3242, loss: 0.5249\n",
            "2022-03-24 08:56:15,244 - mmdet - INFO - Saving checkpoint at 1 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 25/25, 3.9 task/s, elapsed: 6s, ETA:     0s\n",
            "---------------iou_thr: 0.5---------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-03-24 08:56:24,478 - mmdet - INFO - \n",
            "+------------+-----+------+--------+-------+\n",
            "| class      | gts | dets | recall | ap    |\n",
            "+------------+-----+------+--------+-------+\n",
            "| Car        | 62  | 691  | 0.952  | 0.764 |\n",
            "| Pedestrian | 13  | 105  | 0.846  | 0.805 |\n",
            "| Cyclist    | 7   | 96   | 0.571  | 0.109 |\n",
            "+------------+-----+------+--------+-------+\n",
            "| mAP        |     |      |        | 0.559 |\n",
            "+------------+-----+------+--------+-------+\n",
            "2022-03-24 08:56:24,482 - mmdet - INFO - Epoch(val) [1][25]\tAP50: 0.5590, mAP: 0.5591\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "---------------iou_thr: 0.5---------------\n",
            "\n",
            "---------------iou_thr: 0.5---------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-03-24 08:56:40,791 - mmdet - INFO - Epoch [2][10/25]\tlr: 2.500e-03, eta: 0:04:17, time: 1.224, data_time: 0.254, memory: 2770, loss_rpn_cls: 0.0167, loss_rpn_bbox: 0.0139, loss_cls: 0.1528, acc: 94.6680, loss_bbox: 0.2686, loss: 0.4519\n",
            "2022-03-24 08:56:50,816 - mmdet - INFO - Epoch [2][20/25]\tlr: 2.500e-03, eta: 0:04:09, time: 1.003, data_time: 0.060, memory: 2770, loss_rpn_cls: 0.0144, loss_rpn_bbox: 0.0129, loss_cls: 0.1410, acc: 94.7363, loss_bbox: 0.2124, loss: 0.3806\n",
            "2022-03-24 08:56:55,437 - mmdet - INFO - Saving checkpoint at 2 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 25/25, 3.9 task/s, elapsed: 6s, ETA:     0s\n",
            "---------------iou_thr: 0.5---------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-03-24 08:57:04,239 - mmdet - INFO - \n",
            "+------------+-----+------+--------+-------+\n",
            "| class      | gts | dets | recall | ap    |\n",
            "+------------+-----+------+--------+-------+\n",
            "| Car        | 62  | 346  | 0.984  | 0.851 |\n",
            "| Pedestrian | 13  | 70   | 0.846  | 0.751 |\n",
            "| Cyclist    | 7   | 42   | 0.571  | 0.259 |\n",
            "+------------+-----+------+--------+-------+\n",
            "| mAP        |     |      |        | 0.620 |\n",
            "+------------+-----+------+--------+-------+\n",
            "2022-03-24 08:57:04,247 - mmdet - INFO - Epoch(val) [2][25]\tAP50: 0.6200, mAP: 0.6201\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "---------------iou_thr: 0.5---------------\n",
            "\n",
            "---------------iou_thr: 0.5---------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-03-24 08:57:20,140 - mmdet - INFO - Epoch [3][10/25]\tlr: 2.500e-03, eta: 0:03:43, time: 1.193, data_time: 0.244, memory: 2770, loss_rpn_cls: 0.0038, loss_rpn_bbox: 0.0103, loss_cls: 0.0947, acc: 96.5527, loss_bbox: 0.1516, loss: 0.2603\n",
            "2022-03-24 08:57:30,181 - mmdet - INFO - Epoch [3][20/25]\tlr: 2.500e-03, eta: 0:03:36, time: 1.004, data_time: 0.059, memory: 2770, loss_rpn_cls: 0.0083, loss_rpn_bbox: 0.0129, loss_cls: 0.1469, acc: 94.4629, loss_bbox: 0.2678, loss: 0.4359\n",
            "2022-03-24 08:57:34,867 - mmdet - INFO - Saving checkpoint at 3 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 25/25, 4.0 task/s, elapsed: 6s, ETA:     0s\n",
            "---------------iou_thr: 0.5---------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-03-24 08:57:43,542 - mmdet - INFO - \n",
            "+------------+-----+------+--------+-------+\n",
            "| class      | gts | dets | recall | ap    |\n",
            "+------------+-----+------+--------+-------+\n",
            "| Car        | 62  | 222  | 0.968  | 0.864 |\n",
            "| Pedestrian | 13  | 76   | 0.923  | 0.675 |\n",
            "| Cyclist    | 7   | 50   | 0.429  | 0.216 |\n",
            "+------------+-----+------+--------+-------+\n",
            "| mAP        |     |      |        | 0.585 |\n",
            "+------------+-----+------+--------+-------+\n",
            "2022-03-24 08:57:43,545 - mmdet - INFO - Epoch(val) [3][25]\tAP50: 0.5850, mAP: 0.5849\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "---------------iou_thr: 0.5---------------\n",
            "\n",
            "---------------iou_thr: 0.5---------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-03-24 08:57:59,663 - mmdet - INFO - Epoch [4][10/25]\tlr: 2.500e-03, eta: 0:03:17, time: 1.215, data_time: 0.245, memory: 2770, loss_rpn_cls: 0.0055, loss_rpn_bbox: 0.0132, loss_cls: 0.1232, acc: 95.2734, loss_bbox: 0.2241, loss: 0.3660\n",
            "2022-03-24 08:58:09,714 - mmdet - INFO - Epoch [4][20/25]\tlr: 2.500e-03, eta: 0:03:10, time: 1.003, data_time: 0.059, memory: 2770, loss_rpn_cls: 0.0056, loss_rpn_bbox: 0.0116, loss_cls: 0.1221, acc: 95.4785, loss_bbox: 0.2169, loss: 0.3562\n",
            "2022-03-24 08:58:14,294 - mmdet - INFO - Saving checkpoint at 4 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 25/25, 4.0 task/s, elapsed: 6s, ETA:     0s\n",
            "---------------iou_thr: 0.5---------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-03-24 08:58:22,995 - mmdet - INFO - \n",
            "+------------+-----+------+--------+-------+\n",
            "| class      | gts | dets | recall | ap    |\n",
            "+------------+-----+------+--------+-------+\n",
            "| Car        | 62  | 173  | 0.903  | 0.815 |\n",
            "| Pedestrian | 13  | 76   | 0.923  | 0.783 |\n",
            "| Cyclist    | 7   | 51   | 0.571  | 0.191 |\n",
            "+------------+-----+------+--------+-------+\n",
            "| mAP        |     |      |        | 0.596 |\n",
            "+------------+-----+------+--------+-------+\n",
            "2022-03-24 08:58:22,998 - mmdet - INFO - Epoch(val) [4][25]\tAP50: 0.5960, mAP: 0.5963\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "---------------iou_thr: 0.5---------------\n",
            "\n",
            "---------------iou_thr: 0.5---------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-03-24 08:58:39,035 - mmdet - INFO - Epoch [5][10/25]\tlr: 2.500e-03, eta: 0:02:53, time: 1.210, data_time: 0.248, memory: 2770, loss_rpn_cls: 0.0025, loss_rpn_bbox: 0.0093, loss_cls: 0.1048, acc: 96.1621, loss_bbox: 0.2071, loss: 0.3237\n",
            "2022-03-24 08:58:49,395 - mmdet - INFO - Epoch [5][20/25]\tlr: 2.500e-03, eta: 0:02:45, time: 1.035, data_time: 0.063, memory: 2770, loss_rpn_cls: 0.0033, loss_rpn_bbox: 0.0106, loss_cls: 0.0931, acc: 96.6602, loss_bbox: 0.1880, loss: 0.2949\n",
            "2022-03-24 08:58:54,024 - mmdet - INFO - Saving checkpoint at 5 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 25/25, 4.0 task/s, elapsed: 6s, ETA:     0s\n",
            "---------------iou_thr: 0.5---------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-03-24 08:59:02,743 - mmdet - INFO - \n",
            "+------------+-----+------+--------+-------+\n",
            "| class      | gts | dets | recall | ap    |\n",
            "+------------+-----+------+--------+-------+\n",
            "| Car        | 62  | 173  | 0.935  | 0.840 |\n",
            "| Pedestrian | 13  | 82   | 0.923  | 0.767 |\n",
            "| Cyclist    | 7   | 59   | 0.429  | 0.092 |\n",
            "+------------+-----+------+--------+-------+\n",
            "| mAP        |     |      |        | 0.566 |\n",
            "+------------+-----+------+--------+-------+\n",
            "2022-03-24 08:59:02,750 - mmdet - INFO - Epoch(val) [5][25]\tAP50: 0.5660, mAP: 0.5664\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "---------------iou_thr: 0.5---------------\n",
            "\n",
            "---------------iou_thr: 0.5---------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-03-24 08:59:19,090 - mmdet - INFO - Epoch [6][10/25]\tlr: 2.500e-03, eta: 0:02:30, time: 1.215, data_time: 0.254, memory: 2770, loss_rpn_cls: 0.0050, loss_rpn_bbox: 0.0082, loss_cls: 0.0817, acc: 96.9922, loss_bbox: 0.1762, loss: 0.2711\n",
            "2022-03-24 08:59:29,267 - mmdet - INFO - Epoch [6][20/25]\tlr: 2.500e-03, eta: 0:02:22, time: 1.019, data_time: 0.060, memory: 2770, loss_rpn_cls: 0.0018, loss_rpn_bbox: 0.0101, loss_cls: 0.0897, acc: 96.6309, loss_bbox: 0.1810, loss: 0.2826\n",
            "2022-03-24 08:59:33,830 - mmdet - INFO - Saving checkpoint at 6 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 25/25, 4.0 task/s, elapsed: 6s, ETA:     0s\n",
            "---------------iou_thr: 0.5---------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-03-24 08:59:42,905 - mmdet - INFO - \n",
            "+------------+-----+------+--------+-------+\n",
            "| class      | gts | dets | recall | ap    |\n",
            "+------------+-----+------+--------+-------+\n",
            "| Car        | 62  | 184  | 0.952  | 0.838 |\n",
            "| Pedestrian | 13  | 66   | 0.923  | 0.873 |\n",
            "| Cyclist    | 7   | 57   | 0.571  | 0.086 |\n",
            "+------------+-----+------+--------+-------+\n",
            "| mAP        |     |      |        | 0.599 |\n",
            "+------------+-----+------+--------+-------+\n",
            "2022-03-24 08:59:42,909 - mmdet - INFO - Epoch(val) [6][25]\tAP50: 0.5990, mAP: 0.5991\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "---------------iou_thr: 0.5---------------\n",
            "\n",
            "---------------iou_thr: 0.5---------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-03-24 08:59:58,839 - mmdet - INFO - Epoch [7][10/25]\tlr: 2.500e-03, eta: 0:02:06, time: 1.202, data_time: 0.251, memory: 2770, loss_rpn_cls: 0.0026, loss_rpn_bbox: 0.0096, loss_cls: 0.0826, acc: 96.9141, loss_bbox: 0.1728, loss: 0.2676\n",
            "2022-03-24 09:00:08,940 - mmdet - INFO - Epoch [7][20/25]\tlr: 2.500e-03, eta: 0:01:58, time: 1.010, data_time: 0.058, memory: 2770, loss_rpn_cls: 0.0025, loss_rpn_bbox: 0.0112, loss_cls: 0.0842, acc: 96.5625, loss_bbox: 0.1819, loss: 0.2797\n",
            "2022-03-24 09:00:13,668 - mmdet - INFO - Saving checkpoint at 7 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 25/25, 4.0 task/s, elapsed: 6s, ETA:     0s\n",
            "---------------iou_thr: 0.5---------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-03-24 09:00:22,446 - mmdet - INFO - \n",
            "+------------+-----+------+--------+-------+\n",
            "| class      | gts | dets | recall | ap    |\n",
            "+------------+-----+------+--------+-------+\n",
            "| Car        | 62  | 117  | 0.919  | 0.809 |\n",
            "| Pedestrian | 13  | 61   | 0.923  | 0.868 |\n",
            "| Cyclist    | 7   | 60   | 0.429  | 0.055 |\n",
            "+------------+-----+------+--------+-------+\n",
            "| mAP        |     |      |        | 0.577 |\n",
            "+------------+-----+------+--------+-------+\n",
            "2022-03-24 09:00:22,449 - mmdet - INFO - Epoch(val) [7][25]\tAP50: 0.5770, mAP: 0.5773\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "---------------iou_thr: 0.5---------------\n",
            "\n",
            "---------------iou_thr: 0.5---------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-03-24 09:00:38,431 - mmdet - INFO - Epoch [8][10/25]\tlr: 2.500e-03, eta: 0:01:43, time: 1.203, data_time: 0.243, memory: 2770, loss_rpn_cls: 0.0027, loss_rpn_bbox: 0.0090, loss_cls: 0.0719, acc: 97.0117, loss_bbox: 0.1439, loss: 0.2275\n",
            "2022-03-24 09:00:48,632 - mmdet - INFO - Epoch [8][20/25]\tlr: 2.500e-03, eta: 0:01:35, time: 1.019, data_time: 0.060, memory: 2770, loss_rpn_cls: 0.0016, loss_rpn_bbox: 0.0079, loss_cls: 0.0741, acc: 97.1777, loss_bbox: 0.1687, loss: 0.2523\n",
            "2022-03-24 09:00:53,286 - mmdet - INFO - Saving checkpoint at 8 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 25/25, 4.0 task/s, elapsed: 6s, ETA:     0s\n",
            "---------------iou_thr: 0.5---------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-03-24 09:01:02,032 - mmdet - INFO - \n",
            "+------------+-----+------+--------+-------+\n",
            "| class      | gts | dets | recall | ap    |\n",
            "+------------+-----+------+--------+-------+\n",
            "| Car        | 62  | 147  | 0.968  | 0.868 |\n",
            "| Pedestrian | 13  | 39   | 0.846  | 0.785 |\n",
            "| Cyclist    | 7   | 48   | 0.429  | 0.051 |\n",
            "+------------+-----+------+--------+-------+\n",
            "| mAP        |     |      |        | 0.568 |\n",
            "+------------+-----+------+--------+-------+\n",
            "2022-03-24 09:01:02,036 - mmdet - INFO - Epoch(val) [8][25]\tAP50: 0.5680, mAP: 0.5682\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "---------------iou_thr: 0.5---------------\n",
            "\n",
            "---------------iou_thr: 0.5---------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-03-24 09:01:17,995 - mmdet - INFO - Epoch [9][10/25]\tlr: 2.500e-04, eta: 0:01:21, time: 1.201, data_time: 0.244, memory: 2770, loss_rpn_cls: 0.0011, loss_rpn_bbox: 0.0083, loss_cls: 0.0580, acc: 97.7441, loss_bbox: 0.1306, loss: 0.1980\n",
            "2022-03-24 09:01:28,147 - mmdet - INFO - Epoch [9][20/25]\tlr: 2.500e-04, eta: 0:01:12, time: 1.015, data_time: 0.059, memory: 2770, loss_rpn_cls: 0.0006, loss_rpn_bbox: 0.0063, loss_cls: 0.0509, acc: 97.9980, loss_bbox: 0.1068, loss: 0.1646\n",
            "2022-03-24 09:01:32,799 - mmdet - INFO - Saving checkpoint at 9 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 25/25, 4.0 task/s, elapsed: 6s, ETA:     0s\n",
            "---------------iou_thr: 0.5---------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-03-24 09:01:41,612 - mmdet - INFO - \n",
            "+------------+-----+------+--------+-------+\n",
            "| class      | gts | dets | recall | ap    |\n",
            "+------------+-----+------+--------+-------+\n",
            "| Car        | 62  | 145  | 0.968  | 0.864 |\n",
            "| Pedestrian | 13  | 42   | 0.846  | 0.768 |\n",
            "| Cyclist    | 7   | 50   | 0.429  | 0.064 |\n",
            "+------------+-----+------+--------+-------+\n",
            "| mAP        |     |      |        | 0.566 |\n",
            "+------------+-----+------+--------+-------+\n",
            "2022-03-24 09:01:41,619 - mmdet - INFO - Epoch(val) [9][25]\tAP50: 0.5660, mAP: 0.5656\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "---------------iou_thr: 0.5---------------\n",
            "\n",
            "---------------iou_thr: 0.5---------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-03-24 09:01:57,654 - mmdet - INFO - Epoch [10][10/25]\tlr: 2.500e-04, eta: 0:00:58, time: 1.210, data_time: 0.246, memory: 2770, loss_rpn_cls: 0.0026, loss_rpn_bbox: 0.0080, loss_cls: 0.0630, acc: 97.5781, loss_bbox: 0.1295, loss: 0.2032\n",
            "2022-03-24 09:02:07,855 - mmdet - INFO - Epoch [10][20/25]\tlr: 2.500e-04, eta: 0:00:49, time: 1.019, data_time: 0.060, memory: 2770, loss_rpn_cls: 0.0008, loss_rpn_bbox: 0.0059, loss_cls: 0.0575, acc: 97.6953, loss_bbox: 0.1264, loss: 0.1905\n",
            "2022-03-24 09:02:12,530 - mmdet - INFO - Saving checkpoint at 10 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 25/25, 3.8 task/s, elapsed: 7s, ETA:     0s\n",
            "---------------iou_thr: 0.5---------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-03-24 09:02:21,840 - mmdet - INFO - \n",
            "+------------+-----+------+--------+-------+\n",
            "| class      | gts | dets | recall | ap    |\n",
            "+------------+-----+------+--------+-------+\n",
            "| Car        | 62  | 137  | 0.952  | 0.857 |\n",
            "| Pedestrian | 13  | 42   | 0.846  | 0.782 |\n",
            "| Cyclist    | 7   | 49   | 0.429  | 0.081 |\n",
            "+------------+-----+------+--------+-------+\n",
            "| mAP        |     |      |        | 0.574 |\n",
            "+------------+-----+------+--------+-------+\n",
            "2022-03-24 09:02:21,852 - mmdet - INFO - Epoch(val) [10][25]\tAP50: 0.5740, mAP: 0.5736\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "---------------iou_thr: 0.5---------------\n",
            "\n",
            "---------------iou_thr: 0.5---------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-03-24 09:02:38,121 - mmdet - INFO - Epoch [11][10/25]\tlr: 2.500e-04, eta: 0:00:35, time: 1.217, data_time: 0.262, memory: 2770, loss_rpn_cls: 0.0012, loss_rpn_bbox: 0.0069, loss_cls: 0.0629, acc: 97.3633, loss_bbox: 0.1180, loss: 0.1891\n",
            "2022-03-24 09:02:48,369 - mmdet - INFO - Epoch [11][20/25]\tlr: 2.500e-04, eta: 0:00:27, time: 1.023, data_time: 0.058, memory: 2770, loss_rpn_cls: 0.0011, loss_rpn_bbox: 0.0074, loss_cls: 0.0559, acc: 97.9395, loss_bbox: 0.1250, loss: 0.1895\n",
            "2022-03-24 09:02:53,059 - mmdet - INFO - Saving checkpoint at 11 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 25/25, 3.9 task/s, elapsed: 6s, ETA:     0s\n",
            "---------------iou_thr: 0.5---------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-03-24 09:03:02,098 - mmdet - INFO - \n",
            "+------------+-----+------+--------+-------+\n",
            "| class      | gts | dets | recall | ap    |\n",
            "+------------+-----+------+--------+-------+\n",
            "| Car        | 62  | 132  | 0.952  | 0.852 |\n",
            "| Pedestrian | 13  | 42   | 0.846  | 0.790 |\n",
            "| Cyclist    | 7   | 52   | 0.429  | 0.081 |\n",
            "+------------+-----+------+--------+-------+\n",
            "| mAP        |     |      |        | 0.575 |\n",
            "+------------+-----+------+--------+-------+\n",
            "2022-03-24 09:03:02,101 - mmdet - INFO - Epoch(val) [11][25]\tAP50: 0.5750, mAP: 0.5746\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "---------------iou_thr: 0.5---------------\n",
            "\n",
            "---------------iou_thr: 0.5---------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-03-24 09:03:18,372 - mmdet - INFO - Epoch [12][10/25]\tlr: 2.500e-05, eta: 0:00:13, time: 1.229, data_time: 0.256, memory: 2770, loss_rpn_cls: 0.0013, loss_rpn_bbox: 0.0061, loss_cls: 0.0542, acc: 97.9395, loss_bbox: 0.1197, loss: 0.1813\n",
            "2022-03-24 09:03:28,510 - mmdet - INFO - Epoch [12][20/25]\tlr: 2.500e-05, eta: 0:00:04, time: 1.012, data_time: 0.060, memory: 2770, loss_rpn_cls: 0.0019, loss_rpn_bbox: 0.0048, loss_cls: 0.0484, acc: 98.0273, loss_bbox: 0.0887, loss: 0.1438\n",
            "2022-03-24 09:03:33,185 - mmdet - INFO - Saving checkpoint at 12 epochs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>] 25/25, 3.9 task/s, elapsed: 6s, ETA:     0s\n",
            "---------------iou_thr: 0.5---------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-03-24 09:03:42,359 - mmdet - INFO - \n",
            "+------------+-----+------+--------+-------+\n",
            "| class      | gts | dets | recall | ap    |\n",
            "+------------+-----+------+--------+-------+\n",
            "| Car        | 62  | 132  | 0.952  | 0.851 |\n",
            "| Pedestrian | 13  | 42   | 0.846  | 0.790 |\n",
            "| Cyclist    | 7   | 52   | 0.429  | 0.081 |\n",
            "+------------+-----+------+--------+-------+\n",
            "| mAP        |     |      |        | 0.574 |\n",
            "+------------+-----+------+--------+-------+\n",
            "2022-03-24 09:03:42,363 - mmdet - INFO - Epoch(val) [12][25]\tAP50: 0.5740, mAP: 0.5742\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "---------------iou_thr: 0.5---------------\n",
            "\n",
            "---------------iou_thr: 0.5---------------\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='3784.758 MB of 3784.758 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "459724d95943402a9f0e3e8e25fee172"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>learning_rate</td><td>████████████████▂▂▂▂▂▂▁▁</td></tr><tr><td>momentum</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/acc</td><td>▁▆▇▇▇▆▇▇▇▇█▇█▇██████████</td></tr><tr><td>train/loss</td><td>█▄▄▃▂▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>train/loss_bbox</td><td>█▆▅▄▂▅▄▄▄▃▃▃▃▃▂▃▂▁▂▂▂▂▂▁</td></tr><tr><td>train/loss_cls</td><td>█▃▂▂▂▂▂▂▂▂▁▂▁▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train/loss_rpn_bbox</td><td>█▅▆▆▄▆▆▅▄▄▃▄▄▅▃▃▃▂▃▂▂▂▂▁</td></tr><tr><td>train/loss_rpn_cls</td><td>█▅▆▅▂▃▂▂▂▂▂▁▂▂▂▁▁▁▂▁▁▁▁▁</td></tr><tr><td>val/AP50</td><td>▁█▄▅▂▆▃▂▂▃▃▃</td></tr><tr><td>val/mAP</td><td>▁█▄▅▂▆▃▂▂▃▃▃</td></tr><tr><td>val/val_step</td><td>▁▂▂▃▄▄▅▅▆▇▇█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>learning_rate</td><td>3e-05</td></tr><tr><td>momentum</td><td>0.9</td></tr><tr><td>train/acc</td><td>98.02734</td></tr><tr><td>train/loss</td><td>0.14381</td></tr><tr><td>train/loss_bbox</td><td>0.08874</td></tr><tr><td>train/loss_cls</td><td>0.04837</td></tr><tr><td>train/loss_rpn_bbox</td><td>0.00482</td></tr><tr><td>train/loss_rpn_cls</td><td>0.00187</td></tr><tr><td>val/AP50</td><td>0.574</td></tr><tr><td>val/mAP</td><td>0.57423</td></tr><tr><td>val/val_step</td><td>11</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">robust-vortex-1</strong>: <a href=\"https://wandb.ai/ayut/MMDetection-tutorial/runs/1jr64j4h\" target=\"_blank\">https://wandb.ai/ayut/MMDetection-tutorial/runs/1jr64j4h</a><br/>Synced 5 W&B file(s), 0 media file(s), 38 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20220324_085536-1jr64j4h/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4️⃣ Notes on using `MMDetWandbHook`. \n",
        "\n",
        "Using `MMDetWandbHook` is easy and in most cases it will throw friendly `UserWarning` if something is not quite right. However in the best interest, here are some of things and best practices you should keep in mind:\n",
        "\n",
        "* The `MMDetWandbHook` depends on `CheckpointHook` for logging the checkpoints as W&B Artifacts and `EvalHook`/`DistEvalHook` for logging validation data and model predictions. If anyone or both aren't available, this hook will give `UserWarning` and not cause any error. \n",
        "\n",
        "* The priority of both `CheckpointHook` and `EvalHook`/`DistEvalHook` should be more than `MMDetWandbHook`. \n",
        "\n",
        "* The validation data is logged once as `val_data` W&B Table. The evaluation tables, use reference to this data thus you will not be uploading the same data multiple times. \n",
        "\n",
        "* If you want to log the configuration to W&B, pass this key-value pair `'config': cfg._cfg_dict.to_dict()` to `init_kwargs`. "
      ],
      "metadata": {
        "id": "HnPPp2EzJjpo"
      }
    }
  ]
}