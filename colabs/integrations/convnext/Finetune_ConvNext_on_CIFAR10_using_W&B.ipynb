{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Finetune ConvNext on CIFAR10 using W&B",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPKvhiEC75DHbgGpIR7kIgq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayulockin/examples/blob/master/colabs/integrations/convnext/Finetune_ConvNext_on_CIFAR10_using_W%26B.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use this notebook to finetune a ConvNeXt-tiny model on CIFAR 10 dataset. The [official ConvNeXt repository](https://github.com/facebookresearch/ConvNeXt) is instrumented with [Weights and Biases](https://wandb.ai/site). You can now easily log your train/test metrics and version control your model checkpoints to Weigths and Biases"
      ],
      "metadata": {
        "id": "LniKjqdogsrH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚öΩÔ∏è Installation and Setup\n",
        "\n",
        "The following installation instruction is based on [INSTALL.md](https://github.com/facebookresearch/ConvNeXt/blob/main/INSTALL.md) provided by the official ConvNeXt repository. "
      ],
      "metadata": {
        "id": "1JS4ffXFRnRr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qq torch==1.8.0+cu111 torchvision==0.9.0+cu111 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "!pip install -qq wandb timm==0.3.2 six tensorboardX"
      ],
      "metadata": {
        "id": "5YbEGpKrDKC5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the official ConvNeXt respository. "
      ],
      "metadata": {
        "id": "kDXQ-EpX9fsB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/facebookresearch/ConvNeXt"
      ],
      "metadata": {
        "id": "zmmHO1Cp4E90"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üèÄ Download the Dataset\n",
        "\n",
        "We will be finetuning on CIFAR-10 dataset. To use any custom dataset (CIFAR-10 here) the format of the dataset should be as shown below:\n",
        "\n",
        "```\n",
        "/path/to/dataset/\n",
        "  train/\n",
        "    class1/\n",
        "      img1.jpeg\n",
        "    class2/\n",
        "      img2.jpeg\n",
        "  val/\n",
        "    class1/\n",
        "      img3.jpeg\n",
        "    class2/\n",
        "      img4.jpeg\n",
        "```\n",
        "\n",
        "I have used this [repository](https://github.com/YoongiKim/CIFAR-10-images) that has the CIFAR-10 images in the required format. "
      ],
      "metadata": {
        "id": "yoVwkQ0v80KW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/YoongiKim/CIFAR-10-images"
      ],
      "metadata": {
        "id": "8xcQ6QV41k8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üèà Download Pretrained Weights\n",
        "\n",
        "We will be finetuning the ConvNeXt Tiny model pretrained on ImageNet 1K dataset."
      ],
      "metadata": {
        "id": "J6qUVfL29tH1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ConvNeXt/\n",
        "!wget https://dl.fbaipublicfiles.com/convnext/convnext_tiny_1k_224_ema.pth"
      ],
      "metadata": {
        "id": "TYPDl5bT8LZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üéæ Train with Weights and Biases\n",
        "\n",
        "If you want to log the train and evaluation metrics using Weights and Biases pass `--enable_wandb true`. \n",
        "\n",
        "You can also save the finetuned checkpoints as version controlled W&B [Artifacts](https://docs.wandb.ai/guides/artifacts) if you pass `--wandb_ckpt true`.\n",
        "\n"
      ],
      "metadata": {
        "id": "pSPgPCjp-Lro"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py --epochs 10 \\\n",
        "                --model convnext_tiny \\\n",
        "                --data_set image_folder \\\n",
        "                --data_path ../CIFAR-10-images/train \\\n",
        "                --eval_data_path ../CIFAR-10-images/test \\\n",
        "                --nb_classes 10 \\\n",
        "                --num_workers 8 \\\n",
        "                --warmup_epochs 0 \\\n",
        "                --save_ckpt true \\\n",
        "                --output_dir model_ckpt \\\n",
        "                --finetune convnext_tiny_1k_224_ema.pth \\\n",
        "                --cutmix 0 \\\n",
        "                --mixup 0 --lr 4e-4 \\\n",
        "                --enable_wandb true --wandb_ckpt true"
      ],
      "metadata": {
        "id": "_8sNl2Mb6x8_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üèê Conclusion\n",
        "\n",
        "* **The above setting gives a top-1 accuracy of ~95%.**\n",
        "* The ConvNeXt repository comes with modern training regimes and is easy to finetune on any dataset. \n",
        "* The finetune model achieves competitive results. \n",
        "\n",
        "* By passing two arguments you get the following:\n",
        "\n",
        "  * Repository of all your experiments (train and test metrics) as a [W&B Project](https://docs.wandb.ai/ref/app/pages/project-page). You can easily compare experiments to find the best performing model.\n",
        "  * Hyperparameters (Configs) used to train individual models. \n",
        "  * System (CPU/GPU/Disk) metrics.\n",
        "  * Model checkpoints saved as W&B Artifacts. They are versioned and easy to share. \n",
        "\n",
        "  Check out the associated [W&B run page](https://wandb.ai/ayut/convnext/runs/16vi9e31). $‚Üí$"
      ],
      "metadata": {
        "id": "350MmZgtBVWy"
      }
    }
  ]
}