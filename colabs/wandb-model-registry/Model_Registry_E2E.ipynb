{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/wandb/examples/blob/master/colabs/wandb-model-registry/Model_Registry_E2E.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.imgur.com/gb6B4ig.png\" width=\"400\" alt=\"Weights & Biases\" />\n",
    "\n",
    "<!--- @wandbcode{tables_mendeleev} -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artifacts and Model Registry Walkthrough \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "\n",
    "# source directory for all raw data\n",
    "DATA_SRC = \"nature_100\"\n",
    "IMAGES_PER_LABEL = 10\n",
    "BALANCED_SPLITS = {\"train\" : 8, \"val\" : 1, \"test\": 1}\n",
    "SRC = DATA_SRC\n",
    "PREFIX = \"GCS\" # convenient for tracking local data\n",
    "PROJECT_NAME = \"Model Registry E2E\" #@param {type:\"string\"}\n",
    "ENTITY=\"kenlee\"#@param {type:\"string\"}\n",
    "dataset_name = \"mnist\"\n",
    "\n",
    "# number of images per class label\n",
    "# the total number of images is 10X this (10 classes)\n",
    "TOTAL_IMAGES = IMAGES_PER_LABEL * 10\n",
    "RAW_DATA_AT = \"_\".join([PREFIX, \"raw_data\", str(TOTAL_IMAGES)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Registry Overview\n",
    "![dataset_card_overview](https://drive.google.com/uc?export=view&id=1Ea_vEhhbcqHBnooY-Efdo_tST6ULRW3e)\n",
    "\n",
    "1. Checkpoint the model every epoch and log as an artifact\n",
    "2. Link your best model to a **Registered Collection** in the Model Registry\n",
    "3. Retrieve the model from the collection for downstream evaluation or inference\n",
    "4. Add aliases depending on stage of model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set SIZE to \"TINY\", \"SMALL\", \"MEDIUM\", or \"LARGE\"\n",
    "# to select one of these three datasets\n",
    "# TINY dataset: 100 images, 30MB\n",
    "# SMALL dataset: 1000 images, 312MB\n",
    "# MEDIUM dataset: 5000 images, 1.5GB\n",
    "# LARGE dataset: 12,000 images, 3.6GB\n",
    "\n",
    "SIZE = \"TINY\"\n",
    "\n",
    "if SIZE == \"TINY\":\n",
    "  src_url = \"https://storage.googleapis.com/wandb_datasets/nature_100.zip\"\n",
    "  src_zip = \"nature_100.zip\"\n",
    "  DATA_SRC = \"nature_100\"\n",
    "  IMAGES_PER_LABEL = 10\n",
    "  BALANCED_SPLITS = {\"train\" : 8, \"val\" : 1, \"test\": 1}\n",
    "elif SIZE == \"SMALL\":\n",
    "  src_url = \"https://storage.googleapis.com/wandb_datasets/nature_1K.zip\"\n",
    "  src_zip = \"nature_1K.zip\"\n",
    "  DATA_SRC = \"nature_1K\"\n",
    "  IMAGES_PER_LABEL = 100\n",
    "  BALANCED_SPLITS = {\"train\" : 80, \"val\" : 10, \"test\": 10}\n",
    "elif SIZE == \"MEDIUM\":\n",
    "  src_url = \"https://storage.googleapis.com/wandb_datasets/nature_12K.zip\"\n",
    "  src_zip = \"nature_12K.zip\"\n",
    "  DATA_SRC = \"inaturalist_12K/train\" # (technically a subset of only 10K images)\n",
    "  IMAGES_PER_LABEL = 500\n",
    "  BALANCED_SPLITS = {\"train\" : 400, \"val\" : 50, \"test\": 50}\n",
    "elif SIZE == \"LARGE\":\n",
    "  src_url = \"https://storage.googleapis.com/wandb_datasets/nature_12K.zip\"\n",
    "  src_zip = \"nature_12K.zip\"\n",
    "  DATA_SRC = \"inaturalist_12K/train\" # (technically a subset of only 10K images)\n",
    "  IMAGES_PER_LABEL = 1000\n",
    "  BALANCED_SPLITS = {\"train\" : 800, \"val\" : 100, \"test\": 100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!curl -SL $src_url > $src_zip\n",
    "!unzip $src_zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0: Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start out by installing the experiment tracking library and setting up your free W&B account:\n",
    "\n",
    "\n",
    "*   `pip install wandb` – Install the W&B library\n",
    "*   `import wandb` – Import the wandb library\n",
    "*   `wandb login` – Login to your W&B account so you can log all your metrics in one place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 1.8 MB 6.1 MB/s \n",
      "\u001b[K     |████████████████████████████████| 181 kB 6.0 MB/s \n",
      "\u001b[K     |████████████████████████████████| 157 kB 24.1 MB/s \n",
      "\u001b[K     |████████████████████████████████| 63 kB 1.7 MB/s \n",
      "\u001b[K     |████████████████████████████████| 156 kB 42.8 MB/s \n",
      "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
       "            function loadScript(url) {\n",
       "            return new Promise(function(resolve, reject) {\n",
       "                let newScript = document.createElement(\"script\");\n",
       "                newScript.onerror = reject;\n",
       "                newScript.onload = resolve;\n",
       "                document.body.appendChild(newScript);\n",
       "                newScript.src = url;\n",
       "            });\n",
       "            }\n",
       "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
       "            const iframe = document.createElement('iframe')\n",
       "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
       "            document.body.appendChild(iframe)\n",
       "            const handshake = new Postmate({\n",
       "                container: iframe,\n",
       "                url: 'https://wandb.ai/authorize'\n",
       "            });\n",
       "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
       "            handshake.then(function(child) {\n",
       "                child.on('authorize', data => {\n",
       "                    clearTimeout(timeout)\n",
       "                    resolve(data)\n",
       "                });\n",
       "            });\n",
       "            })\n",
       "        });\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install -qqq wandb\n",
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Create a Registered Model!\n",
    "![](https://drive.google.com/uc?id=13VM43j_7iaN8Hxn74yWWrn2nBismdvdU)\n",
    "\n",
    "## Put the collection under the `model-registry` project in the team you want to make your model visible to:\n",
    "\n",
    "![](https://drive.google.com/uc?id=1Y0xSfDktiC3l-OkBrUZmFh0v96d30eFM)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Log training data as an artifact\n",
    "Check out more docs on [artifacts in W&B](https://docs.wandb.ai/guides/artifacts/api). Steps to create and log an artifact are quite simple\n",
    "0. Initialize Run with `wandb.init()`\n",
    "1. Create an artifact with `wandb.Artifact`\n",
    "2. Add directories, files to the artifact with `artifact.add_dir`, `artifact.add_file`\n",
    "3. Log the artifact with `wandb.log_artifact`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 40\n",
      "drwxr-xr-x 2 root root 4096 Dec 18  2020 Amphibia\n",
      "drwxr-xr-x 2 root root 4096 Dec 18  2020 Animalia\n",
      "drwxr-xr-x 2 root root 4096 Dec 18  2020 Arachnida\n",
      "drwxr-xr-x 2 root root 4096 Dec 18  2020 Aves\n",
      "drwxr-xr-x 2 root root 4096 Dec 18  2020 Fungi\n",
      "drwxr-xr-x 2 root root 4096 Dec 18  2020 Insecta\n",
      "drwxr-xr-x 2 root root 4096 Dec 18  2020 Mammalia\n",
      "drwxr-xr-x 2 root root 4096 Dec 18  2020 Mollusca\n",
      "drwxr-xr-x 2 root root 4096 Dec 18  2020 Plantae\n",
      "drwxr-xr-x 2 root root 4096 Dec 18  2020 Reptilia\n"
     ]
    }
   ],
   "source": [
    "!ls -l nature_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkenlee\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20220804_161422-8en37v6x</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kenlee/Model%20Registry%20E2E/runs/8en37v6x\" target=\"_blank\">cool-elevator-11</a></strong> to <a href=\"https://wandb.ai/kenlee/Model%20Registry%20E2E\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./nature_100)... Done. 0.3s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "693dfffcd66a446e9cfe03d98b480152",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.031 MB of 0.031 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">cool-elevator-11</strong>: <a href=\"https://wandb.ai/kenlee/Model%20Registry%20E2E/runs/8en37v6x\" target=\"_blank\">https://wandb.ai/kenlee/Model%20Registry%20E2E/runs/8en37v6x</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220804_161422-8en37v6x/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(project=PROJECT_NAME, entity=ENTITY, job_type=\"upload_data\")\n",
    "\n",
    "raw_data_art = wandb.Artifact(RAW_DATA_AT, type=\"raw_data\")\n",
    "raw_data_art.add_dir(DATA_SRC)\n",
    "run.log_artifact(raw_data_art)\n",
    "\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log preprocessed/split data as artifact\n",
    "- For example, a preprocessing job produces a tokenized or augmented dataset that is then utilized by a training job\n",
    "- Each job is a run logged in W&B\n",
    "- Declare dependency of a run on an artifact with `wandb.use_artifact`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20220804_161429-2nhvxg7c</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/kenlee/Model%20Registry%20E2E/runs/2nhvxg7c\" target=\"_blank\">wobbly-spaceship-12</a></strong> to <a href=\"https://wandb.ai/kenlee/Model%20Registry%20E2E\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04bbb7b58c6f4bae94be08c5a254c574",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='30.341 MB of 30.341 MB uploaded (30.300 MB deduped)\\r'), FloatProgress(value=1.0, …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B sync reduced upload amount by 99.8%             "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">wobbly-spaceship-12</strong>: <a href=\"https://wandb.ai/kenlee/Model%20Registry%20E2E/runs/2nhvxg7c\" target=\"_blank\">https://wandb.ai/kenlee/Model%20Registry%20E2E/runs/2nhvxg7c</a><br/>Synced 4 W&B file(s), 0 media file(s), 102 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220804_161429-2nhvxg7c/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "SPLIT_DATA_AT = \"_\".join([PREFIX, \"80-10-10\", str(TOTAL_IMAGES)])\n",
    "run = wandb.init(project=PROJECT_NAME, entity=ENTITY, job_type=\"data_split\")\n",
    "\n",
    "SPLIT_COUNTS = BALANCED_SPLITS\n",
    "\n",
    "data_at = run.use_artifact(RAW_DATA_AT + \":latest\")\n",
    "data_dir = data_at.download()\n",
    "data_split_at = wandb.Artifact(SPLIT_DATA_AT, type=\"balanced_data\")\n",
    "\n",
    "labels = os.listdir(data_dir)\n",
    "for l in labels:\n",
    "  if l.startswith(\".\"): # skip non-label file\n",
    "    continue\n",
    "  imgs_per_label = os.listdir(os.path.join(data_dir, l))\n",
    "  shuffle(imgs_per_label)\n",
    "  start_id = 0\n",
    "  for split, count in SPLIT_COUNTS.items():\n",
    "    # take a subset\n",
    "    split_imgs = imgs_per_label[start_id:start_id+count]\n",
    "    for img_file in split_imgs:\n",
    "      f_id = img_file.split(\".\")[0]\n",
    "      full_path = os.path.join(data_dir, l, img_file)\n",
    "\n",
    "      data_split_at.add_file(full_path, name = os.path.join(split, l, img_file))\n",
    "    start_id += count\n",
    "\n",
    "# log artifact to W&B\n",
    "run.log_artifact(data_split_at)\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPERIMENT CONFIG\n",
    "#------------------------\n",
    "# Core globals to modify\n",
    "NUM_EPOCHS = 5 # set low for demo purposes, try 3, or 5, or as many as you like\n",
    "\n",
    "\n",
    "# optional globals to modify\n",
    "# set to a custom name to help keep your experiments organized\n",
    "RUN_NAME = \"keras_model_training\" \n",
    "# change this if you'd like start a new set of comparable Tables\n",
    "# (only Tables logged to the same key can be compared)\n",
    "VAL_TABLE_NAME = \"predictions\" \n",
    "\n",
    "# hyperparams set low for demo/training speed\n",
    "# if you set these higher, be mindful of how many items are in\n",
    "# the dataset artifacts you chose by setting the SIZE at the top\n",
    "NUM_TRAIN = BALANCED_SPLITS[\"train\"]*10\n",
    "NUM_VAL = BALANCED_SPLITS[\"val\"]*10\n",
    "\n",
    "# enforced max for this is ceil(NUM_VAL/batch_size)\n",
    "NUM_LOG_BATCHES = 16\n",
    "\n",
    "# ARTIFACTS CONFIG\n",
    "#------------------------\n",
    "# training data artifact to load\n",
    "TRAIN_DATA_AT = PREFIX + \"_80-10-10_\" + str(TOTAL_IMAGES)\n",
    "\n",
    "# model name\n",
    "# if you want to train a sufficiently different model, give this a new name\n",
    "# to start a new lineage for the model, instead of just incrementing the\n",
    "# version of the old model\n",
    "MODEL_NAME = \"iv3_finetuned\"\n",
    "\n",
    "# folder in which to save the final, trained model\n",
    "# if you want to train a sufficiently different model, give this a new name\n",
    "# to start a new lineage for the model, instead of just incrementing the\n",
    "# version of the old model\n",
    "SAVE_MODEL_DIR = \"finetune_iv3_keras\"\n",
    "\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "# experiment configuration saved to W&B\n",
    "CFG = {\n",
    "  \"num_train\" : NUM_TRAIN,\n",
    "  \"num_val\" : NUM_VAL,\n",
    "  \"num_classes\" : 10,\n",
    "  \"fc_size\" : 1024,\n",
    "  \"epochs\" : NUM_EPOCHS,\n",
    "  \"batch_size\" : 32,\n",
    "\n",
    "  # inceptionV3 settings\n",
    "  \"img_width\" : 299,\n",
    "  \"img_height\": 299\n",
    "}\n",
    "\n",
    "# number of validation data batches to log/use when computing metrics\n",
    "# at the end of each epoch\n",
    "max_log_batches = int(np.ceil(float(CFG[\"num_val\"])/float(CFG[\"batch_size\"])))\n",
    "# change this min to max to log ALL the available images to a Table\n",
    "CFG[\"num_log_batches\"] = min(max_log_batches, NUM_LOG_BATCHES)\n",
    "\n",
    "def finetune_inception_model(fc_size, num_classes):\n",
    "  \"\"\"Load InceptionV3 with ImageNet weights, freeze it,\n",
    "  and attach a finetuning top for this classification task\"\"\"\n",
    "  # load InceptionV3 as base\n",
    "  base = InceptionV3(weights=\"imagenet\", include_top=\"False\")\n",
    "  # freeze base layers\n",
    "  for layer in base.layers:\n",
    "    layer.trainable = False\n",
    "  x = base.get_layer('mixed10').output \n",
    "\n",
    "  # attach a fine-tuning layer\n",
    "  x = GlobalAveragePooling2D()(x)\n",
    "  x = Dense(fc_size, activation='relu')(x)\n",
    "  guesses = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "  model = Model(inputs=base.input, outputs=guesses)\n",
    "  model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "  return model\n",
    "\n",
    "def train():\n",
    "  \"\"\" Main training loop which freezes the InceptionV3 layers of the model\n",
    "  and only trains the new top layers on the new data. A subsequent training\n",
    "  phase might unfreeze all the layers and finetune the whole model on the new data\"\"\" \n",
    "  run = wandb.init(project=PROJECT_NAME, entity=ENTITY, name=RUN_NAME, job_type=\"train\", config=CFG)\n",
    "  cfg = wandb.config\n",
    "\n",
    "  # locate and download training and validation data\n",
    "  data_at = TRAIN_DATA_AT + \":latest\"\n",
    "  data = run.use_artifact(data_at, type=\"balanced_data\")\n",
    "  data_dir = data.download()\n",
    "  train_dir = os.path.join(data_dir, \"train\")\n",
    "  val_dir = os.path.join(data_dir, \"val\")\n",
    "\n",
    "  # create train and validation data generators\n",
    "  train_datagen = ImageDataGenerator(\n",
    "      rescale=1. / 255,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True)\n",
    "  val_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "  train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(cfg.img_width, cfg.img_height),\n",
    "    batch_size=cfg.batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "  val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(cfg.img_width, cfg.img_height),\n",
    "    batch_size=cfg.batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False)\n",
    "\n",
    "  # instantiate model and callbacks\n",
    "  model = finetune_inception_model(cfg.fc_size, cfg.num_classes)\n",
    "  callbacks = [WandbCallback(), ValLog(val_generator, cfg.num_log_batches)]\n",
    "\n",
    "  # train!\n",
    "  model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch = cfg.num_train // cfg.batch_size,\n",
    "    epochs=cfg.epochs,\n",
    "    validation_data=val_generator,\n",
    "    callbacks = callbacks,\n",
    "    validation_steps = cfg.num_val // cfg.batch_size)\n",
    "\n",
    "  \n",
    "  run.finish()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3. Train and Checkpoint the Model\n",
    "- Checkpoint the model every epoch and log as a model artifact\n",
    "- Log metrics and predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ValLog(Callback):\n",
    "  \"\"\" Custom callback to log validation images\n",
    "  at the end of each training epoch\"\"\"\n",
    "  def __init__(self, generator=None, num_log_batches=1):\n",
    "    self.best_loss = float(\"inf\")\n",
    "    self.best_model = None\n",
    "\n",
    "    self.generator = generator\n",
    "    self.num_batches = num_log_batches\n",
    "    # store full names of classes\n",
    "    self.flat_class_names = [k for k, v in generator.class_indices.items()]\n",
    "\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    # collect validation data and ground truth labels from generator\n",
    "    val_data, val_labels = zip(*(self.generator[i] for i in range(self.num_batches)))\n",
    "    val_data, val_labels = np.vstack(val_data), np.vstack(val_labels)\n",
    "\n",
    "    # use the trained model to generate predictions for the given number\n",
    "    # of validation data batches (num_batches)\n",
    "    val_preds = self.model.predict(val_data)\n",
    "    true_ids = val_labels.argmax(axis=1)\n",
    "    max_preds = val_preds.argmax(axis=1)\n",
    "\n",
    "    # log validation predictions alongside the run\n",
    "    columns=[\"id\", \"image\", \"guess\", \"truth\"]\n",
    "    for a in self.flat_class_names:\n",
    "      columns.append(\"score_\" + a)\n",
    "    predictions_table = wandb.Table(columns = columns)\n",
    "    \n",
    "    # log image, predicted and actual labels, and all scores\n",
    "    for filepath, img, top_guess, scores, truth in zip(self.generator.filenames,\n",
    "                                                       val_data, \n",
    "                                                       max_preds, \n",
    "                                                       val_preds,\n",
    "                                                       true_ids):\n",
    "      img_id = filepath.split('/')[-1].split(\".\")[0]\n",
    "      row = [img_id, wandb.Image(img), \n",
    "             self.flat_class_names[top_guess], self.flat_class_names[truth]]\n",
    "      for s in scores.tolist():\n",
    "        row.append(np.round(s, 4))\n",
    "      predictions_table.add_data(*row)\n",
    "\n",
    "    val_acc = np.mean(max_preds == true_ids)\n",
    "    wandb.run.log({VAL_TABLE_NAME : predictions_table,\n",
    "                   'val_acc': val_acc})\n",
    "\n",
    "\n",
    "    is_best = val_acc > self.best_loss\n",
    "    if is_best:\n",
    "        self.best_loss = val_acc\n",
    "    \n",
    "     # Checkpoint the Model at the end of each epoch\n",
    "    trained_model_artifact = wandb.Artifact(\n",
    "              MODEL_NAME, type=\"model\",\n",
    "              description=\"finetuned inception v3\")\n",
    "  \n",
    "    self.model.save(SAVE_MODEL_DIR)\n",
    "    trained_model_artifact.add_dir(SAVE_MODEL_DIR)\n",
    "\n",
    "    # Add an alias indicating the best and latest checkpoint\n",
    "    wandb.log_artifact(trained_model_artifact, aliases=[\"best\", \"latest\"] if is_best else None)\n",
    "    if is_best:\n",
    "        self.best_model = trained_model_artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4. Link the best model checkpoint to the collection\n",
    "1. You can link a model via the UI or api with [wandb.run.link_artifact](https://docs.wandb.ai/guides/models/walkthrough#3.-link-model-versions-to-the-collection)\n",
    "2. Assign a `staging` alias to indicate this model is promising, but still needs further review\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://drive.google.com/uc?id=1fFdG_j0VZjCNsZ22hg-Gxfn08_Znw_JS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5. Load your staged model from the collection for evaluation\n",
    "- Perform evaluation and testing on the `staging` model. Refer to it by `Nature Classification:staging`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_TABLE_NAME = \"test_results\" \n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "MODEL_NAME = \"iv3_finetuned\"\n",
    "# location of test data from our original split\n",
    "# should match SPLIT_DATA_AT\n",
    "TEST_DATA_AT = \"_\".join([PREFIX, \"80-10-10\", str(TOTAL_IMAGES)])\n",
    "\n",
    "\n",
    "run = wandb.init(project=PROJECT_NAME, entity=ENTITY, job_type=\"inference\")\n",
    "model_at = wandb.use_artifact(\"Nature Classification:staging\")\n",
    "model_dir = model_at.download()\n",
    "print(\"model: \", model_dir)\n",
    "model = keras.models.load_model(model_dir)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# download latest version of test data\n",
    "test_data_at = run.use_artifact(TEST_DATA_AT + \":latest\")\n",
    "test_dir = test_data_at.download()\n",
    "test_dir += \"/test/\"\n",
    "\n",
    "class_names = [\"Animalia\", \"Amphibia\", \"Arachnida\", \"Aves\", \"Fungi\", \n",
    "               \"Insecta\", \"Mammalia\", \"Mollusca\", \"Plantae\", \"Reptilia\"]\n",
    "\n",
    "# load test images\n",
    "imgs = []\n",
    "filenames = []\n",
    "class_labels = os.listdir(test_dir)\n",
    "truth = []\n",
    "for l in class_labels:\n",
    "  if l.startswith(\".\"):\n",
    "    continue\n",
    "  imgs_per_class = os.listdir(os.path.join(test_dir, l))\n",
    "  for img in imgs_per_class:\n",
    "    # track the image id\n",
    "    filenames.append(img.split(\".\")[0])\n",
    "    truth.append(l)\n",
    "    img_path = os.path.join(test_dir, l, img)\n",
    "    img = image.load_img(img_path, target_size=(299, 299))\n",
    "    img = image.img_to_array(img)\n",
    "    # don't forget to rescale test images to match the range of inputs\n",
    "    # to the network\n",
    "    img = np.expand_dims(img/255.0, axis=0)\n",
    "    imgs.append(img)\n",
    "\n",
    "# predict on test data and bin predictions by guessed label \n",
    "preds = {}\n",
    "imgs = np.vstack(imgs)\n",
    "classes = model.predict(imgs, batch_size=32)\n",
    "for c in classes:\n",
    "  class_id = np.argmax(c)\n",
    "  if class_id in preds:\n",
    "    preds[class_id] += 1\n",
    "  else:\n",
    "    preds[class_id] = 1\n",
    "\n",
    "# log inference results as a Table to the run workspace\n",
    "columns=[\"id\", \"image\", \"guess\", \"truth\"]\n",
    "for a in class_names:\n",
    "  columns.append(\"score_\" + a)\n",
    "test_dt = wandb.Table(columns = columns)\n",
    "\n",
    "# store all the scores for each image\n",
    "for img_id, i, t, c in zip(filenames, imgs, truth, classes):\n",
    "  guess = class_names[np.argmax(c)]\n",
    "  row = [img_id, wandb.Image(i), guess, t]\n",
    "  for c_i in c.tolist():\n",
    "    row.append(np.round(c_i, 4))\n",
    "  test_dt.add_data(*row)\n",
    "  \n",
    "run.log({TEST_TABLE_NAME : test_dt})\n",
    "print(\"Quick distribution of predicted classes: \")\n",
    "print(preds)\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6. Replace Alias\n",
    "- Replace `staging` with `production` alias on the model collection\n",
    "\n",
    "![](https://drive.google.com/uc?id=1W5pRvTAqtjX30r8MZlc3eAkriQMebH8R)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
