{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anthropic\n",
    "\n",
    "Weave automatically tracks and logs LLM calls made via the [Anthropic Python library](https://github.com/anthropics/anthropic-sdk-python), after `weave.init()` is called.\n",
    "\n",
    "> **Note: Do you want to experiment with Anthropic models on Weave without any set up? Try the [LLM Playground](https://weave-docs.wandb.ai/guides/tools/playground).**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Traces\n",
    "\n",
    "It’s important to store traces of LLM applications in a central database, both during development and in production. You’ll use these traces for debugging, and as a dataset that will help you improve your application.\n",
    "\n",
    "Weave will automatically capture traces for [anthropic-sdk-python](https://github.com/anthropics/anthropic-sdk-python). You can use the library as usual, start by calling `weave.init()`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install weave anthropic -qqq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import weave\n",
    "import os\n",
    "from anthropic import Anthropic\n",
    "import getpass\n",
    "\n",
    "print(\"Enter your Anthropic API key:\")\n",
    "os.environ[\"ANTHROPIC_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If not already logged in, you will be prompted to log into wandb and authorize using your wandb account in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Weave\n",
    "weave.init(\"quickstart_anthropic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Anthropic(\n",
    "    api_key=os.environ.get(\"ANTHROPIC_API_KEY\"),\n",
    ")\n",
    "\n",
    "message = client.messages.create(\n",
    "    max_tokens=1024,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Tell me a joke about a dog\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"claude-3-opus-20240229\",\n",
    ")\n",
    "print(message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Weave will now track and log all LLM calls made through the Anthropic library. You can view the traces in the Weave web interface.\n",
    "\n",
    "[![anthropic_trace.png](https://weave-docs.wandb.ai/assets/images/anthropic_trace-86762152ce8e85940a0c11fcaa89b2c1.png)](https://wandb.ai/capecape/anthropic_project/weave/calls)\n",
    "\n",
    "**Note: We patch the anthropic `Messages.create` method for you to keep track of your LLM calls.**\n",
    "\n",
    "\n",
    "Weave will now track and log all LLM calls made through Anthropic. You can view the logs and insights in the Weave web interface.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Wrapping with your own ops\n",
    "\n",
    "Weave ops make results *reproducible* by automatically versioning code as you experiment, and they capture their inputs and outputs. Simply create a function decorated with [`@weave.op()`](https://weave-docs.wandb.ai/guides/tracking/ops) that calls into [`Anthropic.messages.create`](https://docs.anthropic.com/en/api/messages-examples) and Weave will track the inputs and outputs for you. Let's see how we can do this in nested example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@weave.op()\n",
    "def call_anthropic(user_input:str, model:str) -> str:\n",
    "    message = client.messages.create(\n",
    "    max_tokens=1024,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": user_input,\n",
    "        }\n",
    "        ],\n",
    "        model=model,\n",
    "    )\n",
    "    return message.content[0].text\n",
    "\n",
    "\n",
    "@weave.op()\n",
    "def generate_joke(topic: str) -> str:\n",
    "    return call_anthropic(f\"Tell me a joke about {topic}\", model=\"claude-3-haiku-20240307\")\n",
    "\n",
    "print(generate_joke(\"chickens\"))\n",
    "print(generate_joke(\"cars\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "[![anthropic_ops.png](https://weave-docs.wandb.ai/assets/images/anthropic_ops-7ba2cedd670985492e77127c01d67a6d.png)](https://wandb.github.io/weave/guides/tracking/ops)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a `Model` for easier experimentation\n",
    "\n",
    "Organizing experimentation is difficult when there are many moving pieces. By using the [`Model`](https://weave-docs.wandb.ai/guides/core-types/models/) class, you can capture and organize the experimental details of your app like your system prompt or the model you're using. This helps organize and compare different iterations of your app. \n",
    "\n",
    "In addition to versioning code and capturing inputs/outputs, [`Model`](https://weave-docs.wandb.ai/guides/core-types/models/)s capture structured parameters that control your application’s behavior, making it easy to find what parameters worked best. You can also use Weave Models with `serve`, and [`Evaluation`](https://weave-docs.wandb.ai/guides/core-types/evaluations)s.\n",
    "\n",
    "In the example below, you can experiment with `model` and `temperature`. Every time you change one of these, you'll get a new _version_ of `JokerModel`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JokerModel(weave.Model): # Change to `weave.Model`\n",
    "  model: str\n",
    "  temperature: float\n",
    "  \n",
    "  @weave.op()\n",
    "  def predict(self, topic): # Change to `predict`\n",
    "    client = Anthropic()\n",
    "    message = client.messages.create(\n",
    "    max_tokens=1024,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Tell me a joke about {topic}\",\n",
    "        }\n",
    "        ],\n",
    "        model=self.model,\n",
    "        temperature=self.temperature\n",
    "    )\n",
    "    return message.content[0].text\n",
    "\n",
    "\n",
    "joker = JokerModel(\n",
    "    model=\"claude-3-haiku-20240307\",\n",
    "    temperature = 0.1)\n",
    "result = joker.predict(\"Chickens and Robots\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "[![anthropic_model.png](https://weave-docs.wandb.ai/assets/images/anthropic_model-cfa9fe341388d9c96d559872dd065541.png)](https://wandb.ai/capecape/anthropic_project/weave/calls)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Tools (function calling)\n",
    "\n",
    "Anthropic provides [tools](https://docs.anthropic.com/en/docs/tool-use) interface for calling functions. Weave will automatically track those functions calls.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = client.messages.create(\n",
    "    max_tokens=1024,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What's the weather like in San Francisco?\",\n",
    "        }\n",
    "    ],\n",
    "    tools=[\n",
    "        {\n",
    "            \"name\": \"get_weather\",\n",
    "            \"description\": \"Get the current weather in a given location\",\n",
    "            \"input_schema\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The city and state, e.g. San Francisco, CA\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"location\"],\n",
    "            },\n",
    "        },\n",
    "    ],\n",
    "    model=\"claude-3-opus-20240229\",\n",
    ")\n",
    "\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We automatically capture the tools you used on the prompt and keep them versioned.\n",
    "\n",
    "[![anthropic_tool.png](https://weave-docs.wandb.ai/assets/images/anthropic_tool-8c94aecc041d6bbcf5a8a23a43760c81.png)](https://wandb.ai/capecape/anthropic_project/weave/calls)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wandb-examples",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
