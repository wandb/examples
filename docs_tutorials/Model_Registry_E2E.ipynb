{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artifacts and Model Registry Walkthrough \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/wandb/examples/blob/master/colabs/wandb-model-registry/Model_Registry_E2E.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "\n",
    "# source directory for all raw data\n",
    "DATA_SRC = \"nature_100\"\n",
    "IMAGES_PER_LABEL = 10\n",
    "BALANCED_SPLITS = {\"train\" : 8, \"val\" : 1, \"test\": 1}\n",
    "SRC = DATA_SRC\n",
    "PREFIX = \"GCS\" # convenient for tracking local data\n",
    "PROJECT_NAME = \"Model Registry E2E\" #@param {type:\"string\"}\n",
    "ENTITY=\"kenlee\"#@param {type:\"string\"}\n",
    "dataset_name = \"mnist\"\n",
    "\n",
    "# number of images per class label\n",
    "# the total number of images is 10X this (10 classes)\n",
    "TOTAL_IMAGES = IMAGES_PER_LABEL * 10\n",
    "RAW_DATA_AT = \"_\".join([PREFIX, \"raw_data\", str(TOTAL_IMAGES)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Registry Overview\n",
    "![dataset_card_overview](https://drive.google.com/uc?export=view&id=1Ea_vEhhbcqHBnooY-Efdo_tST6ULRW3e)\n",
    "\n",
    "1. Checkpoint the model every epoch and log as an artifact\n",
    "2. Link your best model to a **Registered Collection** in the Model Registry\n",
    "3. Retrieve the model from the collection for downstream evaluation or inference\n",
    "4. Add aliases depending on stage of model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# set SIZE to \"TINY\", \"SMALL\", \"MEDIUM\", or \"LARGE\"\n",
    "# to select one of these three datasets\n",
    "# TINY dataset: 100 images, 30MB\n",
    "# SMALL dataset: 1000 images, 312MB\n",
    "# MEDIUM dataset: 5000 images, 1.5GB\n",
    "# LARGE dataset: 12,000 images, 3.6GB\n",
    "\n",
    "SIZE = \"TINY\"\n",
    "\n",
    "if SIZE == \"TINY\":\n",
    "  src_url = \"https://storage.googleapis.com/wandb_datasets/nature_100.zip\"\n",
    "  src_zip = \"nature_100.zip\"\n",
    "  DATA_SRC = \"nature_100\"\n",
    "  IMAGES_PER_LABEL = 10\n",
    "  BALANCED_SPLITS = {\"train\" : 8, \"val\" : 1, \"test\": 1}\n",
    "elif SIZE == \"SMALL\":\n",
    "  src_url = \"https://storage.googleapis.com/wandb_datasets/nature_1K.zip\"\n",
    "  src_zip = \"nature_1K.zip\"\n",
    "  DATA_SRC = \"nature_1K\"\n",
    "  IMAGES_PER_LABEL = 100\n",
    "  BALANCED_SPLITS = {\"train\" : 80, \"val\" : 10, \"test\": 10}\n",
    "elif SIZE == \"MEDIUM\":\n",
    "  src_url = \"https://storage.googleapis.com/wandb_datasets/nature_12K.zip\"\n",
    "  src_zip = \"nature_12K.zip\"\n",
    "  DATA_SRC = \"inaturalist_12K/train\" # (technically a subset of only 10K images)\n",
    "  IMAGES_PER_LABEL = 500\n",
    "  BALANCED_SPLITS = {\"train\" : 400, \"val\" : 50, \"test\": 50}\n",
    "elif SIZE == \"LARGE\":\n",
    "  src_url = \"https://storage.googleapis.com/wandb_datasets/nature_12K.zip\"\n",
    "  src_zip = \"nature_12K.zip\"\n",
    "  DATA_SRC = \"inaturalist_12K/train\" # (technically a subset of only 10K images)\n",
    "  IMAGES_PER_LABEL = 1000\n",
    "  BALANCED_SPLITS = {\"train\" : 800, \"val\" : 100, \"test\": 100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!curl -SL $src_url > $src_zip\n",
    "!unzip $src_zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0: Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start out by installing the experiment tracking library and setting up your free W&B account:\n",
    "\n",
    "\n",
    "*   `pip install wandb` – Install the W&B library\n",
    "*   `import wandb` – Import the wandb library\n",
    "*   `wandb login` – Login to your W&B account so you can log all your metrics in one place"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -qqq wandb\n",
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Create a Registered Model!\n",
    "![](https://drive.google.com/uc?id=13VM43j_7iaN8Hxn74yWWrn2nBismdvdU)\n",
    "\n",
    "## Put the collection under the `model-registry` project in the team you want to make your model visible to:\n",
    "\n",
    "![](https://drive.google.com/uc?id=1Y0xSfDktiC3l-OkBrUZmFh0v96d30eFM)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Log training data as an artifact\n",
    "Check out more docs on [artifacts in W&B](https://docs.wandb.ai/guides/artifacts/api). Steps to create and log an artifact are quite simple\n",
    "0. Initialize Run with `wandb.init()`\n",
    "1. Create an artifact with `wandb.Artifact`\n",
    "2. Add directories, files to the artifact with `artifact.add_dir`, `artifact.add_file`\n",
    "3. Log the artifact with `wandb.log_artifact`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "!ls -l nature_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "run = wandb.init(project=PROJECT_NAME, entity=ENTITY, job_type=\"upload_data\")\n",
    "\n",
    "raw_data_art = wandb.Artifact(RAW_DATA_AT, type=\"raw_data\")\n",
    "raw_data_art.add_dir(DATA_SRC)\n",
    "run.log_artifact(raw_data_art)\n",
    "\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log preprocessed/split data as artifact\n",
    "- For example, a preprocessing job produces a tokenized or augmented dataset that is then utilized by a training job\n",
    "- Each job is a run logged in W&B\n",
    "- Declare dependency of a run on an artifact with `wandb.use_artifact`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "SPLIT_DATA_AT = \"_\".join([PREFIX, \"80-10-10\", str(TOTAL_IMAGES)])\n",
    "run = wandb.init(project=PROJECT_NAME, entity=ENTITY, job_type=\"data_split\")\n",
    "\n",
    "SPLIT_COUNTS = BALANCED_SPLITS\n",
    "\n",
    "data_at = run.use_artifact(RAW_DATA_AT + \":latest\")\n",
    "data_dir = data_at.download()\n",
    "data_split_at = wandb.Artifact(SPLIT_DATA_AT, type=\"balanced_data\")\n",
    "\n",
    "labels = os.listdir(data_dir)\n",
    "for l in labels:\n",
    "  if l.startswith(\".\"): # skip non-label file\n",
    "    continue\n",
    "  imgs_per_label = os.listdir(os.path.join(data_dir, l))\n",
    "  shuffle(imgs_per_label)\n",
    "  start_id = 0\n",
    "  for split, count in SPLIT_COUNTS.items():\n",
    "    # take a subset\n",
    "    split_imgs = imgs_per_label[start_id:start_id+count]\n",
    "    for img_file in split_imgs:\n",
    "      f_id = img_file.split(\".\")[0]\n",
    "      full_path = os.path.join(data_dir, l, img_file)\n",
    "\n",
    "      data_split_at.add_file(full_path, name = os.path.join(split, l, img_file))\n",
    "    start_id += count\n",
    "\n",
    "# log artifact to W&B\n",
    "run.log_artifact(data_split_at)\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# EXPERIMENT CONFIG\n",
    "#------------------------\n",
    "# Core globals to modify\n",
    "NUM_EPOCHS = 5 # set low for demo purposes, try 3, or 5, or as many as you like\n",
    "\n",
    "\n",
    "# optional globals to modify\n",
    "# set to a custom name to help keep your experiments organized\n",
    "RUN_NAME = \"keras_model_training\" \n",
    "# change this if you'd like start a new set of comparable Tables\n",
    "# (only Tables logged to the same key can be compared)\n",
    "VAL_TABLE_NAME = \"predictions\" \n",
    "\n",
    "# hyperparams set low for demo/training speed\n",
    "# if you set these higher, be mindful of how many items are in\n",
    "# the dataset artifacts you chose by setting the SIZE at the top\n",
    "NUM_TRAIN = BALANCED_SPLITS[\"train\"]*10\n",
    "NUM_VAL = BALANCED_SPLITS[\"val\"]*10\n",
    "\n",
    "# enforced max for this is ceil(NUM_VAL/batch_size)\n",
    "NUM_LOG_BATCHES = 16\n",
    "\n",
    "# ARTIFACTS CONFIG\n",
    "#------------------------\n",
    "# training data artifact to load\n",
    "TRAIN_DATA_AT = PREFIX + \"_80-10-10_\" + str(TOTAL_IMAGES)\n",
    "\n",
    "# model name\n",
    "# if you want to train a sufficiently different model, give this a new name\n",
    "# to start a new lineage for the model, instead of just incrementing the\n",
    "# version of the old model\n",
    "MODEL_NAME = \"iv3_finetuned\"\n",
    "\n",
    "# folder in which to save the final, trained model\n",
    "# if you want to train a sufficiently different model, give this a new name\n",
    "# to start a new lineage for the model, instead of just incrementing the\n",
    "# version of the old model\n",
    "SAVE_MODEL_DIR = \"finetune_iv3_keras\"\n",
    "\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from wandb.keras import WandbCallback\n",
    "\n",
    "# experiment configuration saved to W&B\n",
    "CFG = {\n",
    "  \"num_train\" : NUM_TRAIN,\n",
    "  \"num_val\" : NUM_VAL,\n",
    "  \"num_classes\" : 10,\n",
    "  \"fc_size\" : 1024,\n",
    "  \"epochs\" : NUM_EPOCHS,\n",
    "  \"batch_size\" : 32,\n",
    "\n",
    "  # inceptionV3 settings\n",
    "  \"img_width\" : 299,\n",
    "  \"img_height\": 299\n",
    "}\n",
    "\n",
    "# number of validation data batches to log/use when computing metrics\n",
    "# at the end of each epoch\n",
    "max_log_batches = int(np.ceil(float(CFG[\"num_val\"])/float(CFG[\"batch_size\"])))\n",
    "# change this min to max to log ALL the available images to a Table\n",
    "CFG[\"num_log_batches\"] = min(max_log_batches, NUM_LOG_BATCHES)\n",
    "\n",
    "def finetune_inception_model(fc_size, num_classes):\n",
    "  \"\"\"Load InceptionV3 with ImageNet weights, freeze it,\n",
    "  and attach a finetuning top for this classification task\"\"\"\n",
    "  # load InceptionV3 as base\n",
    "  base = InceptionV3(weights=\"imagenet\", include_top=\"False\")\n",
    "  # freeze base layers\n",
    "  for layer in base.layers:\n",
    "    layer.trainable = False\n",
    "  x = base.get_layer('mixed10').output \n",
    "\n",
    "  # attach a fine-tuning layer\n",
    "  x = GlobalAveragePooling2D()(x)\n",
    "  x = Dense(fc_size, activation='relu')(x)\n",
    "  guesses = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "  model = Model(inputs=base.input, outputs=guesses)\n",
    "  model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "  return model\n",
    "\n",
    "def train():\n",
    "  \"\"\" Main training loop which freezes the InceptionV3 layers of the model\n",
    "  and only trains the new top layers on the new data. A subsequent training\n",
    "  phase might unfreeze all the layers and finetune the whole model on the new data\"\"\" \n",
    "  run = wandb.init(project=PROJECT_NAME, entity=ENTITY, name=RUN_NAME, job_type=\"train\", config=CFG)\n",
    "  cfg = wandb.config\n",
    "\n",
    "  # locate and download training and validation data\n",
    "  data_at = TRAIN_DATA_AT + \":latest\"\n",
    "  data = run.use_artifact(data_at, type=\"balanced_data\")\n",
    "  data_dir = data.download()\n",
    "  train_dir = os.path.join(data_dir, \"train\")\n",
    "  val_dir = os.path.join(data_dir, \"val\")\n",
    "\n",
    "  # create train and validation data generators\n",
    "  train_datagen = ImageDataGenerator(\n",
    "      rescale=1. / 255,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True)\n",
    "  val_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "  train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(cfg.img_width, cfg.img_height),\n",
    "    batch_size=cfg.batch_size,\n",
    "    class_mode='categorical')\n",
    "\n",
    "  val_generator = val_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=(cfg.img_width, cfg.img_height),\n",
    "    batch_size=cfg.batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False)\n",
    "\n",
    "  # instantiate model and callbacks\n",
    "  model = finetune_inception_model(cfg.fc_size, cfg.num_classes)\n",
    "  callbacks = [WandbCallback(), ValLog(val_generator, cfg.num_log_batches)]\n",
    "\n",
    "  # train!\n",
    "  model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch = cfg.num_train // cfg.batch_size,\n",
    "    epochs=cfg.epochs,\n",
    "    validation_data=val_generator,\n",
    "    callbacks = callbacks,\n",
    "    validation_steps = cfg.num_val // cfg.batch_size)\n",
    "\n",
    "  \n",
    "  run.finish()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3. Train and Checkpoint the Model\n",
    "- Checkpoint the model every epoch and log as a model artifact\n",
    "- Log metrics and predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "class ValLog(Callback):\n",
    "  \"\"\" Custom callback to log validation images\n",
    "  at the end of each training epoch\"\"\"\n",
    "  def __init__(self, generator=None, num_log_batches=1):\n",
    "    self.best_loss = float(\"inf\")\n",
    "    self.best_model = None\n",
    "\n",
    "    self.generator = generator\n",
    "    self.num_batches = num_log_batches\n",
    "    # store full names of classes\n",
    "    self.flat_class_names = [k for k, v in generator.class_indices.items()]\n",
    "\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    # collect validation data and ground truth labels from generator\n",
    "    val_data, val_labels = zip(*(self.generator[i] for i in range(self.num_batches)))\n",
    "    val_data, val_labels = np.vstack(val_data), np.vstack(val_labels)\n",
    "\n",
    "    # use the trained model to generate predictions for the given number\n",
    "    # of validation data batches (num_batches)\n",
    "    val_preds = self.model.predict(val_data)\n",
    "    true_ids = val_labels.argmax(axis=1)\n",
    "    max_preds = val_preds.argmax(axis=1)\n",
    "\n",
    "    # log validation predictions alongside the run\n",
    "    columns=[\"id\", \"image\", \"guess\", \"truth\"]\n",
    "    for a in self.flat_class_names:\n",
    "      columns.append(\"score_\" + a)\n",
    "    predictions_table = wandb.Table(columns = columns)\n",
    "    \n",
    "    # log image, predicted and actual labels, and all scores\n",
    "    for filepath, img, top_guess, scores, truth in zip(self.generator.filenames,\n",
    "                                                       val_data, \n",
    "                                                       max_preds, \n",
    "                                                       val_preds,\n",
    "                                                       true_ids):\n",
    "      img_id = filepath.split('/')[-1].split(\".\")[0]\n",
    "      row = [img_id, wandb.Image(img), \n",
    "             self.flat_class_names[top_guess], self.flat_class_names[truth]]\n",
    "      for s in scores.tolist():\n",
    "        row.append(np.round(s, 4))\n",
    "      predictions_table.add_data(*row)\n",
    "\n",
    "    val_acc = np.mean(max_preds == true_ids)\n",
    "    wandb.run.log({VAL_TABLE_NAME : predictions_table,\n",
    "                   'val_acc': val_acc})\n",
    "\n",
    "\n",
    "    is_best = val_acc > self.best_loss\n",
    "    if is_best:\n",
    "        self.best_loss = val_acc\n",
    "    \n",
    "     # Checkpoint the Model at the end of each epoch\n",
    "    trained_model_artifact = wandb.Artifact(\n",
    "              MODEL_NAME, type=\"model\",\n",
    "              description=\"finetuned inception v3\")\n",
    "  \n",
    "    self.model.save(SAVE_MODEL_DIR)\n",
    "    trained_model_artifact.add_dir(SAVE_MODEL_DIR)\n",
    "\n",
    "    # Add an alias indicating the best and latest checkpoint\n",
    "    wandb.log_artifact(trained_model_artifact, aliases=[\"best\", \"latest\"] if is_best else None)\n",
    "    if is_best:\n",
    "        self.best_model = trained_model_artifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4. Link the best model checkpoint to the collection\n",
    "1. You can link a model via the UI or api with [wandb.run.link_artifact](https://docs.wandb.ai/guides/models/walkthrough#3.-link-model-versions-to-the-collection)\n",
    "2. Assign a `staging` alias to indicate this model is promising, but still needs further review\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://drive.google.com/uc?id=1fFdG_j0VZjCNsZ22hg-Gxfn08_Znw_JS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5. Load your staged model from the collection for evaluation\n",
    "- Perform evaluation and testing on the `staging` model. Refer to it by `Nature Classification:staging`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "TEST_TABLE_NAME = \"test_results\" \n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "MODEL_NAME = \"iv3_finetuned\"\n",
    "# location of test data from our original split\n",
    "# should match SPLIT_DATA_AT\n",
    "TEST_DATA_AT = \"_\".join([PREFIX, \"80-10-10\", str(TOTAL_IMAGES)])\n",
    "\n",
    "\n",
    "run = wandb.init(project=PROJECT_NAME, entity=ENTITY, job_type=\"inference\")\n",
    "model_at = wandb.use_artifact(\"Nature Classification:staging\")\n",
    "model_dir = model_at.download()\n",
    "print(\"model: \", model_dir)\n",
    "model = keras.models.load_model(model_dir)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# download latest version of test data\n",
    "test_data_at = run.use_artifact(TEST_DATA_AT + \":latest\")\n",
    "test_dir = test_data_at.download()\n",
    "test_dir += \"/test/\"\n",
    "\n",
    "class_names = [\"Animalia\", \"Amphibia\", \"Arachnida\", \"Aves\", \"Fungi\", \n",
    "               \"Insecta\", \"Mammalia\", \"Mollusca\", \"Plantae\", \"Reptilia\"]\n",
    "\n",
    "# load test images\n",
    "imgs = []\n",
    "filenames = []\n",
    "class_labels = os.listdir(test_dir)\n",
    "truth = []\n",
    "for l in class_labels:\n",
    "  if l.startswith(\".\"):\n",
    "    continue\n",
    "  imgs_per_class = os.listdir(os.path.join(test_dir, l))\n",
    "  for img in imgs_per_class:\n",
    "    # track the image id\n",
    "    filenames.append(img.split(\".\")[0])\n",
    "    truth.append(l)\n",
    "    img_path = os.path.join(test_dir, l, img)\n",
    "    img = image.load_img(img_path, target_size=(299, 299))\n",
    "    img = image.img_to_array(img)\n",
    "    # don't forget to rescale test images to match the range of inputs\n",
    "    # to the network\n",
    "    img = np.expand_dims(img/255.0, axis=0)\n",
    "    imgs.append(img)\n",
    "\n",
    "# predict on test data and bin predictions by guessed label \n",
    "preds = {}\n",
    "imgs = np.vstack(imgs)\n",
    "classes = model.predict(imgs, batch_size=32)\n",
    "for c in classes:\n",
    "  class_id = np.argmax(c)\n",
    "  if class_id in preds:\n",
    "    preds[class_id] += 1\n",
    "  else:\n",
    "    preds[class_id] = 1\n",
    "\n",
    "# log inference results as a Table to the run workspace\n",
    "columns=[\"id\", \"image\", \"guess\", \"truth\"]\n",
    "for a in class_names:\n",
    "  columns.append(\"score_\" + a)\n",
    "test_dt = wandb.Table(columns = columns)\n",
    "\n",
    "# store all the scores for each image\n",
    "for img_id, i, t, c in zip(filenames, imgs, truth, classes):\n",
    "  guess = class_names[np.argmax(c)]\n",
    "  row = [img_id, wandb.Image(i), guess, t]\n",
    "  for c_i in c.tolist():\n",
    "    row.append(np.round(c_i, 4))\n",
    "  test_dt.add_data(*row)\n",
    "  \n",
    "run.log({TEST_TABLE_NAME : test_dt})\n",
    "print(\"Quick distribution of predicted classes: \")\n",
    "print(preds)\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6. Replace Alias\n",
    "- Replace `staging` with `production` alias on the model collection\n",
    "\n",
    "![](https://drive.google.com/uc?id=1W5pRvTAqtjX30r8MZlc3eAkriQMebH8R)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
